\subsection{\software{Netabc}: uses, limitations, and possible extensions}

The method behind \software{netabc} is model-agnostic, meaning that it can be
used to infer parameters of any network model, as long as it allows simulated
networks can be easily generated. We have included generators for the \gls{BA}
model discussed here, as well as the \gls{ER} and \gls{WS} network models.
Instructions for adding additional models are available in the project's online
documentation. We have made \software{netabc} publicly available at
\url{github.com/rmcclosk/netabc} under a permissive open source license, to
encourage other researchers to apply and extend our method.

Several alternative network models and modeling frameworks have been developed
which may provide useful future targets for kernel-\gls{ABC}. Waring
models~\autocite{irwin1963place,handcock2004likelihood} are a more flexible
type of preferential attachment model which permit a subset of attachments to
be formed non-prefentially. These models were used by
\textcite{brown2011transmission} to characterize the transmission network in
the United Kingdom. \Glspl{ERGM}~\autocite{robins2007introduction} are a
flexible and expressive parameterization of contact networks in terms of
statistics of network features such as pairs and triads.
\textcite{goodreau2007assessing} evaluated the effect of several different
\gls{ERGM} parameterizations on transmission tree shape and effective
population size. The author suggested the use of \glspl{ERGM} as a general
framework for estimation of epidemiological quantities related to \gls{HIV}
transmission. Except for a few special cases, simulating a network according to
an \gls{ERGM} generally requires \gls{MCMC}, which would be too computationally
intensive to integrate into \software{netabc} as it currently stands. To fit
\gls{ERGM} with kernel-\gls{ABC}, one possibility would be to consider the
network itself as a parameter to be modified by the \gls{MCMC} kernel.
Other network modelling frameworks include the partnership-centric formulation
developed by~\textcite{eames2002modeling} and the log-linear adjacency matrix
parameterization developed by~\textcite{morriz1993epidemiology}.

%\Textcite{morris1993epidemiology} proposes to apply the standard compartmental
%modelling framework to contact networks by assigning each individual their own
%compartment. Thus, each individual is associated with a single \gls{ODE}, with
%the entire \gls{ODE} system parameterized by the adjacency matrix of the
%contact network. 
%The author proposes to use log-linear models to parameterize the adjacency
%5matrix of a contact network. This framework is highly expressive, and allows
%straightforward incorporation of time-dependent dynamics. 
%However, simulating a transmission tree would require the numerical solution of
%a very large system of \glspl{ODE}, which may be computationally prohibitive
%given the number of simulations required for kernel-\gls{ABC}.

The two-step process of simulating a contact network and subsequently allowing
an epidemic to spread over that network carries with it the assumption that the
contact network is static over the duration of the epidemic. Clearly this
assumption is invalid, as people make and break partnerships on a regular
basis. Addressing the impact of this simplifying assumption is outside the
scope of this work. However, the same assumption is made by most studies using
contact network models in an epidemiological
context~\autocite{welch2011statistical, bansal2007individual}. In principle,
kernel-\gls{ABC} could be adapted to dynamic contact networks by using a method
such as that developed by \textcite{robinson2012dynamics} to simulate such a
network, while concurrently simulating the spread of an epidemic.

It is important to note that \software{netabc} takes a transmission tree as
input, rather than a viral phylogeny. Thus, we have left the estimation of a
transmission tree up to the user. In theory, it is possible to incorporate the
process by which a viral phylogeny is generated along with a transmission tree
into our method, for example by simulating within-host dynamics. Although this
may be an avenue for future extension, we felt that it would obscure the
primary purpose of this work, which is to study contact network parameters.
In addition, there are a number of different methods available for inferring
transmission trees~\autocite{didelot2014bayesian, ypma2012unravelling,
jombart2011reconstructing, cottam2008integrating, poon2015phylodynamic}, some
of which incorporate geographic and/or epidemiological data not accommodated by
our method. We therefore felt it would be best to allow researchers to use
their own preferred tree building method.

Our implementation of \gls{SMC} uses a simple multinomial scheme to sample
particles from the population according to their weights. Several other
sampling strategies have been developed~\autocite{douc2005comparison}, and it
is possible that the use of a more sophisticated technique might increase the
algorithm's accuracy. 

\subsection{Analysis of \acrlong{BA} model}

The preferential attachment power \gls{alpha} had a very strong influence on
tree shape in the range of values we considered. Although the tree kernel was
the most effective classifier for \gls{alpha}, a tree balance statistic
performed nearly as well. This result was intuitive: high \gls{alpha} values
produce networks with few well-connected superspreader nodes which are involved
in a large number of transmissions, resulting in a highly unbalanced
ladder-like tree structure. The \gls{I} parameter, representing the prevalence
at the time of sampling, was also generally estimable. The dynamics of the
\gls{SI} model, and the coalescent process, offer a potential explanation for
this result. In the initial phase of the epidemic, when \gls{I} is small, each
new transmission results in potentially many new discordant edges, thus
decreasing the waiting time until the next transmission. Hence, there is an
early exponential growth phase, producing many short branches near the root of
the tree. As the epidemic gets closer to saturating the network, the number of
discordant edges decays, causing longer waiting times. The distribution of
coalescent times in the tree should therefore be informative about \gls{I}.
This information is captured by the tree kernel, and also by the \gls{nltt}
statistic, which both performed quite will in classifying \gls{I}
(\cref{fig:rsquared}).

The number of nodes in the network, \gls{N}, exhibited the most variation in
terms of being estimable. There was almost no difference between trees
simulated under different \gls{N} values when the number of infected nodes
\gls{I} was very small. There is an intuitive explanation for this result,
namely that adding additional nodes does not change the edge density or overall
shape of a \gls{BA} network. This can be illustrated by imagining that we add a
small number of nodes to a network after the epidemic simulation has already
been completed. It is possible that none of these new nodes attains a
connection to any infected node. Thus, running the simulation again on the new,
larger network could produce the exact same transmission tree as before. On the
other hand, when \gls{I} is large, the coalescent dynamics discussed above for
\gls{I} also apply, as evidenced by the relative accuracy of the \gls{nltt}.
The \gls{m} parameter, which controls the number of connections added to the
network per vertex, did not have a measurable impact on tree shape and was not
estimable with kernel-ABC. The exception to this was the value \gls{m} = 1,
which produces networks without cycles whose associated trees were more easily
distinguished. However, all the analyses presented here did not take the
absolute size of the transmission trees into account, as the branch lengths
were rescaled by their mean. Because higher \gls{m} values imply higher edge
density, an epidemic should spread more quickly for higher \gls{m} than lower
\gls{m} with the same per-edge transmission probability.  Hence, considering
the absolute height of the trees may improve our method's ability to
reconstruct \gls{m}.

In addition to the tree height, many summary statistics have been developed to
capture particular details of tree shape. Two of these, Sackin's index and the
ratio of internal to terminal branch lengths, were correlated with every
\gls{BA} parameter. Classifiers based on Sackin's index and the \gls{nltt}
similarity measure performed well in some cases, though poorly in others.
\gls{ABC} is often applied using a vector of summary statistics, rather than a
kernel-based similarity score as we have done here, and methods have been
developed to select an optimal combination of summary statistics for a given
inference task~\autocite{fearnhead2012constructing}. Hence, an avenue for
future improvement of our method may be the inclusion of additional summary
statistics to supplement the tree kernel. In addition, all four parameters were
more accurately classified when the number of tips in the transmission trees
was larger, underscoring the importance of adequate sampling for accurate
phylodynamic inference.

For the more estimable parameters, the credible intervals attained from the
marginal \gls{ABC} target distributions were much narrower than those obtained
through grid search, while point estimates were of comparable accuracy. This
was likely due to the fact that \gls{SMC} employs importance sampling to
approximate the posterior distribution, while grid search simply calculates a
distance metric which may not have any resemblance to the posterior.
Admittedly, our method of finding credible intervals from kernel scores along
the grid, namely by normalizing the scores to resemble a probability
distribution, was somewhat ad hoc, which may also have played a role.
Regardless, this result indicates that there is benefit to applying the more
sophisticated method, even if values for some of the parameters are known
\textit{a priori}, and especially if credible intervals are desired on the
parameters of interest.

As noted by \textcite{lintusaari2016identifiability}, uniform priors on model
parameters may translate to highly informative priors on quantities of
interest. We observed a non-linear relationship between the pcreferential
attachment power $\alpha$ and the power law exponent $\gamma$
(\cref{fig:gamma}). Thecrefore, placing a uniform prior on $\alpha$ between 0
and 2 is equivalent to placing an informative prior that $\gamma$ is close to
2. Thecrefore, if we were primarily interested in $\gamma$ rather than
$\alpha$, a more sensible choice of prior might have a shape informed by
\cref{fig:gamma} and be bounded above by approximately $\alpha$ = 1.5. This
would uniformly bound $\gamma$ in the region $2 \leq \gamma \leq 4$ commonly
reported in the network literature~\autocite{liljeros2001web,
schneeberger2004scale, colgate1989risk, brown2011transmission}. We note however
that \textcite{jones2003assessment} estimated $\gamma$ values greater than
four for some datasets, in one case as high as 17, indicating that a wider
range of permitted $\gamma$ values may be warranted.

\subsection{Application to HIV data}

Our investigation of published HIV datasets indicated heterogeneity in the
contact network structures underlying several distinct local epidemics. When
interpreting these results, we caution that the BA model is quite simple and
most likely misspecified for these data. In particular, the average degree of a
node in the network is equal to $2m$, and thecrefore is constrained to be a
multiple of 2. Furthermore, we considered the case $m = 1$, where the network
has no cycles, to be implausible and thecrefore assigned it zero prior
probability in one set of analyses. This forced the average degree to be at
least four, which may be unrealistically high for sexual networks. The fact
that the estimated values of $\alpha$ differed substatially for three datasets
depending on whether or not $m = 1$ was allowed by the prior is futher evidence
of this potential misspecification. However, we note that for two of the
datasets, the estimated values of $\alpha$ did not change much between priors,
and the estimates of $I$ were robust to the choice of prior for all datasets
studied. More sophisticated models, for example models incorporating
heterogeneity in node behaviour, are likely to provide a better fit to these
data.

With respect to the pcreferential attachment power $\alpha$, the five datasets
analysed fell into three categories (\cref{fig:abchpd}). First, we
estimated a pcreferential attachment power close to 1, indicating linear
pcreferential attachment, for the outbreaks studied by
\textcite{niculescu2015recent} and \textcite{wang2015targeting}. These values
were robust to specifying different priors for $m$. Both studies were of
populations in which we would expect a high degree of epidemiological
relatedness: \textcite{niculescu2015recent} studied a recent outbreak among
Romanian injection drug users (IDU), while \citeauthor{wang2015targeting}
sampled acutely infected MSM in Beijing, China. Both these are contexts in
which we would expect some of the assumptions of the BA model, such as a
connected network, relatively high mean degree, and pcreferential attachment
dynamics, to hold.

The remaining three datasets (\textcite{cuevas2009hiv, novitsky2014impact,
li2015hiv}) had estimated values of $\alpha$ below 0.5 when $m = 1$ was
included in the prior, but these were not robust to changing the prior to
exclude $m = 1$. For the \citeauthor{cuevas2009hiv} data, model
misspecification is likely partially responsible. While the authors found that
a large proportion of the samples were epidemiologically linked, these were
mainly in small local clusters rather than the single large component
postulated by the BA model. In addition, the mixed risk groups in the dataset
would be unlikely to significantly interact, further weakening any global
pcreferential attachment dynamics. The dataset studied by
\textcite{novitsky2014impact} originated from a densely sampled population
where the predominant risk factor was believed to be heterosexual exposure.
Although the MAP estimate of $\alpha$ was almost unchanged when the value $m =
1$ was excluded from the prior, the confidence interval shrank substantially.
For both priors, the estimated prevalence was extremely high, in fact higher
than the estimated HIV prevalence in the sampled region. The authors indicated
that the source of the samples was a town in close proximity to the country's
capital city, and suggested that there may have been a high degree of migration
and partner interchange between the two locations. It is possible that the
contact network underlying the subtree we investigated includes a much larger
group based in the capital city, which would explain the high estimate of $I$.
There is no clear explanation for the discrepancy between the two priors for
the \textcite{li2015hiv} data, as the subset we analyzed formed a phylogenetic
cluster and thecrefore was a good candidate for the BA model. However, nearly
all the posterior density was assigned to $m = 1$ when this value was allowed,
indicating that the network was more likely to have an acyclic tree structure.

Our use of the \gls{BA} model makes several simplifying assumptions. First, we
assume homogeneity across the network with respect to node behaviour and
transmission risk. In reality, the attraction to high-degree nodes seems likely
to vary among individuals, as does their risk of transmitting or contracting
the virus. We have also assumed that all transmission risks are symmetric,
which is clearly false for all known modes of \gls{HIV} transmission, and that
infected individuals never recover but remain infectious indefinitely. These
assumptions were made for the purpose of keeping the model as simple as
possible, since this is the very first attempt to fit a contact network model
in a phylodynamic context. However, the Gillespie simulation algorithm built
into \software{netabc} can handle arbitrary transmission and removal rates
which need not be homogeneous across the network. Moreover, it is possible to
use kernel-\gls{ABC} to fit a model which relaxes some or all of these
assumptions, which may be a fruitful avenue for future investigation.
