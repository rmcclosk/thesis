<<setup, include=FALSE>>=
    source("global.R")
@

{\color{blue}\uline{
The chapter is organized as follows. One section is devoted to each of our
three research aims: the development of a method for inference of contact
network parameters from transmission trees} (\cref{sec:netabc}), \uline{the
investigation of the \acrlong{BA} network model using simulated data
}(\cref{sec:ba}), \uline{ and the application of the method to real-world
\gls{HIV} epidemics }(\cref{sec:hiv}). \uline{Each of these sections contains a
description of the methods used and, in the case of the latter two objectives,
the results of the experiments. The fourth and final section of the chapter
}(\cref{sec:disc}) \uline{contains a unified discussion of all three
objectives. }}

\section{\software{Netabc}: a computer program for estimation of contact
network parameters with kernel-assisted ABC}
\label{sec:netabc}

\software{Netabc} is a computer program to perform statistical inference of
contact network parameters from an estimated transmission tree using
\gls{ABC}. {\color{blue}\uline{As discussed in }\cref{sec:obj}, \uline{the principal
statistical algorithm used by \software{netabc} is adaptive
\gls{ABC}-\gls{SMC}~\autocite{del2012adaptive}. In addition, there are two
supplementary components which are specific to the domain of phylogenetics and
contact networks: Gillespie simulation~\autocite{gillespie1976general}, to
simulate transmission trees on contact networks; and the tree
kernel~\autocite{poon2013mapping}, which is used as the distance function in
\gls{ABC} to compare transmission trees~\autocite{poon2015phylodynamic}} (see
\cref{sec:abc}).} We give a high-level overview of the program here, before
describing these components in detail. \software{Netabc} takes as input an
estimated transmission tree, which can be derived from a viral phylogeny by
rooting and time-scaling as described in \cref{subsec:phylodynamics} or
estimated by other methods~\autocite{cottam2008integrating,
jombart2011reconstructing, ypma2012unravelling, morelli2012bayesian,
didelot2014bayesian, hall2015epidemic}. We variously refer to this estimated
transmission tree as the observed tree, input tree, or true tree.

As described in \cref{sec:smc}, \software{netabc} keeps track of a population
of particles $x^{(k)}$, each of which contains particular parameter values
$\theta^{(k)}$ for the {\color{blue}\uline{contact network}} model we are
trying to fit {\color{blue}\uline{to the input tree}}. A small number of
contact networks $z^{(k)}$ are generated under the model for each particle, in
accordance with that particle's parameters. An epidemic is simulated over each
of these networks using Gillespie simulation, and by keeping track of its
progress, a transmission tree is obtained. Thus, each particle becomes
associated with several simulated transmission trees. These trees are compared
to the input tree using the tree kernel. Particles are weighted according to
the similarity of their associated simulated trees with the true tree, with
more similar trees receiving higher weights. The particles are iteratively
perturbed to explore the parameter space, and particles with simulated trees
too distant from the true tree are periodically dropped and resampled. Once a
convergence criterion is attained, the final set of particles is used as a
Monte Carlo approximation to the target distribution of \gls{ABC}, which is
assumed to resemble the posterior distribution on model parameters (see
\cref{sec:abc}). A graphical schematic of this algorithm is given in
\cref{fig:abcsmc}.

\begin{figure}
    \includegraphics{abc-smc.pdf}
    \caption[Graphical schematic of the ABC-SMC algorithm implemented in \software{netabc}.]{
      Graphical schematic of the \gls{ABC}-\gls{SMC} algorithm implemented in
      \software{netabc}. Particles are initially drawn from their prior
      distributions, making the initial population a Monte Carlo approximation
      to the prior. At each iteration, particles are perturbed, and a distance
      threshold around the true tree contracts. Particles are rejected, and
      eventually resampled, when all their associated simulated trees lie
      outside the threshold. As the algorithm progresses, the population
      smoothly approaches a Monte Carlo approximation of the \gls{ABC} target
      distribution, which is assumed to resemble the posterior.
    }
    \label{fig:abcsmc}
\end{figure}

\software{Netabc} is written in the \software{C} programming language. The
\software{igraph} library~\autocite{csardi2006igraph} is used to generate and
store contact networks and phylogenies. Judy arrays~\autocite{baskins2004judy}
are used for hash tables and dynamic programming matrices. The
\gls{GSL}~\autocite{gough2009gnu} is used to generate random draws from
probability distributions, and to perform the bisection step in the adaptive
\gls{ABC}-\gls{SMC} algorithm. Parallelization is implemented with \gls{POSIX}
threads~\autocite{barney2009posix}. In addition to the \software{netabc} binary
to perform kernel-assisted \gls{ABC}, we provide three additional stand-alone
utilities: \software{treekernel}, to calculate the tree kernel;
\software{nettree}, to simulate a transmission tree over a contact network; and
\software{treestat}, to compute various summary statistics of phylogenies. The
programs are freely available at \url{https://github.com/rmcclosk/netabc}.

To check that our implementation of Gillespie simulation was correct, we
reproduced Figure 1A of \textcite{leventhal2012inferring} (our
\cref{fig:leventhal}), which plots the unbalancedness of transmission trees
simulated over four network models at various levels of pathogen
transmissibility. Our implementation of adaptive \gls{ABC}-\gls{SMC} was tested
by applying it to the same mixture of Gaussians used by
\textcite{del2012adaptive} to demonstrate their method (originally used
by~\textcite{sisson2007sequential}). We were able to obtain a close
approximation to the function (see \cref{fig:smctest}), and attained the
stopping condition used by the authors in a comparable number of steps. To
check that the algorithm would converge to a bimodal distribution, we also
applied it to a mixture of two Gaussians with means $\pm$4 and variances 1. The
algorithm was able to recover both peaks (\cref{fig:smctest2}).

\subsection{Simulation of transmission trees over contact networks}
\label{subsec:nettree}

The simulation of epidemics, and the corresponding transmission trees, over
contact networks is performed in \software{netabc} using the Gillespie
simulation algorithm~\autocite{gillespie1976general}. This method has been
independently implemented and applied by several
authors~\autocite[\textit{e.g.}][]{o2011contact, robinson2013dynamics,
leventhal2012inferring, groendyke2011bayesian, villandre2016assessment}.
\textcite{groendyke2011bayesian} published their implementation as an
\software{R} package, but since the \gls{SMC} algorithm is quite
computationally intensive, we chose to implement our own version in
\software{C}.

Let $G = (V, E)$ be a directed contact network. We assume the individual nodes
and edges of $G$ follow the dynamics of the \gls{SIR}
model~\autocite{kermack1927contribution}. Each directed edge $e = (u, v)$ in
the network is associated with a transmission rate $\beta_e$, which indicates
that, once $u$ becomes infected, the waiting time until $u$ infects $v$ is
distributed as $\Exponential(\beta_e)$. Note that $v$ may become infected
before this time has elapsed, if $v$ has other incoming edges. $v$ also has a
removal rate $\gamma_v$, so that the waiting time until removal of $v$ from the
population is $\Exponential(\gamma_v)$. Removal may correspond to death or
recovery with immunity, or a combination of both, but in our implementation
recovered nodes never re-enter the susceptible population. We define a
\defn{discordant edge} as an edge $(u, v)$ where $u$ is infected and $v$ has
never been infected.

To describe the algorithm, we introduce some notation and variables. Let
$\inc(v)$ be the set of incoming edges to $v$, and $\out(v)$ be the set of
outgoing edges from $v$. Let $I$ be the set of infected nodes in the network,
$R$ be the set of removed nodes, and $S$ be the remaining susceptible nodes,
and $D$ be the set of discordant edges in the network. Let $\beta$ be the total
transmission rate over all discordant edges, and $\gamma$ be the total removal
rate of all infected nodes,
\[
  \beta = \sum_{e \in D} \beta_e, \quad
  \gamma = \sum_{v \in I} \gamma_v.
\]
The variables $S$, $I$, $R$, $D$, $\beta$, and $\gamma$ are all updated as the
simulation progresses. When a node $v$ becomes infected, it is deleted from $S$
and added to $I$. Any formerly discordant edges in $\inc(v)$ are deleted from
$D$, and edges in $\out(v)$ to nodes in $S$ are added to $D$. If $v$ is later
removed, it is deleted from $I$ and added to $R$, and any discordant edges in
$\out(v)$ are deleted from $D$. At the time of either infection or removal, the
variables $\beta$ and $\gamma$ are updated to reflect the changes in the
network. Since these updates are straightforward, we do not write them
explicitly in the algorithm.

\newcommand{\tip}{\mathit{tip}}

The Gillespie simulation algorithm is given as Algorithm~\ref{alg:nettree}. The
transmission tree $T$ is simulated along with the epidemic. We keep a map
called $\tip$, which maps infected nodes in $I$ to the tips of $T$. The
simulation continues until either there are no discordant edges left in the
network, or we reach a user-defined cutoff of time ($t_{\max}$) or number of
infections ($I_{\max}$). We use the notation $\Uniform(0, 1)$ to indicate a
number drawn from a uniform distribution on $(0, 1)$, and likewise for
$\Exponential(\lambda)$. The combined number of internal nodes and tips in $T$
is denoted $|T|$.

\begin{algorithm}
  \label{alg:nettree}
  \caption{Simulation of an epidemic and transmission tree over a contact network}
  \begin{algorithmic}
    \State infect a node $v$ at random, updating $S$, $I$, $D$, $\beta$ and $\gamma$
    \State $T \gets$ a single node with label $1$
    \State $\tip[v] \gets 1$
    \State $t \gets 0$
    \While{$D \neq \emptyset$ and $|I| + |R| < I_{\max}$ and $t < t_{\max}$}
      \State $s \gets \min(t_{\max} - t, \Exponential(\beta + \gamma))$
      \For{$v \in \tip$}
        \State{extend the branch length of $\tip[v]$ by $s$}
      \EndFor
      \State $t \gets t + s$
      \If{$t < t_{\max}$}
        \If{$\Uniform(0, \beta + \gamma) < \beta$}
          \State choose an edge $e = (u, v)$ from $D$ with probability $\beta_e / \beta$
                 and infect $v$
          \State add tips with labels $(|T|+1)$ and $(|T|+2)$ to $T$
          \State connect the new nodes to $\tip[v]$ in $T$, with branch lengths $0$
          \State $\tip[v] \gets |T|-1$
          \State $\tip[u] \gets |T|$
        \Else
          \State choose a node $v$ from $I$ with probability $\gamma_v / \gamma$
                 and remove $v$
          \State delete $v$ from $\tip$
        \EndIf
        \State update $S$, $I$, $R$, $D$, $\beta$, and $\gamma$
      \EndIf
    \EndWhile
  \end{algorithmic}
\end{algorithm}

\subsection{Phylogenetic kernel}

The tree kernel developed by \textcite{poon2013mapping} provides a
comprehensive similarity score between two phylogenetic trees, via the
dot-product of the two trees' feature vectors in the infinite-dimensional space
of all possible subset trees with branch lengths (see \cref{subsec:treeshape}).
The kernel was implemented using the fast algorithm developed by
\textcite{moschitti2006making}. First, the production rule of each node, which
is the total number of children and the number of leaf children, is recorded.
The nodes of both trees are ordered by production rule, and a list of pairs of
nodes sharing the same production rule is created. These are the nodes for
which the value of the tree kernel must be computed - all other pairs have a
value of zero. The pairs to be compared are then re-ordered so that the child
nodes are always evaluated before their parents. Due to its recursive
definition, ordering the pairs in this way allows the tree kernel to be
computed by dynamic programming. The complexity of this implementation is
$O(|T_1||T_2|)$, where $|T|$ counts the number of nodes in the tree $T$.

The tree kernel cannot be used directly as a distance measure for \gls{ABC},
since it is maximized, not minimized, when the two trees being compared are the
same. Therefore, we defined the distance between two trees as
\[
  \rho(T_1, T_2) = 1 - \frac{K(T_1, T_2)}{\sqrt{K(T_1, T_1) K(T_2, T_2)}},
\]
which is a number between 0 and 1 minimized when $T_1 = T_2$. This is similar
to the normalization used by \textcite{collins2002new, poon2013mapping}.

\subsection{Adaptive sequential Monte Carlo for Approximate Bayesian computation}
\label{subsec:adaptsmc}

We implemented the adaptive \gls{SMC} algorithm for \gls{ABC} developed by
\textcite{del2012adaptive}. This algorithm is similar to the reference
\gls{ABC}-\gls{SMC} algorithm described in \cref{subsec:abcalg}, except that
the sequence of tolerances $\varepsilon_i$ is automatically determined rather
than specified in advance. The tolerances are chosen such that the \gls{ESS} of
the particle population, which indicates the quality of the Monte Carlo
approximation (see \cref{subsec:sis}), decays at a controlled rate. A
sudden precipitous drop in \gls{ESS} would indicate that only a small number of
particles had non-zero importance weights, which would result in a very poor
Monte Carlo approximation to the target distribution. This situation is
referred to as the ``collapse'' of the approximation, and is mitigated by the
adaptive approach. A single parameter $\alpha$ (not to be confused with the
\gls{BA} model parameter) controls the decay rate, with $\varepsilon_i$ being
chosen to satisfy
\[
  \ESS(w_i) = \alpha \ESS(w_{i-1}).
\]
Here, $w_i$ is the vector of weights at the $i$th step. Note that, since $w_i$
depends on $\varepsilon_i$, this equation solves for the updated weights and
the updated tolerance simultaneously. As pointed out by
\textcite{del2012adaptive}, the equation has no analytic solution, but can be
solved numerically by bisection. The forward kernels $K_i$ are taken to be
\gls{MCMC} kernels with stationary distributions $\pi_{\varepsilon_i}$ and
proposal distributions
\[
  q_i(\theta, \theta') \prod_{k=1}^M \Pr(z_i^{(k)'} \mid \theta'),
\]
where $\theta$ is the vector of model parameters and $z_k$ are $M$ datasets
simulated according to $\theta'$. In our implementation, $q$ is either a
Gaussian proposal for continuous parameters, or a Poisson proposal for discrete
parameters. For the Poisson proposals, the number of steps to move the particle
is drawn from a Poisson distribution, and the direction in which to move the
particle is chosen uniformly at random. For both proposals, the variance was
set equal to twice the empirical variance of the particles,
following~\autocite{beaumont2009adaptive, del2012adaptive}. The backwards
kernels are
\[
  L_{i-1}(x', x) = \frac{\pi_n(x)K(x, x')}{\pi_n(x')}.
\]
When substituted into \cref{eq:smcwt}, the forward kernels $K(x, x')$ and
densities $\pi_n(x') = \pi_{\varepsilon_n}(x')$ cancel out, and we are left
with the weight update 
\begin{align*}
  w_i(x) 
    &\propto w_{i-1}(x) \frac{\pi_n(x \mid y)}{\pi_{i-1}(x \mid y)} \\
    &= w_{i-1}(x) \frac{\pi(x) \pi_i(y \mid x)}{\pi(x) \pi_{i-1}(y \mid x)} \\
    &= w_{i-1}(x) \frac{\sum_{k=i}^M \I_{A_{\varepsilon_i, y}}(z_k)}
            {\sum_{k=i}^M \I_{A_{\varepsilon_{i-1}, y}}(z_k)}.
\end{align*}
In other words, when the distance threshold $\varepsilon_{i-1}$ is contracted
to $\varepsilon_i$, the particles' weights are multiplied by the proportion of
simulated datasets which are still inside the new threshold. The algorithm may
be stopped when one of two termination conditions is reached. The user may
specify a final tolerance $\varepsilon$, or a final acceptance rate of the
\gls{MCMC} kernel. The latter condition stops the algorithm when the particles
are not moving around very much, implying little change in the estimated
target.

\section{Analysis of \acrlong{BA} model with synthetic data}
\label{sec:ba}

\subsection{Methods}
\glsreset{BA}

{\color{blue}\uline{Using synthetic data,}} we investigated four parameters
related to the \gls{BA} contact network model, denoted \gls{N}, \gls{m},
\gls{alpha}, \gls{I} (see \cref{subsec:pa}). The first three of these are
parameters of the model itself, while \gls{I} is related to the simulation of
transmission trees over the network. However, we will refer to all four as
\gls{BA} parameters. \gls{N} denotes the total number of nodes in the network,
or equivalently, susceptible individuals in the population. When a node is
added to the network, \gls{m} new undirected edges are added incident to it,
and are attached to existing nodes of degree $k$ with probability proportional
to $k^\alpha + 1$ (\cref{subsec:pa}). To simulate transmission trees over a
\gls{BA} network, we allowed an epidemic to spread until \gls{I} nodes were
infected, and sampled a transmission tree at that time. The \gls{alpha}
parameter is unitless, while \gls{m} has units of edges or connections per
vertex, and \gls{N} and \gls{I} both have units of nodes or individuals.

{\color{blue}\uline{Our investigation comprised three sets of computational
experiments aimed at determining which of these parameters could be estimated
from phylogenetic data, and with what degree of accuracy. First, we performed
an exploratory analysis using a tree kernel-based classifier to determine which
of the four \gls{BA} parameters might be identifiable from tree shapes when all
others were held fixed. This analysis was also used to validate our choice of
the tree kernel as a distance function for \gls{ABC}, by evaluating two further
classifiers based on other tree summary statistics from the literature. Second,
we used grid search to investigate the accuracy and precision of marginal
parameter estimates, again holding all but one parameters of the model fixed.
Finally, we applied the full \gls{ABC}-\gls{SMC} algorithm to jointly estimate
the four parameters of the \gls{BA} model simultaneously.}}

We assumed that all contacts had symmetric transmission risk, which was
implemented by replacing each undirected edge in the network with two directed
edges (one in each direction). Nodes in our networks followed simple \gls{SI}
dynamics, meaning that they became infected at a rate proportional to their
number of infected neighbours, and never recovered. We did not consider the
time scale of the transmission trees in these simulations, only their shape.
Therefore, the transmission rate along each edge in the network was set to 1,
the removal rate of each node was set to 0, and all transmission trees' branch
lengths were scaled by their mean. \textit{igraph} library's implementation of
the BA model~\autocite{csardi2006igraph} was used to generate the graphs. The
analyses were run on Westgrid (\url{https://www.westgrid.ca/}) and a local
computer cluster. With the exception of our own programs, all analyses were
done in \software{R}, and all packages listed below are \software{R} packages.
{\color{blue}\uline{Code to run all simulation-based experiments is freely
available at \url{https://github.com/rmcclosk/thesis}.}}

\subsubsection*{Classifiers for BA model parameters based on tree shape}
\label{subsec:kernel}

\glsreset{nltt}

{\color{blue}\uline{
Our first computational experiment was designed as an exploratory analysis of
the four \gls{BA} model parameters defined above: \gls{alpha}, \gls{I},
\gls{m}, and \gls{N}. The objective of this experiment was to determine whether
any of the four parameters might be identifiable from the shape of the
transmission tree. TODO }

\uline{In addition, a secondary objective of this section was to validate the
use of the tree kernel as a distance measure for \gls{ABC} in our context. As
discussed in} \cref{sec:abc}, \uline{the choice of distance function is
extremely important for the accuracy of the \gls{ABC} approximation to the
posterior. Therefore, we evaluated two additional tree statistics in the same
manner as we evaluated the tree kernel (that is, by constructing and testing a
classifier). First, we considered Sackin's index~\autocite{shao1990tree}, which
measures the degree of unbalancedeness or asymmetry in a phylogeny} (see
\cref{subsec:treeshape}). \uline{Sackin's index is widely used for
characterizing phylogenies~\autocite{frost2013modelling} and has been
demonstrated to vary between transmission trees simulated under different
contact network types~\autocite{leventhal2012inferring}. Sackin's index does
not take branch lengths into account, considering only the tree's topology. The
other statistic we considered was the
\gls{nltt}~\autocite{janzen2015approximate}, which compares two trees based on
normalized distributions of their branching times} (see \cref{sec:treeshape}).
\uline{In contrast with Sackin's index, the \gls{nltt} does not explicity
consider the trees' topologies, but it does use their normalized branch
lengths. While the \gls{nltt} is a newly developed statistic not yet in
widespread use, the unnormalized \gls{ltt}~\autocite{nee1992tempo} was the
basis of seminal early work extracting epidemiological information from
phylodynamics~\autocite{holmes1995revealing}.}

\uline{We expect the tree kernel to classify the \gls{BA} parameters more
accurately than either Sackin's index or the \gls{nltt}, since the tree kernel
takes both topology and branch lengths into account. }}

This experiment involved a large number of variables which were varied
combinatorially. For ease of exposition, we will describe a single experiment
first, then enumerate the values of all variables for which the experiment was
repeated. The parameters of the tree kernel, $\lambda$ and $\sigma$
(\cref{subsec:treeshape}) will be referred to as \defn{meta-parameters} to
distinguish them from the parameters of the \gls{BA} model. 

The attachment power parameter \gls{alpha} was varied among three values: 0.5,
1.0, and 1.5. For each value, the \software{sample\_pa} function in the
\software{igraph} package was used to simulate 100 networks, with the other
parameters set to \gls{N} = 5000 and \gls{m} = 2. This step yielded a total of
300 networks. An epidemic was simulated on each network using our
\software{nettree} binary until \gls{I} = 1000 nodes were infected, at which
point 500 of them were sampled to form a transmission tree. A total of 300
transmission trees were thus obtained, comprised of 100 trees for each of the
three values of \gls{alpha}. The trees were ``ladderized'' so that the subtree
descending from the left child of each node was not smaller than that
descending from the right child. Summary statistics, such as Sackin's index and
the ratio of internal to terminal branch lengths, were computed for each
simulated tree using our \software{treestat} binary. The trees were visualized
using the \software{ape} package~\autocite{paradis2004ape}. Our
\software{treekernel} binary was used to calculate the value of the kernel for
each pair of trees, with the meta-parameters set to $\lambda = 0.3$ and $\sigma
= 4$. These values were stored in a symmetric 300 $\times$ 300 kernel matrix.
Similarly, we computed the \gls{nltt} statistic between each pair of trees
using our \software{treestat} binary, and stored them in a second $300 \times
300$ matrix.

To investigate the identifiability of \gls{alpha} from tree shape, we
constructed classifiers for \gls{alpha} based on the three tree shape
statistics discussed above. First, we used the \software{kernlab}
package~\autocite{zeileis2004kernlab} to create a \gls{kSVR} classifier using
the computed kernel matrix. Second, we used the \software{e1071}
package~\autocite{meyer2015e1071} to create an ordinary \gls{SVR} classifier
using the pairwise \gls{nltt} matrix. Finally, we performed an ordinary linear
regression of \gls{alpha} against Sackin's index. Each of these classifiers was
evaluated with 1000 two-fold cross-validations. We also performed a \gls{kPCA}
projection of the kernel matrix, and used it to visualize the separation of the
different \gls{alpha} values in the tree kernel's feature space. A schematic of
this experiment is presented in \cref{fig:kernelexpt}.

Similar experiments were performed with the values shown in
\cref{tab:kernelexpt}. The other three \gls{BA} parameters, namely \gls{N},
\gls{m}, and \gls{I}, were each varied while holding the others fixed. The
experiments for \gls{alpha}, \gls{m}, and \gls{N} were repeated with three
different values of \gls{I}. All experiments were repeated with trees having
three different numbers of tips. Kernel matrices were computed for all pairs of
the meta-parameters \gls{lambda} = \sett{0.2, 0.3, 0.4} and \gls{sigma} =
\sett{\nicefrac18, \nicefrac14, \nicefrac12, 1, 2, 4, 8}.

\begin{landscape}
\begin{table}[ht]
  \centering
  \input{\tablepath/kernel-expt}
  \caption[Variables used in tree kernel simulation experiments]
  {
    Values of parameters and other variables used in tree kernel simulation
    experiments. Each row corresponds to one of the \gls{BA} model parameters.
    One kernel matrix was created for every combination of values except the
    one indicated in the ``varied parameter'' column, which was varied when
    producing simulated trees.
  }
  \label{tab:kernelexpt}
\end{table}

\begin{table}[ht]
  \centering
  \input{\tablepath/gridsearch-expt}
  \caption[Variables used in grid search experiments]
  {
    Variables and \gls{BA} parameter values used for grid search experiments. 
    Trees were simulated under the test values, and compared to a grid of trees
    simulated under the grid values. Kernel scores were used to calculate point
    estimates and credible intervals for the test values.
  }
  \label{tab:gridexpt}
\end{table}
\end{landscape}

\begin{figure}[ht]
  \centering
  \includegraphics{kernel-expt.pdf}
  \caption[Schematic of experiments investigating impact of BA model parameters
           on tree shape.]{
    Schematic of experiments designed to investigate the impact of variations
    in BA model parameters on transmission tree shapes. The parameters of the
    BA model were varied one at a time {\color{blue}\uline{while holding all
    others fixed}}. Transmission trees were simulated under three different
    values of each parameter, then compared pairwise using the tree kernel.
    Classifiers were constructed for each parameter, and their accuracy was
    evaluated by cross-validation. Kernel-PCA projections were used to visually
    examine the separation of the trees in the feature space defined by the
    tree kernel.
  }
  \label{fig:kernelexpt}
\end{figure}

\subsubsection*{Grid search}

{\color{blue}\uline{The previous experiment was an exploratory analysis
intended to determine which of the \gls{BA} parameters were identifiable, and
whether the tree kernel could potentially be used to distinguish different
parameter values when all others were held fixed. In this experiment, which was
still of an exploratory nature, we continued to consider one parameter at a
time while fixing the other three. However, rather than checking for
identifiability, we were now interested in quantifying the accuracy and
precision of kernel score-based estimates. This was done by examining the
distribution of kernel scores on a grid of parameter values, when trees
simulated according to those values were compared with a single simulated test
tree. This experiment did not involve the full \gls{ABC}-\gls{SMC} algorithm,
nor did we continue to use Sackin's index or the \gls{nltt}.}}

As in the previous section, we will begin by describing a single experiment,
and then list the variables for which similar experiments were performed. We
varied \gls{alpha} along a narrowly spaced grid of values: 0, 0.01, \ldots, 2.
For each value, fifteen networks were generated with \software{igraph}, and
transmission trees were simulated over each using \software{nettree}. These
trees will be referred to as ``grid trees''. Next, one further test tree was
simulated with the test value \gls{alpha} = 0. Both the grid trees and the test
tree had 500 tips, and were simulated with the other \gls{BA} parameters set to
{\color{blue}\uline{the known values}} $N$ = 5000, $m$ = 2, and $I$ = 1000. The
test tree was compared to each of the grid trees using the tree kernel, with
the meta-parameters set to $\lambda = 0.3$ and $\sigma = 4$, using the
\software{treekernel} binary. The median kernel score was calculated for each
grid value, and the scores were normalized such that the area under the curve
was equal to 1. {\color{red}\sout{The grid value with the highest median kernel
score was taken as the point estimate for the test value}}{\color{blue}\uline{
A point estimate for the test value was obtained by calculating the weighted
mean of the grid values with the kernel scores as weights}}, and a 95\%
credible interval was obtained using the \software{hpd} function in the
\software{TeachingDemos} package~\autocite{snow2013teachingdemos}.

Each experiment of the type just described was repeated ten times with the same
test value. Similar experiments were performed for each of the four \gls{BA}
parameters, with several test values and trees of varying sizes. The variables
are listed in \cref{tab:gridexpt}. A graphical schematic of the grid search
experiments is shown in \cref{fig:gridexpt}. {\color{blue}\uline{We emphasize
that these experiments were marginal in nature; that is, the each parameter was
varied and estimated individually while holding the others at known, fixed
values.}}

%Spearman's correlation was used to test whether the number of tips in the tree
%was correlated with the acccuracy of the point estimates. One-way \gls{ANOVA}
%was used to test whether the accuracy of the point estimates were significantly
%higher for any parameter values. If so, the distribution of errors was examined
%to choose a suitable post hoc test. If there appeared to be a correlation
%between the parameter value and the accuracy of the estimate, Spearman's
%correlation was calculated. If there were one or more particular values which
%appeared to have lower error, we used the Wilcoxon rank-sum test.

\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth]{gridsearch-expt}
  \caption[Schematic of grid search experiment.]{
    Graphical schematic of grid search experiments used to investigate \gls{BA}
    model parameters. Trees were simulated along a narrowly spaced grid of
    values of one parameter (``grid trees'') {\color{blue}\uline{with all other
    parameters fixed to known values}}. Separate trees were simulated for a
    small subset of the grid values (``test trees''), {\color{blue}\uline{also
    holding the other parameters fixed}}. Each test tree was
    compared to every grid tree using the tree kernel, and the resulting kernel
    scores were normalized to resemble a probability density from which the
    mode and 95\% highest density interval were calculated.
  }
  \label{fig:gridexpt}
\end{figure}

\subsubsection*{Approximate Bayesian computation}

{\color{blue}\uline{
Our final simulation-based experiment was designed to test the full
\gls{ABC}-\gls{SMC} algorithm by jointly estimating the four parameters of the
\gls{BA} model. In contrast to the previous two experiments, we did not inform
the algorithm of any of the true parameter values.
}}

We simulated three trees each under a variety of parameter values, and ran the
\software{netabc} program to estimate posterior distributions for the
parameters. The parameter values and priors used are listed in
\cref{tab:abcexpt}. The tree kernel meta-parameters were set to $\lambda = 0.3$
and $\sigma = 4$. The \gls{SMC} algorithm was run with 1000 particles, five
sampled datasets per particle, and the $\alpha$ parameter (not to be confused
with the \gls{BA} preferential attachment parameter, see
\cref{subsec:adaptsmc}) set to 0.95. The algorithm was stopped when the
acceptance rate of the \gls{MH} kernel dropped below 1.5\%, the same criterion
used by \citeauthor{del2012adaptive}. Approximate marginal posterior densities
for each parameter were calculated using the \software{density} function in
\software{R} applied to the final weighted population of particles.
{\color{red}\sout{Credible intervals were obtained for each parameter using the
\software{HPDinterval} function in the \software{coda}
package~\autocite{plummer2006coda}.}} {\color{blue}\uline{Posterior means
obtained for each parameter using the \software{wtd.mean} function in the
\software{Hmisc} package~\autocite{harrell2016hmisc}. Credible intervals were
obtained using the \software{hpd} function in the \software{TeachingDemos}
package~\autocite{snow2013teachingdemos}.}}

\begin{table}[ht]
  \centering
  \input{\tablepath/abc-expt}
  \caption[Variables used in grid search experiments]
  {
    Variables and \gls{BA} parameter values used for \gls{ABC} validation
    experiments. Trees were simulated under the test values, and
    kernel-assisted \gls{ABC} was used to re-estimate posterior distributions for the
    \gls{BA} parameters without training.
  }
  \label{tab:abcexpt}
\end{table}

{\color{blue}\uline{
To evaluate the effects of the true parameter values on the accuracy of the
posterior mean estimates, we analysed each parameter individually using a
\gls{GLM} (four \glspl{GLM} total). The response variable was the error of the
point estimate, and the predictor variables were the true values of
\gls{alpha}, \gls{I}, and \gls{m}. We did not test for differences across true
values of \gls{N}, because \gls{N} was not varied in these simulations. The
distribution family and link function for each \gls{GLM} were chosen by
examination of residual plots and \gls{AIC}. For \gls{alpha}, \gls{I}, and
\gls{N}, we used the Gaussian distribution with the inverse link function. For
\gls{m}, we used the Poisson distribution with the log link function. The
$p$-values of the estimated \glspl{GLM} coefficients were corrected using
Holm-Bonferroni correction~\autocite{holm1979simple} with $n = 12$ (four
\glspl{GLM} with three predictors each). }}

%\subsubsection*{Characterization of power-law exponent in Barab\'asi-Albert networks}
%
%Most studies of social network or transmission network
%parameters~\autocite[e.g.][]{liljeros2001web, jones2003assessment,
%schneeberger2004scale, brown2011transmission} report the coefficient
%\gls{gamma} of the power law degree distribution. To make our results
%comparable to previous work, we used simulated networks to investigate the
%relationship between the \gls{BA} model parameters and \gls{gamma}. A network
%was simulated for each combination of parameters listed in
%\cref{tab:gammaexpt}. A power law distribution was fitted to the degree
%distribution of each simulated network using the \software{fit\_power\_law}
%function in \software{igraph} with the `R.mle' implementation. We fitted a
%\gls{GLM} with Gamma-distributed errors and a log link function to the observed
%distribution of \gls{gamma} values, with \gls{alpha}, \gls{m}, \gls{N}, and all
%possible interaction terms as predictors.
%
%\begin{table}
%  \centering
%  \input{\tablepath/gamma-expt}
%  \caption[\gls{BA} parameters used as input \gls{GLM} predicting $\gamma$]
%  {
%    \gls{BA} model parameters used as input to \gls{GLM} predicting power law
%    exponent $\gamma$. One network was simulated with each combination of
%    parameters, and $\gamma$ was calculated for each network. A \gls{GLM} with
%    Gamma-distributed errors and a log link function was fit to the $\gamma$
%    values with all parameters and interaction terms as predictors.
%  }
%  \label{tab:gammaexpt}
%\end{table}

Two further experiments were performed to address potential sources of error.
To evaluate the effect of model misspecification in the case of heterogeneity
among nodes, we generated a network where half the nodes were attached with
power $\alpha$ = 0.5, and the other half with power $\alpha$ = 1.5. The other
parameters for this network were $N$ = 5000, $I$ = 1000, and $m$ = 2. To
investigate the effects of potential sampling
bias~\autocite{karcher2016quantifying}, we simulated a transmission tree where
the tips were sampled in a peer-driven fashion, rather than at random. That is,
the probability to sample a node was twice as high if any of that node's
network peers had already been sampled. The parameters of this network were $N$
= 5000, $I$ = 2000, $m$ = 2, and $\alpha$ = 0.5.

\subsection{Results}

\subsubsection*{Classifiers for BA model parameters based on tree shape}

<<treestats, include=FALSE>>=
    params <- c("alpha", "I", "m", "N")

    get.treestats <- function (param) {
        stats <- paste0("../../simulations/kernel-", param, "/statistics/*")
        d <- collect.data(stats)
        trees <- paste0("../../simulations/kernel-", param, "/tree/*")
        m <- collect.metadata(trees)
        rownames(m) <- sub("../../simulations/", "", rownames(m))
        d <- merge(d, m, by=0, suffixes=c("", ".1"))
        if (param == "alpha") {
            d <- subset(d, m == 2)
            colnames(d)[colnames(d) == "nsimnode"] <- "I"
        }
        setDT(d)
    }
    
    alpha.stats <- get.treestats("alpha")
    I.stats <- get.treestats("I")
    m.stats <- get.treestats("m")
    N.stats <- get.treestats("N")

    alpha.sackin.cor <- alpha.stats[,cor.test(alpha, sackin, method="spearman")]
    I.sackin.cor <- I.stats[,cor.test(I, sackin, method="spearman")]
    m.sackin.cor <- m.stats[,cor.test(m, sackin, method="spearman")]
    N.sackin.cor <- N.stats[,cor.test(N, sackin, method="spearman")]
    stopifnot(alpha.sackin.cor$p.value < 0.05)
    stopifnot(I.sackin.cor$p.value < 0.05)
    stopifnot(m.sackin.cor$p.value < 0.05)
    stopifnot(N.sackin.cor$p.value < 0.05)

    alpha.ratio.cor <- alpha.stats[,cor.test(int.tip.ratio, alpha)]
    I.ratio.cor <- I.stats[,cor.test(int.tip.ratio, I)]
    m.ratio.cor <- m.stats[,cor.test(int.tip.ratio, m)]
    N.ratio.cor <- N.stats[,cor.test(int.tip.ratio, N)]
    stopifnot(alpha.ratio.cor$p.value < 1e-5)
    stopifnot(I.ratio.cor$p.value < 1e-5)
    stopifnot(m.ratio.cor$p.value < 1e-5)
    stopifnot(N.ratio.cor$p.value < 1e-5)
@

Trees simulated under different values of \gls{alpha} were visibly quite
distinct (\cref{fig:alphatrees}). In particular, higher values of \gls{alpha}
produce networks with a small number of highly connected nodes which, once
infected, are likely to transmit to many other nodes. This results in a more
unbalanced, ladder-like structure in the phylogeny, compared to networks with
lower \gls{alpha} values. None of the other three parameters produced trees
which were as easily distinguished from each other
(\cref{fig:Itrees,fig:mtrees,fig:Ntrees,fig:Itrees}).  Sackin's index, which
measures tree imbalance, was significantly correlated with all four parameters
    (for $\alpha$, $I$, $m$, and $N$ respectively: Spearman's rho =
     \Sexpr{round(alpha.sackin.cor$estimate, 2)},
     \Sexpr{round(I.sackin.cor$estimate, 2)},
     \Sexpr{round(m.sackin.cor$estimate, 2)},
     \Sexpr{round(N.sackin.cor$estimate, 2)};
     $p$-values
     $\Sexpr{pp(alpha.sackin.cor$p.value)}$,
     $\Sexpr{pp(I.sackin.cor$p.value)}$,
     $\Sexpr{pp(m.sackin.cor$p.value)}$,
     $\Sexpr{pp(N.sackin.cor$p.value)}$).
The ratio of internal to terminal branch lengths was negatively correlated with
\gls{alpha} and \gls{I}, and positively correlated with \gls{m} and \gls{N}
  (Spearman's rho
    \Sexpr{round(alpha.ratio.cor$estimate, 2)},
    \Sexpr{round(I.ratio.cor$estimate, 2)},
    \Sexpr{round(m.ratio.cor$estimate, 2)},
    \Sexpr{round(N.ratio.cor$estimate, 2)};
  all $p < 10^{-5}$).

\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth]{kernel-alpha-tree.pdf}
  \caption[Simulated transmission trees under three different values of BA parameter $\alpha$]{
    Simulated transmission trees under three different values of BA parameter
    $\alpha$. Epidemics were simulated on \gls{BA} networks of 5000 nodes, with
    \gls{alpha} equal to 0.5, 1.0, or 1.5, until 1000 individuals were
    infected. Transmission trees were created by sampling 500 infected nodes.
    Higher \gls{alpha} values produced networks with a small number of
    highly-connected nodes, resulting in highly unbalanced, ladder-like trees.
  }
  \label{fig:alphatrees}
\end{figure}

\Cref{fig:kpca} shows \gls{kPCA} projections of the simulated trees onto the
first two principal components of the kernel matrix. The figure shows only the
simulations with 500-tip trees and 1000 infected nodes. The three \gls{alpha}
and \gls{I} values considered are well separated from each other in feature
space. On the other hand, the three \gls{N} values overlap significantly, and
the three \gls{m} values are virtually indistinguishable. Similar observations
can be made for other values of \gls{I} and the number of tips
(\cref{fig:alphakpca,fig:Nkpca,fig:Ikpca,fig:mkpca}). The values of \gls{I} and
\gls{N} separated more clearly with larger numbers of tips, and in the case of
\gls{N}, larger epidemic sizes.

\begin{figure}[ht]
  \centering
  \includegraphics{kernel-kpca.pdf}
  \caption[Kernel-PCA projections of simulated trees under varying BA
           parameter values.]{
    Each parameter of the \gls{BA} model was individually varied to produce 300
    simulated trees. Kernel matrices were formed from all pairwise kernel
    scores among each set of 300 trees. The trees were projected onto the first
    two principal components of the kernel matrix calculated using \gls{kPCA}.
    All trees had 500 tips. The parameters not being varied were set to
    \gls{alpha} = 1, \gls{I} = 1000, \gls{m} = 2, and \gls{N} = 5000. The tree
    kernel meta-parameters were $\lambda = 0.3$ and $\sigma = 4$.
  }
  \label{fig:kpca}
\end{figure}

<<classifiers, include=FALSE>>=
    get.kernel.data <- function (param, step) {
        md <- collect.metadata(paste0('../../simulations/kernel-', param, '/', step, '/*'))
        if ('rbf_variance' %in% colnames(md)) {
          md <- subset(md, rbf_variance == 4 & decay_factor == 0.3)
        }
        if (param == 'alpha') {
            md <- subset(md, m == 2)
        }
        d <- setDT(collect.data(rownames(md)))
        if (param %in% c('alpha', 'm')) {
            d[,list(rsquared=mean(rsquared)), by=c('nsimnode', 'ntip')]
        } else if (param == 'I') {
            d[,list(rsquared=mean(rsquared)), by=ntip]
        } else {
            d[,list(rsquared=mean(rsquared)), by=c('I', 'ntip')]
        }
    }
    kernel.alpha <- get.kernel.data('alpha' ,'classifier')
    kernel.m <- get.kernel.data('m', 'classifier')
    kernel.I <- get.kernel.data('I', 'classifier')
    kernel.N <- get.kernel.data('N', 'classifier')

    sackin.alpha <- get.kernel.data('alpha', 'stats-classifier')
    sackin.m <- get.kernel.data('m', 'stats-classifier')
    sackin.I <- get.kernel.data('I', 'stats-classifier')
    sackin.N <- get.kernel.data('N', 'stats-classifier')

    nltt.alpha <- get.kernel.data('alpha', 'nltt-classifier')
    nltt.m <- get.kernel.data('m', 'nltt-classifier')
    nltt.I <- get.kernel.data('I', 'nltt-classifier')
    nltt.N <- get.kernel.data('N', 'nltt-classifier')
@

Accuracy of the \gls{kSVR} classifiers varied based on the parameter being
tested (\cref{fig:rsquared}, left). Classifiers based on two other tree
statistics, the \gls{nltt} and Sackin's index, generally exhibited worse
performance than the tree kernel, although the magnitude of the disparity
varied between the parameters (\cref{fig:rsquared}, centre and right). The
results were largely robust to variations in the tree kernel meta-parameters
$\lambda$ and $\sigma$, although accuracy varied between different epidemic and
sampling scenarios
(\cref{fig:alphacrossv,fig:mcrossv,fig:Icrossv,fig:Ncrossv}).

When classifying $\alpha$, the \gls{kSVR} classifier had an average $R^2$ of 
    \Sexpr{kernel.alpha[,round(mean(rsquared), 2)]},
compared to 
    \Sexpr{nltt.alpha[,round(mean(rsquared), 2)]}
for the \gls{nltt}-based SVR, and
    \Sexpr{sackin.alpha[,round(mean(rsquared), 2)]}
for the linear regression against Sackin's index. There was little variation
about the mean for different tree and epidemic sizes. No classifier could
accurately identify the $m$ parameter in any epidemic scenario, with average
$R^2$ values of 
  \Sexpr{kernel.m[,round(mean(rsquared), 2)]} for \gls{kSVR},
  \Sexpr{nltt.m[,round(mean(rsquared), 2)]} for the \gls{nltt}, and
  \Sexpr{sackin.m[,round(mean(rsquared), 2)]}
for Sackin's index. Again, there was little variation in accuracy between
epidemic scenarios, although the accuracy of the \gls{kSVR} was slightly higher
on 1000-tip trees 
    (average $R^2$ 
     \Sexpr{kernel.m[ntip == 100,round(mean(rsquared), 2)]},
     \Sexpr{kernel.m[ntip == 500,round(mean(rsquared), 2)]},
     \Sexpr{kernel.m[ntip == 1000,round(mean(rsquared), 2)]}
     for 100, 500, and 1000 tips respectively).

The accuracy of classifiers $I$ varied significantly with the number of tips in
the tree. For 100-tip trees, the average $R^2$ values were
  \Sexpr{kernel.I[ntip == 100, round(mean(rsquared), 2)]},
  \Sexpr{nltt.I[ntip == 100, round(mean(rsquared), 2)]}, and
  \Sexpr{sackin.I[ntip == 100, round(mean(rsquared), 2)]}
for the tree kernel, \gls{nltt}, and Sackin's index respectively. For 500-tip
trees, the values increased to
  \Sexpr{kernel.I[ntip == 500, round(mean(rsquared), 2)]},
  \Sexpr{nltt.I[ntip == 500, round(mean(rsquared), 2)]}, and
  \Sexpr{sackin.I[ntip == 500, round(mean(rsquared), 2)]}.
Finally, the performance of classifiers for $N$ depended heavily on the
epidemic scenario. The $R^2$ of the \gls{kSVR} classifier ranged from
  \Sexpr{kernel.N[,round(min(rsquared), 2)]}
for the smallest epidemic and smallest sample size, to
  \Sexpr{kernel.N[,round(max(rsquared), 2)]}
for the largest. Likewise, $R^2$ for the \gls{nltt}-based SVR ranged from 
  \Sexpr{nltt.N[,round(min(rsquared), 2)]}
to
  \Sexpr{nltt.N[,round(max(rsquared), 2)]}.
Sackin's index did not accurately classify $N$ in any scenario, with an average
$R^2$ of
  \Sexpr{sackin.N[,round(mean(rsquared), 2)]}
and little variation between scenarios.

\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth]{kernel-rsquared.pdf}
  \caption[Cross-validation accuracy of kernel-SVR, nLTT-based SVR, and
  Sackin's index regression classifiers for BA model parameters.]{
      Cross-validation accuracy of kernel-SVR classifier (left), SVR classifier
      using \gls{nltt} (centre), and linear regression using Sackin's index
      (right) for \gls{BA} model parameters. Kernel meta-parameters were set to
      $\lambda = 0.3$ and $\sigma = 4$. Each point was calculated based on 300
      simulated transmission trees over networks with three different values of
      the parameter being tested. Vertical lines are empirical 95\% confidence
      intervals based on 1000 two-fold cross-validations. {\color{blue}\uline{
      The classifiers for \gls{I} were not evaluated with 1000-tip trees,
      because one of the tested \gls{I} values was 500, and it is not possible
      to sample a tree of size 1000 from 500 infected individuals.}}
  }
  \label{fig:rsquared}
\end{figure}

\subsubsection*{Marginal parameter estimates with grid search}

<<gridsearch, include=FALSE>>=
    d <- setDT(collect.data("../../simulations/aggregates/gridsearch/*"))
    d[,error := abs(true_value - point.est)]
    setkey(d, parameter)

    # correlation between number of tips and error
    tip.cor <- d[,cor.test(error, tips, method="spearman")[c("p.value", "estimate")], by=parameter]
    setkey(tip.cor, parameter)
    stopifnot(tip.cor["alpha", p.value] < 0.05)
    stopifnot(tip.cor["I", p.value] < 0.05)
    stopifnot(tip.cor["N", p.value] < 0.05)
    stopifnot(tip.cor["m", p.value] > 0.05)

    # CI takes up >75% of grid
    stopifnot(d["alpha", all(upper.95 - lower.95 >= 0.75*2)])
    stopifnot(d["I", all(upper.95 - lower.95 >= 0.75*5000)])
    stopifnot(d["N", all(upper.95 - lower.95 >= 0.75*15000)])
    stopifnot(d["m", all(upper.95 - lower.95 >= 0.75*6)])

    # correlation between value and error
    av <- d[,list(p=summary(aov(error~factor(true_value)))[[1]][["Pr(>F)"]][1]),
            by=parameter]
    stopifnot(av["alpha", p] < 0.05)
    stopifnot(av["I", p] < 0.05)
    stopifnot(av["m", p] < 0.05)
    stopifnot(av["N", p] < 0.05)

    tests <- d[,list(rsquared=cor.test(true_value, point.est)$estimate^2,
                     rel.err=mean(abs(true_value - point.est) * 100 / diff(range(true_value))),
                     abs.err=mean(abs(true_value - point.est))),
                by=parameter]
    setkey(tests, parameter)

    alpha.test <- d["alpha", wilcox.test(.SD[true_value %in% c(1.0, 1.25),error], 
                                         .SD[!true_value %in% c(1.0, 1.25),error])]
    stopifnot(alpha.test$p.value < 0.05)

    I.test <- d["I", wilcox.test(.SD[true_value >= 2000 & true_value <= 3000, error], 
                                 .SD[true_value < 2000 | true_value > 3000, error])]
    stopifnot(I.test$p.value < 0.05)

    m.test <- d["m", wilcox.test(.SD[true_value == 1, error], 
                                 .SD[true_value > 1, error])]
    stopifnot(m.test$p.value < 0.05)

    N.test <- d["N", wilcox.test(.SD[true_value <= 3000, error], 
                                 .SD[true_value > 3000, error])]
    stopifnot(N.test$p.value < 0.05)

    value.cor <- d[,cor.test(error, true_value)[c("p.value", "estimate")], by=parameter]
    setkey(value.cor, parameter)
    stopifnot(value.cor["I", p.value] >= 0.05)
@

{\color{red}\sout{The accuracy of grid search estimates largely paralleled that
of the \gls{kSVR} classifiers.}}\Cref{fig:gridest} shows point estimates and
95\% highest density intervals for each of the \gls{BA} parameters, for one
replicate experiment with 500-tip trees. Plots showing the point estimates for
all replicates can be found in
\cref{fig:gridptalpha,fig:gridptI,fig:gridptm,fig:gridptN}. For all parameters
except $m$, the error of point estimates was negatively correlated with the
number of sampled tips in the tree (for \gls{alpha}, \gls{I}, and \gls{N}
respectively: Spearman's $\rho$ = \Sexpr{tip.cor["alpha", round(estimate, 2)]},
\Sexpr{tip.cor["I", round(estimate, 2)]}, \Sexpr{tip.cor["N", round(estimate,
2)]}; $p$-values
    $\Sexpr{tip.cor["alpha", pp(p.value)]}$,
    $\Sexpr{tip.cor["I", pp(p.value)]}$,
    $\Sexpr{tip.cor["N", pp(p.value)]}$).
The 95\% highest density intervals obtained for all parameters were extremely
wide, occupying $>$75\% of the grid in all cases (\cref{fig:gridest}).

{\color{blue}\uline{Similar to the results obtained in the previous experiment,
the \gls{alpha} and \gls{I} parameters were estimated with comparably high
accuracy, while the other two parameters were less identifiable. Across all
replicates, $R^2$ values for the correlations between the estimated and true
values were
    $\Sexpr{tests["alpha", round(rsquared, 2)]}$,
    $\Sexpr{tests["I", round(rsquared, 2)]}$,
    $\Sexpr{tests["m", round(rsquared, 2)]}$, and
    $\Sexpr{tests["N", round(rsquared, 2)]}$
for \gls{alpha}, \gls{I}, \gls{m}, and \gls{N} respectively. The mean absolute
errors of the point estimates were
    $\Sexpr{tests["alpha", round(abs.err, 2)]}$,
    $\Sexpr{tests["I", round(abs.err)]}$,
    $\Sexpr{tests["m", round(abs.err, 2)]}$, and
    $\Sexpr{tests["N", round(abs.err)]}$,
representing
    $\Sexpr{tests["alpha", round(rel.err)]}$\%,
    $\Sexpr{tests["I", round(rel.err)]}$\%,
    $\Sexpr{tests["m", round(rel.err)]}$\%, and
    $\Sexpr{tests["N", round(rel.err)]}$\%
of the respective grids.}

\uline{Qualitatively, three of the parameters (excluding \gls{N}) exhibited
weak identifiability within particular sections of the grid. The \glspl{IQR}
for \gls{alpha} were nearly identical for the values \gls{alpha} $\leq 1$,
spanning approximately [0-1.3]. Similarly, the \glspl{IQR} for \gls{alpha} $>
1$ were all approximately [0.7-2]} (\cref{fig:gridest}). \uline{The
distributions of kernel scores for these groups of values were also
qualitatively similar} (\cref{fig:gridalpha}), \uline{although the value
\gls{alpha} = 1.25 exhibited a more pronounced peak in kernel scores around the
true value.}

\uline{For \gls{I}, the \glspl{IQR} were nearly identical for the values
\gls{I} $\leq 2000$ (approximately [500,3800]), and for the values \gls{I} $>
3000$ (approximately [1600-5000]). Kernel score distributions for all \gls{I}
values exibited a similar rounded shape} (\cref{fig:gridI}), \uline{although
this was most pronounced for values near the upper and lower extremes of the
grid.}

\uline{The \glspl{IQR} for \gls{m} were distinct for \gls{m} = 1 and 2, but
were similar for all values of \gls{m} $> 2$ (approximately [2-6]). The kernel
score distribution for \gls{m} = 1 was distinct from the others, having a large
peak at \gls{m} = 1, while the others exhibited a valley at \gls{m} = 1 and
were mostly flat everywhere else} (\cref{fig:gridm}). 

\uline{The \glspl{IQR} for \gls{N} did not form any obvious groups like the
other parameters' \glspl{IQR}} (\cref{fig:gridest}). \uline{The kernel score
distribution for \gls{N} = 1000 was distinct, having a peak at the true value}
(\cref{fig:gridN}). \uline{The distributions for \gls{N} $> 1000$ were all
relatively similar, having a valley at the low end of the grid and being mostly 
flat everywhere else.}}

{\color{red}\sout{The \gls{alpha} parameter was the most accurately estimated,
with point estimates having an average deviation of 
    \Sexpr{d["alpha", round(mean(error), 2)]}
from the true value, on a grid from 0 to 2. The error of point estimates varied
significantly between true values of \gls{alpha}
    (one-way \gls{ANOVA}, $p$ $\Sexpr{pp(av["alpha", p], eq=TRUE)}$). In
particular, errors were lower for the values \gls{alpha} = 1.0 and 1.25 than
for the other values
    (average errors 
    \Sexpr{d["alpha", .SD[true_value %in% c(1.0, 1.25), round(mean(error), 2)]]}
    for \gls{alpha} = 1.0 or 1.5 vs.
    \Sexpr{d["alpha", .SD[!true_value %in% c(1.0, 1.25), round(mean(error), 2)]]}
    for \gls{alpha} $\neq$ 1.0 or 1.5),
and this difference was significant
    (Wilcoxon rank-sum test, $p \Sexpr{pp(alpha.test$p.value, eq=TRUE)}$,
}\cref{fig:gridptalpha}).
\sout{These two values exhibited different qualitative behaviour than the other
values in terms of the distribution of kernel scores along the grid
}(\cref{fig:gridalpha}). \sout{In particular, there was a pronounced peak in scores
around the true value, in contrast to the other values where the scores were
flat around the true value. The effect was most obvious for the value
\gls{alpha} = 1.25.}}

%The average absolute error of the point estimates for \gls{I} was 
%    \Sexpr{d["I", round(mean(error))]} individuals,
%on a grid of 500 to 5000, and these errors differed between true values of
%\gls{I}
%    (one-way \gls{ANOVA}, $p \Sexpr{pp(av["I", p], eq=TRUE)}$).
%The errors for $2000 \leq I \leq 3000$ were higher than those for the other
%values
%    (average errors
%     \Sexpr{d["I", .SD[true_value >= 2000 & true_value <= 3000, round(mean(error))]]}
%     for $2000 \leq I \leq 3000$ vs.
%     \Sexpr{d["I", .SD[true_value < 2000 | true_value > 3000, round(mean(error))]]}
%     for $I < 2000$ or $I > 3000$),
%and this difference was significant
%    (Wilcoxon rank-sum test, $p \Sexpr{pp(I.test$p.value, eq=TRUE)}$,
%     \cref{fig:gridptI}).
%Kernel score distributions for all test values exhibited a similar rounded
%shape (\cref{fig:gridI}). 
%
%The average error for \gls{m} was
%    \Sexpr{d["m", round(mean(error), 2)]} edges per vertex,
%on a grid from 1 to 6. The error varied significantly between the true values
%of \gls{m} 
%    (one-way \gls{ANOVA}, $p \Sexpr{pp(av["m", p], eq=TRUE)}$).
%Errors for the value \gls{m} = 1 were lower than the other values
%    (average errors
%    \Sexpr{d["m", .SD[true_value == 1, round(mean(error), 2)]]}
%    for $m = 1$ vs.
%    \Sexpr{d["m", .SD[true_value > 1, round(mean(error), 2)]]}
%    for $m > 1$),
%and this difference was significant
%    (Wilcoxon rank-sum test, $p \Sexpr{pp(m.test$p.value, eq=TRUE)}$,
%     \cref{fig:gridptm}).
%The value $m = 1$ causes the network to take on a distinct shape relative to
%higher \gls{m} values, namely a tree (\ie there are no cycles, see
%\cref{subsec:treeshape}). The kernel score distribution had a peak at $m = 1$
%when this was the true value, and a valley at $m = 1$ when the true value of
%$m$ was greater that 1 (\cref{fig:gridm}).
%
%The average error for \gls{N} was 
%    \Sexpr{d[parameter == "N", round(mean(error))]} individuals,
%on a grid from 1000 to 15000, and was varied significantly with the true value
%of \gls{N}
%    (one-way \gls{ANOVA}, $p \Sexpr{pp(av["N", p], eq=TRUE)}$).
%The errors were lower for $N \leq 3000$
%    (average errors
%     \Sexpr{d["N", .SD[true_value <= 3000, round(mean(error))]]}
%     for $N \leq 3000$ vs.
%     \Sexpr{d["N", .SD[true_value > 3000, round(mean(error))]]}
%     for $N > 3000$),
%and this difference was significant
%    (Wilcoxon rank-sum test, $p \Sexpr{pp(N.test$p.value, eq=TRUE)}$,
%     \cref{fig:gridptN}).
%The kernel score distribution had a peak at $N = 1000$ when this was the true
%value, and a valley there otherwise (\cref{fig:gridN}). Except for this valley,
%the distributions were flat for $N > 3000$.

\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth]{gridsearch-example}
  \caption[Grid search estimates of \gls{BA} model parameters.]{Point estimates
      (center lines) and 75\% (boxes) and 95\% (whiskers) highest density
      intervals for each \gls{BA} model parameter, obtained using grid search.
      Networks and transmission trees were simulated over a grid of values for
      each parameter while holding the others fixed. For a subset of the grid
      values ($x$-axis), test networks and trees were created and compared to
      each tree on the grid using the tree kernel. The kernel scores along the
      grid were normalized to resemble a probability distribution, from which
      the mode and highest density interval were calculated. Shown values
      correspond to one replicate experiment, with trees of size 500.
  } 
  \label{fig:gridest}
\end{figure}

\subsubsection*{Joint parameter estimates with kernel-assisted ABC}

<<point_est, include=FALSE>>=
    f <- Sys.glob("../../simulations/abc-pa-free-m/point-estimate/*")
    d <- fread(f)
    d[,m := floor(m)]
    d[,alpha_error := abs(true_alpha - alpha)]
    d[,N_error := abs(true_N - N)]
    d[,I_error := abs(true_I - I)]
    d[,m_error := abs(true_m - m)]

    alpha.av <- anova(lm(alpha_error ~ factor(true_alpha) + factor(true_m) + factor(true_I), d))
    m.av <- anova(lm(m_error ~ factor(true_alpha) + factor(true_m) + factor(true_I), d))
    N.av <- anova(lm(N_error ~ factor(true_alpha) + factor(true_m) + factor(true_I), d))
    I.av <- anova(lm(I_error ~ factor(true_alpha) + factor(true_m) + factor(true_I), d))

    m.tbl <- d[,prop.table(table(m_error))]
    zero.alpha.test <- wilcox.test(d[true_alpha == 0, alpha_error], 
                                   d[true_alpha != 0, alpha_error])
    alpha.I.test <- wilcox.test(d[true_alpha < 1, I_error],
                                d[true_alpha >= 1, I_error])
    I.I.test <- wilcox.test(d[true_I == 1000, I_error],
                            d[true_I == 2000, I_error])
    alpha.m.test <- wilcox.test(d[true_alpha == 0 | true_alpha == 1, m_error],
                                d[true_alpha == 0.5 | true_alpha == 1.5, m_error])
    #stopifnot(alpha.av["factor(true_m)", "Pr(>F)"] <= 0.05)
    #stopifnot(alpha.av["factor(true_I)", "Pr(>F)"] > 0.05)
    #stopifnot(I.I.test$p.value < 1e-5)
    #stopifnot(I.av["factor(true_m)", "Pr(>F)"] > 0.05)
    #stopifnot(m.av["factor(true_m)", "Pr(>F)"] > 0.05)
    #stopifnot(m.av["factor(true_I)", "Pr(>F)"] > 0.05)
    #stopifnot(m.av["factor(true_alpha)", "Pr(>F)"] > 0.05)
    #stopifnot(min(N.av[1:3,"Pr(>F)"]) > 0.05)

    # one-way ANOVAs
    stopifnot(anova(lm(alpha_error~true_m, d))[1, "Pr(>F)"] > 0.05)
    stopifnot(anova(lm(alpha_error~factor(true_I), d))[1, "Pr(>F)"] > 0.05)
    stopifnot(anova(lm(I_error~true_m, d))[1, "Pr(>F)"] > 0.05)
    stopifnot(anova(lm(m_error~factor(true_alpha), d))[1, "Pr(>F)"] > 0.05)
    stopifnot(anova(lm(m_error~factor(true_I), d))[1, "Pr(>F)"] > 0.05)

    stopifnot(anova(lm(N_error~factor(true_alpha), d))[1, "Pr(>F)"] > 0.05)
    stopifnot(anova(lm(N_error~factor(true_I), d))[1, "Pr(>F)"] > 0.05)
    stopifnot(anova(lm(N_error~true_m, d))[1, "Pr(>F)"] > 0.05)

    alpha.m.cor <- cor.test(d[,alpha_error], d[,true_m], method="spearman")
@

\Cref{fig:abcptm2} shows {\color{red}\sout{\gls{MAP}}}
{\color{blue}\uline{posterior mean}} point estimates of the BA model parameters
obtained with kernel-assisted ABC on simulated data. The estimates shown
correspond only to the simulations where the $m$ parameter was set to 2,
however the results for $m = 3$ and $m = 4$ were similar
(\cref{fig:abcptm3,fig:abcptm4}). Average boundaries of 95\% HPD intervals are
given in \cref{tab:abchpd}.

The accuracy of the parameter estimates obtained with kernel-assisted ABC
paralleled the results from the \gls{kSVR} classifier. Of the four parameters,
$\alpha$ was the most accurately estimated, with point estimates having a
median [IQR] absolute error of 
    \Sexpr{d[,round(median(alpha_error), 2)]} 
    [\Sexpr{d[,round(quantile(alpha_error, 0.25), 2)]} - 
    \Sexpr{d[,round(quantile(alpha_error, 0.75), 2)]}].
The errors when the true value of $\alpha$ was zero were significantly greater
than those for the other values 
    (Wilcoxon rank-sum test, $p$ = $\Sexpr{latexSN(round(zero.alpha.test$p.value, 4))}$).
Errors in estimating $\alpha$ 
%also varied with the true value of $m$ just at
%the threshold of statistical significance
%    (one-way ANOVA, $p 
%    \Sexpr{pp(anova(lm(alpha_error~true_m, d))[1, "Pr(>F)"], eq=TRUE)}$),
{\color{blue}\uline{did not vary across the true values of $m$ or $I$ (both
one-way ANOVA).}} 

Estimates for $I$ were relatively accurate, with point estimate errors of
    \Sexpr{d[,round(median(I_error))]} 
    [\Sexpr{d[,round(quantile(I_error, 0.25))]} - 
    \Sexpr{d[,round(quantile(I_error, 0.75))]}] individuals.
These errors were significantly higher when the true value of $\alpha$ was
at least 1
    (Wilcoxon rank-sum test, $p$ = $\Sexpr{latexSN(round(alpha.I.test$p.value, 4))}$)
and when the true value of $I$ was 2000 ($p < 10^{-5}$). The true value of $m$
did not affect the estimates of $I$ (one-way ANOVA).

The $m$ parameter was estimated correctly in
    \Sexpr{as.integer(m.tbl[1] * 100)} \%
of simulations {\color{red}\sout{barely better than random guessing}}.
{\color{blue}\uline{However this was due to the estimated value being $m = 3$
in the large majority of simulations (\Sexpr{d[,sum(m == 3)]} out of
\Sexpr{nrow(d)}), with one-third of the simulations having the true value $m =
3$.}} The true values of the other parameters did not significantly affect the
estimates of $m$ (both one-way ANOVA). 

Finally, the total number of nodes $N$ was consistently over-estimated by about
a factor of two (error \Sexpr{d[,round(median(N_error))]}
[\Sexpr{d[,round(quantile(N_error, 0.25))]} - \Sexpr{d[,round(quantile(N_error,
0.75))]}] individuals). No parameters influenced the accuracy of the $N$
estimates (all one-way ANOVA).

\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth]{abc-point-estimate-m2}
  \vspace{6pt}
  \caption[
    Posterior mean point estimates for \gls{BA} model parameters obtained by
    running \software{netabc} on simulated data, for simulations with \gls{m} =
    2.
  ]{
    Posterior mean point estimates for \gls{BA} model parameters obtained by
    running \software{netabc} on simulated data, for simulations with \gls{m} =
    2. Dashed lines indicate true values. (A) Estimates of \gls{alpha} and
    \gls{I} which were varied in these simulations against known values. (B)
    Estimates of \gls{m} and \gls{N} which were held fixed in these simulations
    at the values \gls{m} = 2 and \gls{N} = 5000.
  }
  \label{fig:abcptm2}
\end{figure}

\begin{table*}[ht]
  \centering
  \input{\tablepath/abc-hpd.tex}
  \caption[
      Average posterior mean point estimates and 95\% highest posterior density
      (HPD) interval widths for BA model parameter estimates obtained with
      kernel-assisted ABC.
  ]{
      Average posterior mean point estimates and 95\% highest posterior density
      (HPD) interval widths for BA model parameter estimates obtained with
      kernel-assisted ABC. Three transmission trees were simulated under each
      combination of the listed parameter values, and the parameters were
      estimated with kernel-assisted ABC without training.
  }
  \label{tab:abchpd}
\end{table*}

<<supp_labels, echo=FALSE, results="asis">>=
    N <- 5000
    replicate <- 0
    lab <- NULL
    for (m in c(2, 3, 4)) {
    for (I in c(1000, 2000)) {
    for (alpha in c(0, 0.5, 1, 1.5)) {
        lab <- c(lab, sprintf("fig:%.1f-%d-%d-%d-%d", alpha, I, m, N, replicate))
    }
    }
    }
    lab <- paste(lab, collapse = ",")
@

The dispersion of the ABC approximation to the posterior also varied between
the parameters, with narrower HPD intervals for the parameters with more
accurate point estimates (\cref{tab:abchpd}). \Cref{fig:abcex} shows
the distributions for one simulation. Equivalent plots for one replicate
simulation with each studied parameter combination can be found in
\cref{\Sexpr{lab}}. HPD intervals around $\alpha$ and $I$ were often narrow
relative to the region of nonzero prior density, whereas the intervals for $m$
and $N$ were more widely dispersed.

\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{abc-posterior-example}
  \vspace{6pt}
  \caption{
    Marginal posterior distributions of BA model parameters estimated
    with kernel-assisted ABC for a single simulated transmission tree. Dotted
    lines and shaded polygon indicate true values.
  }
  \label{fig:abcex}
\end{figure}

<<mixed_peerdriven, include=FALSE>>=
  library(coda)
  d <- fread("bzcat ../../simulations/abc-pa-mixed-alpha/abc/*")
  d <- d[iter == max(iter)]
  d <- d[sample(1:nrow(d), prob=weight, replace=TRUE)]
  params <- c("alpha", "m", "N", "I")
  d <- melt(d, measure.vars=params, variable.name="parameter")
  f <- function (x) {
    dens <- density(x)
    hpd <- HPDinterval(mcmc(x))
    list(map=dens$x[which.max(dens$y)], hpd.min=hpd[,"lower"], 
         hpd.max=hpd[,"upper"])
  }
  d <- d[,f(value), by=parameter]
  setkey(d, parameter)

  m <- collect.metadata("../../simulations/abc-pa-peerdriven/abc/*")
  p <- fread(paste("bzcat", rownames(m)[m$sample_peer == 1]))
  p <- p[iter == max(iter)]
  p <- p[sample(1:nrow(p), prob=weight, replace=TRUE)]
  params <- c("alpha", "m", "N", "I")
  p <- melt(p, measure.vars=params, variable.name="parameter")
  f <- function (x) {
    dens <- density(x)
    hpd <- HPDinterval(mcmc(x))
    list(map=dens$x[which.max(dens$y)], hpd.min=hpd[,"lower"], 
         hpd.max=hpd[,"upper"])
  }
  p <- p[,f(value), by=parameter]
  setkey(p, parameter)
  options(scipen=5)
@

To test the effect of model misspecification, we simulated one network where
the nodes exhibited heterogeneous preferential attachment power (half 0.5, the
other half 1.5), with $m$ = 2, $N$ = 5000, and $I$ = 1000. The posterior mean
[95\% HPD] estimates for each parameter were: 
$\alpha$, 
  \Sexpr{round(d["alpha", map], 2)} 
  [\Sexpr{round(d["alpha", hpd.min], 2)} -
   \Sexpr{round(d["alpha", hpd.max], 2)}];
$I$,
  \Sexpr{d["I", round(map)]} 
  [\Sexpr{d["I", round(hpd.min)]} -
   \Sexpr{d["I", round(hpd.max)]}];
$m$,
  \Sexpr{d["m", floor(map)]} 
  [\Sexpr{d["m", floor(hpd.min)]} -
   \Sexpr{d["m", floor(hpd.max)]}];
$N$,
  \Sexpr{d["N", round(map)]} 
  [\Sexpr{d["N", round(hpd.min)]}-
   \Sexpr{d["N", round(hpd.max)]}].
The approximate posterior distributions for this simulation are shown in
\cref{fig:mixed}. To test the effect of sampling bias, we sampled one
transmission tree in a peer-driven fashion, where the probability to sample a
node was twice as high if one of its peers had already been sampled. The
parameters for this experiment were $N$ = 5000, $m$ = 2, $\alpha$ = 0.5, and
$I$ = 2000. The estimated values were
$\alpha$, 
  \Sexpr{p["alpha", round(map, 2)]} 
  [\Sexpr{p["alpha", round(hpd.min, 2)]} -
   \Sexpr{p["alpha", round(hpd.max, 2)]}];
$I$,
  \Sexpr{p["I", floor(map)]} 
  [\Sexpr{p["I", floor(hpd.min)]} -
   \Sexpr{p["I", floor(hpd.max)]}];
$m$,
  \Sexpr{p["m", floor(map)]} 
  [\Sexpr{p["m", floor(hpd.min)]} -
   \Sexpr{p["m", floor(hpd.max)]}];
$N$,
  \Sexpr{p["N", floor(map)]} 
  [\Sexpr{p["N", floor(hpd.min)]} -
   \Sexpr{p["N", floor(hpd.max)]}].
The approximate posterior distributions are shown in \cref{fig:peerdriven}. Both
of these results were in line with estimates obtained on other simulated
datasets (\cref{tab:abchpd}), although the estimate of peer-driven sampling for
$\alpha$ was somewhat lower than typical.

%<<abc_glm, include=FALSE>>=
%    source("global.R")
%    options(scipen=-1, digits=2)
%@
%
%<<alpha_glm, include=FALSE>>=
%    # alpha_error is influenced by alpha and m but not I
%    stopifnot(alpha.glm[Parameter == "alpha", min(p) < 0.05])
%    stopifnot(alpha.glm[Parameter == "m", min(p) < 0.05])
%    stopifnot(alpha.glm[Parameter == "I", min(p) > 0.05])
%
%    # alpha_error is correlated with true_alpha
%    alpha.test <- d[,cor.test(alpha_error, true_alpha, method="spearman")]
%    stopifnot(alpha.test$p.value < 0.05)
%
%    # alpha_error is not correlated with true_m
%    alpha.m.cor <- d[,cor.test(alpha_error, true_m)]
%    stopifnot(alpha.m.cor$p.value < 0.05)
%@
%
%We used \software{netabc} to estimate the parameters of the \gls{BA} model on
%simulated trees where the true parameter values were known. Point estimates for
%each parameter are shown in \cref{fig:abcptm2} for the simulations with \gls{m} =
%2. The results for the other values of \gls{m} were similar
%(\cref{fig:abcptm3,fig:abcptm4}). The median [IQR] absolute error of estimates
%of \gls{alpha} across all simulations was
%    \Sexpr{d[,median(alpha_error)]} 
%    [\Sexpr{d[,quantile(alpha_error, 0.25)]}-\Sexpr{d[,quantile(alpha_error, 0.75)]}].
%\Gls{GLM} analysis indicated that the true values of both \gls{alpha} and
%\gls{m} had significant effects on the error in estimated \gls{alpha}
%    ($p$ values $\Sexpr{pp(alpha.glm[Parameter == "alpha", min(p)], eq=FALSE)}$
%     $\Sexpr{pp(alpha.glm[Parameter == "m", min(p)], eq=FALSE)}$,
%     \cref{tab:glmalpha}),
%but the true value of \gls{I} did not. There was a significant negative
%correlation between the true value of \gls{alpha} and the error
%    (Spearman's $\rho$ = \Sexpr{round(alpha.test$estimate, 2)},
%     $p \Sexpr{pp(alpha.test$p.value, eq=TRUE)}$).
%There was a negative correlation between \gls{m} and the error in \gls{alpha}
%    (Spearman's $\rho$ = \Sexpr{round(alpha.m.cor$estimate, 2)},
%    $p \Sexpr{pp(alpha.m.cor$p.value, eq=FALSE)}$).
%
%<<I_glm, include=FALSE>>=
%    # I_error is influenced by alpha and I but not by m
%    stopifnot(I.glm[Parameter == "alpha", min(p) < 0.05])
%    stopifnot(I.glm[Parameter == "m", min(p) > 0.05])
%    stopifnot(I.glm[Parameter == "I", min(p) < 0.05])
%
%    # correlation between I_error and true_alpha
%    I.alpha.cor <- d[,cor.test(I_error, true_alpha, method="spearman")]
%    stopifnot(I.alpha.cor$p.value < 0.05)
%
%    # correlation between I_error and true_I
%    I.I.cor <- d[,cor.test(I_error, true_I, method="spearman")]
%    stopifnot(I.alpha.cor$p.value < 0.05)
%@
%
%The mean error in the estimated value of \gls{I} was
%    \Sexpr{d[,round(median(I_error))]} 
%    [\Sexpr{d[,round(quantile(I_error, 0.25))]}-\Sexpr{d[,round(quantile(I_error, 0.75))]}],
%an over-estimate of roughly a factor of 1.5
%(\cref{fig:abcptm2,fig:abcptm1,fig:abcptm3,fig:abcptm4}). \Gls{GLM} analysis
%indicated a relationship between the error in estimated \gls{I}, and the true
%values of \gls{alpha} and \gls{I}
%    ($p$ values $\Sexpr{pp(I.glm[Parameter == "alpha", min(p)], eq=FALSE)}$
%     $\Sexpr{pp(alpha.glm[Parameter == "I", min(p)], eq=FALSE)}$,
%     \cref{tab:glmalpha}),
%but not the true value of \gls{m}. There was a significant correlation between 
%the true value of \gls{alpha} and the error in estimated \gls{I}
%    (Spearman's $\rho$ = \Sexpr{I.alpha.cor$estimate},
%     $p \Sexpr{pp(I.alpha.cor$p.value, eq=TRUE)}$),
%and between the true value of \gls{I} and the error in estimated \gls{I}
%    (Spearman's $\rho$ = \Sexpr{I.I.cor$estimate},
%     $p \Sexpr{pp(I.I.cor$p.value, eq=TRUE)}$).
%
%<<m_glm, include=FALSE>>=
%    # effects of parameters on m_error
%    stopifnot(m.glm[Parameter == "m", min(p)] < 0.05)
%    stopifnot(m.glm[Parameter == "alpha", min(p)] > 0.05)
%    stopifnot(m.glm[Parameter == "I", min(p)] > 0.05)
%
%    # m was only estimated correctly in just over 20\% of simulations with m > 2
%    m.tbl <- prop.table(table(d[true_m > 1,m_error]))
%    stopifnot(m.tbl[1] > 0.2 & m.tbl[1] < 0.3)
%
%    # with m = 1, over 95% of simulations are right
%    m1.est <- d[true_m == 1, m_error]
%    stopifnot(sum(m1.est == 0) / length(m1.est) > 0.95)
%    stopifnot(sum(m1.est == 0) / length(m1.est) < 1)
%@
%
%\gls{GLM} analysis showed an effect of the true value of \gls{m} on the error
%in the estimated \gls{m}
%    ($p \Sexpr{pp(m.glm[Parameter == "m", min(p)])}$,
%     \cref{tab:glmm}).
%When the true value of \gls{m} was 1, the correct value was recovered by
%\software{netabc} in virtually every case
%    (\Sexpr{sum(m1.est == 0)} out of \Sexpr{length(m1.est)} simulations).
%However, when the true value of \gls{m} was 2 or higher, the correct value was
%recovered in only 
%    \Sexpr{as.integer(m.tbl[1] * 100)}\%
%of simulations, little better than random guessing. The \gls{GLM} analysis did
%not indicate any effects of the true parameter values on the error in estimated
%\gls{m} (\cref{tab:glmm}).
%
%<<N_glm, include=FALSE>>=
%    # alpha_error is influenced by alpha and m but not I
%    stopifnot(N.glm[Parameter == "alpha", min(p) < 0.05])
%    stopifnot(N.glm[Parameter == "I", min(p) < 0.05])
%    stopifnot(N.glm[Parameter == "m", min(p) > 0.05])
%
%    N.alpha.test <- d[,wilcox.test(.SD[true_alpha == 1.5, N_error], 
%                                   .SD[true_alpha < 1.5, N_error])]
%    stopifnot(N.alpha.test$p.value < 0.05)
%    N.I.test <- d[,wilcox.test(.SD[true_I == 3000, N_error], 
%                               .SD[true_I < 3000, N_error])]
%    stopifnot(N.I.test$p.value < 0.05)
%@
%
%Finally, the total number of nodes \gls{N} was consistently over-estimated by
%about a factor of two
%    (error \Sexpr{d[,format(median(N_error), scientific=FALSE)]} 
%    [\Sexpr{d[,format(quantile(N_error, 0.25), scientific=FALSE)]} - 
%     \Sexpr{d[,format(quantile(N_error, 0.75), scientific=FALSE)]}]).
%The fitted \gls{GLM} indicated that the true values of both \gls{alpha} and
%\gls{I} had an effect on the error in the estimated \gls{N}
%    ($p$-values $\Sexpr{pp(N.glm[Parameter == "alpha", min(p)], eq=FALSE)}$ and 
%     $\Sexpr{pp(N.glm[Parameter == "I", min(p)], eq=FALSE)}$,
%     \cref{tab:glmN}),
%but that the true value of \gls{m} did not. The error in the estimated \gls{N}
%when \gls{alpha} was equal to 1.5 was slightly lower than for other values of
%\gls{alpha}
%    (median [IQR] error rates 
%     \Sexpr{d[true_alpha == 1.5, format(median(N_error), scientific=FALSE)]} 
%    [\Sexpr{d[true_alpha == 1.5, format(quantile(N_error, 0.25), scientific=FALSE)]} - 
%     \Sexpr{d[true_alpha == 1.5, format(quantile(N_error, 0.75), scientific=FALSE)]}]
%     for \gls{alpha} = 1.5 vs. 
%     \Sexpr{d[true_alpha < 1.5, format(median(N_error), scientific=FALSE)]} 
%    [\Sexpr{d[true_alpha < 1.5, format(quantile(N_error, 0.25), scientific=FALSE)]} - 
%     \Sexpr{d[true_alpha < 1.5, format(quantile(N_error, 0.75), scientific=FALSE)]}]
%     for \gls{alpha} < 1.5),
%and this difference was statistically significant
%    (Wilcoxon rank-sum test, $p \Sexpr{pp(N.alpha.test$p.value, eq=TRUE)}$).
%Similarly, the error in the estimated \gls{N} when \gls{I} was equal to 3000 was
%lower than for other values of \gls{I}
%    (median [IQR] error rates 
%     \Sexpr{d[true_I == 3000, format(median(N_error), scientific=FALSE)]} 
%    [\Sexpr{d[true_I == 3000, format(quantile(N_error, 0.25), scientific=FALSE)]} - 
%     \Sexpr{d[true_I == 3000, format(quantile(N_error, 0.75), scientific=FALSE)]}]
%     for \gls{I} = 3000 vs. 
%     \Sexpr{d[true_alpha < 3000, format(median(N_error), scientific=FALSE)]} 
%    [\Sexpr{d[true_alpha < 3000, format(quantile(N_error, 0.25), scientific=FALSE)]} - 
%     \Sexpr{d[true_alpha < 3000, format(quantile(N_error, 0.75), scientific=FALSE)]}]
%     for \gls{I} < 3000),
%and this difference was statistically significant
%    (Wilcoxon rank-sum test, $p \Sexpr{pp(N.I.test$p.value, eq=TRUE)}$).
%
%\begin{figure}
%  \includegraphics{abc-point-estimate-m2}
%  \caption[\Acrlong{MAP} point estimates for \gls{BA} model parameters obtained
%    by running \software{netabc} on simulated data, for simulations with $m = 2$.] 
%  {
%    \Acrlong{MAP} point estimates for \gls{BA} model parameters obtained by         
%    running \software{netabc} on simulated data. Values shown are for               
%    simulations with \gls{m} = 2. Dashed lines indicate true values. (A)            
%    Estimates of \gls{alpha} and \gls{I} which were varied in these simulations  
%    against known values. (B) Estimates of \gls{m} and \gls{N} which were held   
%    fixed in these simulations at the values \gls{m} = 2 and \gls{N} = 5000. 
%  }
%  \label{fig:abcptm2}
%\end{figure}
%
%<<posterior_sims, echo=FALSE>>=
%    N <- 5000
%    replicate <- 0
%    lab <- NULL
%    for (m in c(2, 3, 4)) {
%    for (I in c(1000, 2000)) {
%    for (alpha in c(0, 0.5, 1, 1.5)) {
%        lab <- c(lab, sprintf("fig:%.1f-%d-%d-%d-%d", alpha, I, m, N, replicate))
%    }
%    }
%    }
%    lab <- paste(lab, collapse=",")
%@
%
%\Cref{fig:abcex} shows the \gls{ABC} approximation to the posterior
%distribution on the \gls{BA} parameters for one simulation. Equivalent plots
%for one replicate simulation with each combination of parameters can be found
%in \cref{\Sexpr{lab}}. \Gls{HPD} intervals around \gls{alpha} and \gls{I} were
%narrow relative to the region of nonzero prior density, whereas the intervals
%for $m$ and \gls{N} were widely dispersed. \Cref{tab:abchpd} shows point
%estimates and 95\% \gls{HPD} intervals averaged over all simulations.
%
%\begin{figure}
%  \includegraphics{{abc-posterior/1.0_1000_2_5000_0}.pdf}
%  \caption[Approximate marginal posterior distributions of BA model parameters
%      obtained by applying \textit{netabc} to a simulated transmission tree
%      with values $\alpha$ = 1.0, $I$ = 1000, $m$ = 2, and $N$ = 5000.]
%    {
%        Approximate marginal posterior distributions of BA model parameters
%        obtained by applying \textit{netabc} to a simulated transmission tree
%        with BA parameter values $\alpha$ = 1.0, $I$ = 1000, $m$ = 2, and $N$ =
%        5000. Vertical dashed lines indicate true values. Shaded areas are 95\%
%        highest posterior density intervals. $x$-axes indicate regions of
%        nonzero prior density.
%    }
%  \label{fig:abcex}
%\end{figure}
%
%
%\begin{table}
%    \centering
%    \input{\tablepath/abc-hpd}
%    \caption[
%        Maximum \textit{a priori} estimates and 95\% highest posterior density
%        (HPD) interval boundaries for \gls{BA} model parameters estimated with
%        \software{netabc}, averaged over simulated transmission trees.
%    ]
%    {
%        Maximum \textit{a priori} estimates and 95\% highest posterior density
%        (HPD) interval boundaries for \gls{BA} model parameters estimated with
%        \software{netabc}, averaged over simulated transmission trees.
%    }
%    \label{tab:abchpd}
%\end{table}
%
%<<mixed_peerdriven, include=FALSE>>=
%  library(coda)
%  d <- fread("bzcat ../../simulations/abc-pa-mixed-alpha/abc/*")
%  d <- d[iter == max(iter)]
%  d <- d[sample(1:nrow(d), prob=weight, replace=TRUE)]
%  params <- c("alpha", "m", "N", "I")
%  d <- melt(d, measure.vars=params, variable.name="parameter")
%  f <- function (x) {
%    dens <- density(x)
%    hpd <- HPDinterval(mcmc(x))
%    list(map=dens$x[which.max(dens$y)], hpd.min=hpd[,"lower"], 
%         hpd.max=hpd[,"upper"])
%  }
%  d <- d[,f(value), by=parameter]
%  setkey(d, parameter)
%
%  m <- collect.metadata("../../simulations/abc-pa-peerdriven/abc/*")
%  p <- fread(paste("bzcat", rownames(m)[m$sample_peer == 1]))
%  p <- p[iter == max(iter)]
%  p <- p[sample(1:nrow(p), prob=weight, replace=TRUE)]
%  params <- c("alpha", "m", "N", "I")
%  p <- melt(p, measure.vars=params, variable.name="parameter")
%  f <- function (x) {
%    dens <- density(x)
%    hpd <- HPDinterval(mcmc(x))
%    list(map=dens$x[which.max(dens$y)], hpd.min=hpd[,"lower"], 
%         hpd.max=hpd[,"upper"])
%  }
%  p <- p[,f(value), by=parameter]
%  setkey(p, parameter)
%  options(scipen=5)
%@
%
%To test the effect of model misspecification, we simulated one network where
%the nodes exhibited heterogeneous preferential attachment power (half 0.5, the
%other half 1.5), with $m$ = 2, $N$ = 5000, and $I$ = 1000. The MAP [95\%
%HPD] estimates for each parameter were: 
%$\alpha$, 
%  \Sexpr{round(d["alpha", map], 2)} 
%  [\Sexpr{round(d["alpha", hpd.min], 2)} -
%   \Sexpr{round(d["alpha", hpd.max], 2)}];
%$I$,
%  \Sexpr{d["I", round(map)]} 
%  [\Sexpr{d["I", round(hpd.min)]} -
%   \Sexpr{d["I", round(hpd.max)]}];
%$m$,
%  \Sexpr{d["m", floor(map)]} 
%  [\Sexpr{d["m", floor(hpd.min)]} -
%   \Sexpr{d["m", floor(hpd.max)]}];
%$N$,
%  \Sexpr{d["N", round(map)]} 
%  [\Sexpr{d["N", round(hpd.min)]} -
%   \Sexpr{d["N", round(hpd.max)]}].
%The approximate posterior distributions for this simulation are shown in
%\cref{fig:mixed}. To test the effect of sampling bias, we sampled one
%transmission tree in a peer-driven fashion, where the probability to sample a
%node was twice as high if one of its peers had already been sampled. The
%parameters for this experiment were $N$ = 5000, $m$ = 2, $\alpha$ = 0.5, and
%$I$ = 2000. The estimated values were
%$\alpha$, 
%  \Sexpr{p["alpha", round(map, 2)]} 
%  [\Sexpr{p["alpha", round(hpd.min, 2)]} -
%   \Sexpr{p["alpha", round(hpd.max, 2)]}];
%$I$,
%  \Sexpr{p["I", floor(map)]} 
%  [\Sexpr{p["I", floor(hpd.min)]} -
%   \Sexpr{p["I", floor(hpd.max)]}];
%$m$,
%  \Sexpr{p["m", floor(map)]} 
%  [\Sexpr{p["m", floor(hpd.min)]} -
%   \Sexpr{p["m", floor(hpd.max)]}];
%$N$,
%  \Sexpr{p["N", floor(map)]} 
%  [\Sexpr{p["N", floor(hpd.min)]} -
%   \Sexpr{p["N", floor(hpd.max)]}].
%The approximate posterior distributions are shown in \cref{fig:peerdriven}. Both
%of these results were in line with estimates obtained on other simulated
%datasets (\cref{tab:abchpd}), although the estimate of peer-driven sampling for
%$\alpha$ was somewhat lower than typical.

%\subsubsection*{Effect of parameters on power-law exponent}
%
%\Cref{tab:glm} shows the estimated parameters for a log-link \gls{GLM} fitted
%to the observed distribution of \gls{gamma} values. The coefficients are
%interpretable as multiplicative effects.
%
%\begin{table}
%    \centering
%    \input{\tablepath/pa-gamma-glm}
%    \caption{Estimated \gls{GLM} parameters for relationship between power-law
%    exponent \gls{gamma} and \gls{BA} model parameters.}
%    \label{tab:glm}
%\end{table}


\section{Application to real world HIV data}
\label{sec:hiv}

\subsection{Methods}

{\color{blue}\uline{
The synthetic data experiments presented in the previous section demonstrated 
that the \gls{alpha} and \gls{I} parameters, and to a lesser extent the \gls{N}
parameter, had measurable impacts on tree shape and were identifiable with
kernel-assisted \gls{ABC}. Therefore, our next step was to use
\software{netabc} to estimate the parameters of the \gls{BA} model for real
world \gls{HIV} epidemics. }} Because the \gls{BA} model assumes a single
connected contact network, it is most appropriate to apply to groups of
individuals who are epidemiologically related. Therefore, we searched for
published \gls{HIV} datasets which originated from existing clusters, either
phylogenetically or geographically defined. In addition, we analysed an
in-house dataset sampled from \gls{HIV}-positive individuals in British
Columbia, Canada (the ``BC data''). The datasets are summarized in
\cref{tab:data}.

\begin{table}[ht]
  \centering
  \input{\tablepath/realdata-bc}
  \caption[Characteristics of published HIV datasets analyzed with \software{netabc}.]
  {
    Characteristics of published HIV datasets analyzed with \software{netabc}. 
    Abbreviations: MSM, men who have sex with men; HET, heterosexual; IDU,
    injection drug users. The \textcite{novitsky2013phylogenetic,novitsky2014impact} data
    were sampled from a primarily heterosexual risk environment, but did not
    explicitly exclude other risk factors.
  }
  \label{tab:data}
\end{table}

We downloaded all sequences associated with each published study from GenBank.
For the \textcite{novitsky2014impact} data, each \textit{env} sequence was
aligned pairwise to the HXB2 reference sequence (GenBank accession number
K03455) and the hypervariable regions were clipped out with
\software{BioPython} version 1.66+~\autocite{cock2009biopython}. Sequences were
multiply aligned using \software{MUSCLE} version 3.8.31
\autocite{edgar2004muscle}, and alignments were manually inspected with
\software{Seaview} version 4.4.2 \autocite{gouy2010seaview}. Phylogenies were
constructed from the nucleotide alignments by approximate maximum likelihood
using \software{FastTree2} version 2.1.7 \autocite{price2010fasttree} with the
\gls{GTR} model~\autocite{tavare1986some}. Transmission trees were estimated by
rooting and time-scaling the phylogenies by root-to-tip regression, using a
modified version of Path-O-Gen (distributed as part of
BEAST~\autocite{drummond2007beast}) as described
previously~\autocite{poon2015phylodynamic}. 

Three of the datasets \autocite[][and the BC data]{li2015hiv,novitsky2014impact}
were initially much larger than the others, containing 1265, 1299, and 7923
sequences respectively. To ensure that the analyses were comparable, we reduced
these to a number of sequences similar to the smaller datasets. For the
\citeauthor{li2015hiv} and BC datasets, we detected clusters of size 280 and
399 respectively using a patristic distance cutoff of 0.02 as described
previously~\autocite{poon2015impact}. Only sequences within these clusters were
carried forward. For the \textcite{novitsky2014impact} data, no large clusters
were detected using the same cutoff, so we analysed a subtree of size 180
chosen arbitrarily.

Empirical studies of contact networks often report the exponent $\gamma$ of the
power law degree distribution. To compare our results to the literature, we
simulated 100 networks each according to the \gls{MAP} parameter estimates
obtained for each investigated dataset. The power-law exponent $\gamma$ was
calculated for each network using the \software{fit\_power\_law} function in
\software{igraph}, with the `R.mle' implementation. The median of the 100
$\gamma$ values was taken as a point estimate for the associated dataset.

For all datasets, we used the priors $\alpha$ $\sim$ Uniform(0, 2) and $N$ and
$I$ jointly uniform on the region \{$n \leq N \leq 10000$, $n \leq I \leq
10000$, $I \leq N$\}, where $n$ is the number of tips in the tree (see
\cref{tab:data}). Since the value $m = 1$ produces networks with no cycles,
which we considered fairly implausible, we ran one analysis with the prior $m
\sim$ DiscreteUniform(1, 5), and one with the prior $m \sim$ DiscreteUniform(2,
5). The other parameters to the SMC algorithm were the same as used for the
simulation experiments, except that we used 10000 particles instead of 1000 to
increase the accuracy of the estimated posterior. This was computationally
feasible due to the small number of runs required for this analysis.

\subsection{Results}

<<realdata, include=FALSE>>=
  m <- collect.metadata("../../simulations/aggregates/hpd/*")
  d1 <- fread(rownames(m)[m$m_min == 1])
  d2 <- fread(rownames(m)[m$m_min == 2])

  map1 <- dcast.data.table(d1, dataset~parameter, value.var="mean")
  up1 <- dcast.data.table(d1, dataset~parameter, value.var="hpd.max")
  low1 <- dcast.data.table(d1, dataset~parameter, value.var="hpd.min")
  setkey(map1, dataset)
  setkey(up1, dataset)
  setkey(low1, dataset)

  map2 <- dcast.data.table(d2, dataset~parameter, value.var="mean")
  up2 <- dcast.data.table(d2, dataset~parameter, value.var="hpd.max")
  low2 <- dcast.data.table(d2, dataset~parameter, value.var="hpd.min")
  setkey(map2, dataset)
  setkey(up2, dataset)
  setkey(low2, dataset)
@

We applied kernel-assisted ABC to five published HIV datasets (\cref{tab:data}),
and found substantial heterogeneity among the parameter estimates
(\cref{fig:abchpd,fig:abchpdm2}). Plots of the marginal posterior distributions
for each dataset are shown in
\cref{fig:cuevas,fig:li,fig:niculescu,fig:novitsky,fig:wang}.
Two of the datasets (\textcite{niculescu2015recent, wang2015targeting}) had
estimated $\alpha$ values near unity for the prior allowing $m = 1$ (\gls{MAP}
estimates [95\% \gls{HPD}] 
  \Sexpr{map1["niculescu2015", round(alpha, 2)]} 
  [\Sexpr{low1["niculescu2015", round(alpha, 2)]} - 
   \Sexpr{up1["niculescu2015", round(alpha, 2)]}]
and
  \Sexpr{map1["wang2015", round(alpha, 2)]} 
  [\Sexpr{low1["wang2015", round(alpha, 2)]} -
   \Sexpr{up1["wang2015", round(alpha, 2)]}] respectively).
The MAP estimates did not change appreciably when $m = 1$ was disallowed by the
prior, although the credible interval of the \textcite{niculescu2015recent}
data was narrower
  (\Sexpr{low1["niculescu2015", round(alpha, 2)]} - 
   \Sexpr{up1["niculescu2015", round(alpha, 2)]}).
When $m = 1$ was permitted, the \textcite{li2015hiv, cuevas2009hiv} both had
low estimated $\alpha$ values
  (\Sexpr{map1["li2015", round(alpha, 2)]} 
  [\Sexpr{low1["li2015", round(alpha, 2)]} - 
  \Sexpr{up1["li2015", round(alpha, 2)]}]
and
  \Sexpr{map1["cuevas2009", round(alpha, 2)]} 
  [\Sexpr{low1["cuevas2009", round(alpha, 2)]} -
   \Sexpr{up1["cuevas2009", round(alpha, 2)]}]). 
However, the MAP estimates increased when $m = 1$ was not permitted, although
the HPD intervals remained roughly the same
  (\Sexpr{map2["li2015", round(alpha, 2)]} 
  [\Sexpr{low2["li2015", round(alpha, 2)]} - 
  \Sexpr{up2["li2015", round(alpha, 2)]}]
and
  \Sexpr{map2["cuevas2009", round(alpha, 2)]} 
  [\Sexpr{low2["cuevas2009", round(alpha, 2)]} -
   \Sexpr{up2["cuevas2009", round(alpha, 2)]}]).
The \textcite{novitsky2014impact} data had a fairly low estimated $\alpha$
for both priors on $m$
  (\Sexpr{map1["novitsky2014", round(alpha, 2)]} for $m \geq 1$;
   \Sexpr{map2["novitsky2014", round(alpha, 2)]} for $m \geq 2$).
However, the confidence interval was much wider when $m = 1$ was allowed
  ([\Sexpr{low1["novitsky2014", round(alpha, 2)]} -
    \Sexpr{up1["novitsky2014", round(alpha, 2)]}] for $m \geq 1$ vs.
   [\Sexpr{low2["novitsky2014", round(alpha, 2)]} -
    \Sexpr{up2["novitsky2014", round(alpha, 2)]}] for $m \geq 2$).

For all the datasets except \citeauthor{novitsky2014impact}, estimated values
of $I$ were below 2000 when $m = 1$ was allowed, with relatively narrow HPD
intervals compared to the nonzero prior density region
  (\citeauthor{cuevas2009hiv}, \Sexpr{map1["cuevas2009", floor(I)]} 
  [\Sexpr{low1["cuevas2009", floor(I)]} -
   \Sexpr{up1["cuevas2009", floor(I)]}];
   \citeauthor{niculescu2015recent}, \Sexpr{map1["niculescu2015", floor(I)]}
  [\Sexpr{low1["niculescu2015", floor(I)]} - 
   \Sexpr{up1["niculescu2015", floor(I)]}];
  \citeauthor{li2015hiv}, \Sexpr{map1["li2015", floor(I)]} 
  [\Sexpr{low1["li2015", floor(I)]} -
   \Sexpr{up1["li2015", floor(I)]}];
   \citeauthor{wang2015targeting}, \Sexpr{map1["wang2015", floor(I)]}
  [\Sexpr{low1["wang2015", floor(I)]} - 
   \Sexpr{up1["wang2015", floor(I)]}]).
The \citeauthor{novitsky2014impact} data was the outlier, with a very high
estimated $I$, and HPD interval spanning almost the entire prior region
  (\Sexpr{map1["novitsky2014", floor(I)]} 
  [\Sexpr{low1["novitsky2014", floor(I)]} -
   \Sexpr{up1["novitsky2014", floor(I)]}]).
The $I$ estimates and HPD intervals were generally robust to the choice of
prior on $m$, with slightly narrower HPD intervals (compare
\cref{fig:abchpd,fig:abchpdm2}).

The MAP estimate of $m$ was equal to 1 for all but the
\citeauthor{novitsky2014impact} data, when this value was allowed. However, the
upper bound of the HPD interval was different for each dataset
  (\citeauthor{niculescu2015recent}, \Sexpr{up1["niculescu2015", round(m)]};
   \citeauthor{wang2015targeting}, \Sexpr{up1["wang2015", round(m)]};
   \citeauthor{li2015hiv}, \Sexpr{up1["li2015", round(m)]};
   \citeauthor{cuevas2009hiv}, \Sexpr{up1["cuevas2009", round(m)]}).
When $m = 1$ was disallowed, the MAP for all datasets was either 2 or 3, with
HPD intervals spanning the entire prior region. The estimates for the total
number of nodes $N$ were largely uninformative for all samples, with almost all
MAP estimates greater than 7500 and HPD intervals spanning almost the entire
nonzero prior density region. The only exception was the \citeauthor{li2015hiv}
data, for which the MAP estimate was lower 
  (\Sexpr{map1["li2015", floor(N)]})
when $m = 1$ was allowed.

\begin{figure*}[ht]
  \centering
  \includegraphics{realdata-hpd-bc}
  \caption[
      Maximum \textit{a posteriori} point estimates and 95\% HPD intervals for
      parameters of the BA network model, fitted to six HIV datasets
      with \software{netabc}.]
  {
      Maximum \textit{a posteriori} point estimates and 95\% HPD intervals for
      parameters of the BA network model, fitted to six HIV datasets with
      \software{netabc}. Legend labels indicate risk group and country of
      origin. Abbreviations: IDU, injection drug users; MSM, men who have sex
      with men; HET, heterosexual.
  }
  \label{fig:abchpd}
\end{figure*}

To make our analyses comparable to the existing network literature, we
estimated values of the power law exponent $\gamma$ for each of the datasets 
investigated. The results are summarized in \cref{tab:gamma}. All of the
estimated exponents were in the range $2 \leq \gamma \leq 2.5$, which is on the
lower end of the range $2 \leq \gamma \leq 4$ reported in the literature.

\begin{table}
    \centering
    \input{\tablepath/realdata-gamma.tex}
    \caption[
        Estimated power law exponents for six HIV datasets based on maximum
        \textit{a priori} estimates of BA model parameters.
    ]{
        Estimated power law exponents for six HIV datasets based on maximum
        \textit{a priori} estimates of BA model parameters. 100 networks were
        simulated using \textit{MAP} parameter estimates obtained with
        \software{netabc}. The power law exponent $\gamma$ was estimated for
        each, and the median of those estimates was used as a point estimate
        for the corresponding dataset.
    }
    \label{tab:gamma}
\end{table}
