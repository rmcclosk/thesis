

\add{In this chapter, we will address the three research aims
of this thesis introduced in \cref{sec:obj}. First, in \cref{sec:netabc}, we
describe \software{netabc}, a computer program that implements an
\acrlong{ABC}-based algorithm to fit contact network models to phylogenetic
data. We also provide a justification for the use of \gls{ABC} for this problem
by arguing that the likelihood functions required to fit these models by more
conventional means are likely to be computationally intractable.  Second, in
\cref{sec:ba}, we perform a simulation study to investigate the \acrlong{BA}
network model, which uses a preferential attachment mechanism to generate
networks with the power law degree distributions observed in real world social
and sexual networks. We progress through two exploratory analyses testing the
identifiability of the model's parameters, and conclude by testing
\software{netabc}'s ability to recover the parameters from simulated
transmission trees. Third, in \cref{sec:hiv}, we apply \software{netabc} to fit
the \gls{BA} model to six real world \gls{HIV} datasets, with the understanding
of the model parameters' identifiability gained through the simulation
experiments. We conclude the chapter with a unified discussion of the three
research aims, including interpretation of the results of both the simulated
and real data experiments, as well as an examination of the limitations of our
approach and opportunities for future investigation.}

\section{\software{Netabc}: a computer program for estimation of contact
network parameters with ABC}
\label{sec:netabc}

\software{Netabc} is a computer program to perform statistical inference of
contact network parameters from an estimated transmission tree using
\gls{ABC}. \add{As discussed in \cref{sec:obj}, the principal statistical
algorithm used by \software{netabc} is adaptive
\gls{ABC}-\gls{SMC}~\autocite{del2012adaptive}. In addition, there are two
supplementary components which are specific to the domain of phylogenetics and
contact networks: Gillespie simulation~\autocite{gillespie1976general}, to
simulate transmission trees on contact networks; and the tree
kernel~\autocite{poon2013mapping}, which is used as the distance function in
\gls{ABC} to compare transmission trees~\autocite{poon2015phylodynamic} (see
\cref{sec:abc}).} We give a high-level overview of the program here, before
describing these components in detail. \software{Netabc} takes as input an
estimated transmission tree, which can be derived from a viral phylogeny by
rooting and time-scaling as described in \cref{subsec:phylodynamics} or
estimated by other methods~\autocite{cottam2008integrating,
jombart2011reconstructing, ypma2012unravelling, morelli2012bayesian,
didelot2014bayesian, hall2015epidemic}. We variously refer to this estimated
transmission tree as the observed tree, input tree, or true tree.

As described in \cref{sec:smc}, \software{netabc} keeps track of a population
of particles $x^{(k)}$ indexed by an integer $k$, each of which contains
particular parameter values $\theta^{(k)}$ for the \add{contact network} model
we are trying to fit \add{to the input tree}. A small number \gls{M} of contact
networks $z^{(k,i)}$, $1 \leq i \leq \gls{M}$, are generated under the model
for each particle in accordance with that particle's parameters. An epidemic is
simulated over each of these networks using Gillespie simulation, and by
keeping track of its progress, a transmission tree is obtained. Thus, each
particle becomes associated with several simulated transmission trees. These
trees are compared to the input tree using the tree kernel. Particles are
weighted according to the similarity of their associated simulated trees with
the true tree, with more similar trees receiving higher weights. The particles
are iteratively perturbed to explore the parameter space, and particles with
simulated trees too distant from the true tree are periodically dropped and
resampled. Once a convergence criterion is attained, the final set of particles
is used as a Monte Carlo approximation to the target distribution of \gls{ABC},
which is assumed to resemble the posterior distribution on model parameters
(see \cref{sec:abc}). A graphical schematic of this algorithm is shown in
\cref{fig:abcsmc}.

\begin{figure}
    \includegraphics{abc-smc.pdf}
    \caption[
        Graphical schematic of the ABC-SMC algorithm implemented in \software{netabc}.
    ]{
        Graphical schematic of the \gls{ABC}-\gls{SMC} algorithm implemented in
        \software{netabc}. Particles are initially drawn from their prior
        distributions, making the initial population a Monte Carlo
        approximation to the prior. At each iteration, particles are perturbed,
        and a distance threshold around the true tree contracts. Particles are
        rejected, and eventually resampled, when all their associated simulated
        trees lie outside the threshold. As the algorithm progresses, the
        population smoothly approaches a Monte Carlo approximation of the
        \gls{ABC} target distribution, which is assumed to resemble the
        posterior.
    }
    \label{fig:abcsmc}
\end{figure}

\software{Netabc} is written in the \software{C} programming language. The
\software{igraph} library~\autocite{csardi2006igraph} is used to generate and
store contact networks and phylogenies. Judy arrays~\autocite{baskins2004judy}
are used for hash tables and dynamic programming matrices. The
\gls{GSL}~\autocite{gough2009gnu} is used to generate random draws from
probability distributions, and to \del{perform the bisection step} \add{solve
for the next $\varepsilon$ by bisection} in the adaptive \gls{ABC}-\gls{SMC}
algorithm. Parallelization is implemented with \gls{POSIX}
threads~\autocite{barney2009posix}. In addition to the \software{netabc} binary
to perform \gls{ABC}, we provide three additional stand-alone utilities:
\software{treekernel}, to calculate the tree kernel; \software{nettree}, to
simulate a transmission tree over a contact network; and \software{treestat},
to compute various summary statistics of phylogenies. The programs are freely
available at \url{https://github.com/rmcclosk/netabc}.

To check that our implementation of Gillespie simulation was correct, we
reproduced Figure 1A of \textcite{leventhal2012inferring} (our
\cref{fig:leventhal}), which plots the imbalance of transmission trees
simulated over four network models at various levels of pathogen
transmissibility. Our implementation of adaptive \gls{ABC}-\gls{SMC} was tested
by applying it to the same mixture of Gaussians used by
\textcite{del2012adaptive} to demonstrate their method (originally used
by~\textcite{sisson2007sequential}). We were able to obtain a close
approximation to the function (see \cref{fig:smctest}), and attained the
stopping condition used by the authors in a comparable number of steps. To
check that the algorithm would converge to a bimodal distribution, we also
applied it to a mixture of two Gaussians with means $\pm4$ and variances 1. The
algorithm was able to recover both peaks (\cref{fig:smctest2}).

\subsection{Simulation of transmission trees over contact networks}
\label{subsec:nettree}

The simulation of epidemics, and the corresponding transmission trees, over
contact networks is performed in \software{netabc} using the Gillespie
simulation algorithm~\autocite{gillespie1976general}. This method has been
independently implemented and applied by several
authors~\autocite[\textit{e.g.}][]{o2011contact, robinson2013dynamics,
leventhal2012inferring, groendyke2011bayesian, villandre2016assessment}.
\textcite{groendyke2011bayesian} published their implementation as an
\software{R} package, but since the \gls{SMC} algorithm is quite
computationally intensive, we chose to implement our own version in
\software{C} \add{as part of \software{netabc}}.

Let $G = (V, E)$ be a directed contact network. We assume the individual nodes
and edges of $G$ follow the dynamics of the \gls{SIR}
model~\autocite{kermack1927contribution}. Each directed edge $e = (u, v)$ in
the network is associated with a transmission rate $\beta_e$, which indicates
that, once $u$ becomes infected, the waiting time until $u$ infects $v$ is
distributed as $\Exponential(\gls{beta}_e)$. Note that $v$ may become infected
before this time has elapsed, if $v$ has other incoming edges. $v$ also has a
removal rate $\gls{nu}_v$, so that the waiting time until removal of $v$ from
the population is $\Exponential(\gls{nu}_v)$. Removal may correspond to death
or recovery with immunity, or a combination of both, but in our implementation
recovered nodes never re-enter the susceptible population. We define a
\defn{discordant edge} as an edge $(u, v)$ where $u$ is infected and $v$ has
never been infected. \add{In the epidemiology literature, the symbol $\gamma$
is usually used in place of \gls{nu}; we use \gls{nu} here to distinguish the
recovery rate from the power law exponent of scale free networks (see
\cref{subsec:pa}).}

To describe the algorithm, we introduce some notation and variables. Let
$\inc(v)$ be the set of incoming edges to $v$, and $\out(v)$ be the set of
outgoing edges from $v$. Let \gls{gI} be the set of infected nodes in the
network, \gls{gR} be the set of removed nodes, \gls{gS} be the set of
susceptible nodes, and \gls{gD} be the set of discordant edges in the network.
Let \gls{beta} be the total transmission rate over all discordant edges, and
\gls{nu} be the total removal rate of all infected nodes,
\[
    \gls{beta} = \sum_{e \in \gls{gD}} \gls{beta}_e, \quad
    \gls{nu} = \sum_{v \in \gls{gI}} \gls{nu}_v.
\]
The variables \gls{gS}, \gls{gI}, \gls{gR}, \gls{gD}, \gls{beta}, and \gls{nu}
are all updated as the simulation progresses. When a node $v$ becomes infected,
it is deleted from \gls{gS} and added to \gls{gI}. Any formerly discordant
edges in $\inc(v)$ are deleted from \gls{gD}, and edges in $\out(v)$ to nodes
in \gls{gS} are added to \gls{gD}. If $v$ is later removed, it is deleted from
\gls{gI} and added to \gls{gR}, and any discordant edges in $\out(v)$ are
deleted from \gls{gD}. At the time of either infection or removal, the
variables \gls{beta} and \gls{nu} are updated to reflect the changes in the
network. \del{The updates to \gls{gS}, \gls{gI}, \gls{gR}, \gls{gD},
\gls{beta}, and \gls{nu} are straightforward and are not written explicitly in
the algorithm.}

\newcommand{\tip}{\mathit{tip}}

The Gillespie simulation algorithm is given as \cref{alg:nettree}. The
transmission tree \gls{T} is simulated along with the epidemic. We keep a map
called ``$\tip$'', which maps infected nodes in \gls{gI} to the tips of
\gls{T}. The simulation continues until either there are no discordant edges
left in the network, or we reach a user-defined cutoff of time (\gls{tmax}) or
number of infections (\gls{I}). We use the notation $\Uniform(0, 1)$ to
indicate a number drawn from a uniform distribution on $(0, 1)$, and
$\Exponential(\lambda)$ to indicate a number drawn from an exponential
distribution with rate $\lambda$. The combined number of internal nodes and
tips in \gls{T} is denoted $|T|$. \add{The updates to \gls{gS}, \gls{gI},
\gls{gR}, \gls{gD}, \gls{beta}, and \gls{nu} described in the previous
paragraph are not written explicitly in \cref{alg:nettree}, as they are quite
straightforward and would only obfuscate the pseudocode.}

\begin{algorithm}
    \label{alg:nettree}
    \caption{Simulation of an epidemic and transmission tree over a contact network}
    \begin{algorithmic}
        \State infect a node $v$ at random, updating \gls{gS}, \gls{gI},
                 \gls{gD}, \gls{beta}, and \gls{nu}
        \State $\gls{T} \gets$ a single node with label $1$
        \State $\tip[v] \gets 1$
        \State $\gls{t} \gets 0$
        \While{$\gls{gD} \neq \emptyset$ and $|\gls{gI}| + |\gls{gR}| < \gls{I}$
                and $\gls{t} < \gls{tmax}$}
            \State $s \gets \min(\gls{tmax} - \gls{t},\,
                \Exponential(\gls{beta} + \gls{nu}))$
            \For{$v \in \tip$}
                \State{extend the branch length of $\tip[v]$ by $s$}
            \EndFor
            \State $\gls{t} \gets \gls{t} + s$
            \If{$\gls{t} < \gls{tmax}$}
                \If{$\Uniform(0, \gls{beta} + \gls{nu}) < \gls{beta}$}
                    \State choose an edge $e = (u, v)$ from \gls{gD} with
                        probability $\gls{beta}_e / \gls{beta}$ and infect $v$
                    \State $\tip[v] \gets |\gls{T}|+1$
                    \Comment add new tips to tree and tip array
                    \State $\tip[u] \gets |\gls{T}|+2$
                    \Comment corresponding to $u$ and $v$ 
                    \State add tips with labels $(|\gls{T}|+1)$ and
                        $(|\gls{T}|+2)$ to \gls{T}
                    \State connect the new nodes to $\tip[v]$ in $\gls{T}$,
                        with branch lengths $0$ 
                \Else
                    \State choose a node $v$ from \gls{gI} with probability
                        $\gls{nu}_v / \gls{nu}$ and remove $v$
                    \State delete $v$ from $\tip$
                \EndIf
                \State update \gls{gS}, \gls{gI}, \gls{gR}, \gls{gD},
                    \gls{beta}, and \gls{nu}
            \EndIf
        \EndWhile
    \end{algorithmic}
\end{algorithm}

\subsection{Phylogenetic kernel}

The tree kernel developed by \textcite{poon2013mapping} provides a
comprehensive similarity score between two phylogenetic trees, via the
dot-product of the two trees' feature vectors in the space of all possible
subset trees with branch lengths (see \cref{subsec:treeshape}). \add{Because
the branch lengths are continuous, there are infinitely many possible subset
trees; hence, the feature space is infinite-dimensional.} The kernel was
implemented using the fast algorithm developed by
\textcite{moschitti2006making}. First, the production rule of each node, which
is the total number of children and the number of leaf children, is recorded.
The nodes of both trees are ordered by production rule, and a list of pairs of
nodes sharing the same production rule is created. These are the nodes for
which the value of the tree kernel must be computed - all other pairs have a
value of zero. The pairs to be compared are then re-ordered so that the child
nodes are always evaluated before their parents. Due to its recursive
definition, ordering the pairs in this way allows the tree kernel to be
computed by dynamic programming. The complexity of this implementation is
$O(|\gls{T}_1||\gls{T}_2|)$ for the two trees $\gls{T}_1$ and $\gls{T}_2$ being
compared.

The tree kernel cannot be used directly as a distance measure for \gls{ABC},
since it is maximized, not minimized, when the two trees being compared are the
same. Therefore, we defined the distance between two trees as
\[
    \gls{rho}(\gls{T}_1, \gls{T}_2) = 1 - \frac{K(\gls{T}_1, \gls{T}_2)}{\sqrt{K(\gls{T}_1, \gls{T}_1) K(\gls{T}_2, \gls{T}_2)}},
\]
which is a number between 0 and 1 that is minimized when $\gls{T}_1 = \gls{T}_2$. This is
similar to the normalization used by \textcite{collins2002new,
poon2013mapping}.

\subsection{Adaptive sequential Monte Carlo for Approximate Bayesian computation}
\label{subsec:adaptsmc}

We implemented the adaptive \gls{SMC} algorithm for \gls{ABC} developed by
\textcite{del2012adaptive}. This algorithm is similar to the reference
\gls{ABC}-\gls{SMC} algorithm described in \cref{subsec:abcalg}, except that
the sequence of tolerances $\gls{epsilon}_i$ is automatically determined rather
than specified in advance. The tolerances are chosen such that the \gls{ESS} of
the particle population, which indicates the quality of the Monte Carlo
approximation (see \cref{subsec:sis}), decays at a controlled rate. A
sudden precipitous drop in \gls{ESS} would indicate that only a small number of
particles had non-zero importance weights, which would result in a very poor
Monte Carlo approximation to the target distribution. This situation is
referred to as the collapse of the approximation \add{or particle degeneracy
(see \cref{subsec:smc})} and is mitigated by the adaptive approach. A single
parameter \del{$\alpha$ (not to be confused with the \gls{BA} model parameter)}
controls the decay rate. \add{In the original paper of
\textcite{del2012adaptive}, the parameter is called $\alpha$, but to avoid
confusion with the \gls{BA} parameter of the same name we will refer to it
here as \gls{alphaess}.} The tolerance $\gls{epsilon}_i$ is chosen to satisfy
\[
    \ESS(w_i) = \gls{alphaess} \ESS(w_{i-1}),
\]
where, $w_i$ is the vector of weights at the $i$th step. Note that, since $w_i$
depends on $\gls{epsilon}_i$, this equation solves for the updated weights and
the updated tolerance simultaneously. As pointed out by
\textcite{del2012adaptive}, the equation has no analytic solution, but can be
solved numerically by bisection. The forward kernels $K_i$ are taken to be
\gls{MCMC} kernels with stationary distributions $\pi_{\gls{epsilon}_i}$ and
proposal distributions
\[
    \gls{q}_i\left(\theta^{(k)}, \theta^{(k)\prime}\right) 
    \prod_{j=1}^{\gls{M}} \lik\left(z^{(j,k)\prime} \middle| \theta^{(k)\prime} \right),
\]
where $\theta^{(k)}$ is the vector of model parameters \add{associated with
particle $x^{(k)}$} and $z^{(j,k)\prime}$, $1 \leq j \leq \gls{M}$, are \gls{M}
datasets simulated according to $\theta^{(k)\prime}$. In our implementation,
the $\gls{q}_i$ \add{are constructed component-wise for $\theta$ out of}
Gaussian proposals for continuous parameters and Poisson proposals for discrete
parameters. For the Poisson proposals, the number of \add{discrete} steps to
move the particle is drawn from a Poisson distribution, and the direction in
which to move the particle is chosen uniformly at random. The variance of each
proposal distribution was set equal to twice the empirical variance of the
particles, following~\autocite{beaumont2009adaptive, del2012adaptive}. The
backwards kernels are
\[
    L_{i-1}(x', x) = \frac{\pi_i(x)K_i(x, x')}{\pi_i(x')}.
\]
Here we have written $x'$ for $x_i$ and $x$ for $x_{i-1}$ to emphasize that
$x_{i-1}$ is the current value of the particle and $x_i$ is the proposed value.
When substituted into \cref{eq:smcwt}, the forward kernels $K_i(x, x')$ and
densities $\pi_i(x') = \pi_{\varepsilon_i}(x')$ cancel out, and we are left
with the following weight update.
\begin{align*}
    w_i(x) 
    & \madd{\propto w_{i-1}(x) \frac{\pi_i(x') L_{i-1}(x', x)}{\pi_{i-1}(x)K_i(x, x')}}
        & \madd{\text{importance weight update from SMC}} \\
    &\madd{=w_{i-1}(x) \frac{\pi_i(x') \pi_i(x) K_i(x, x')}{\pi_{i-1}(x)K_i(x, x')\pi_i(x')}}
        & \madd{\text{substitute } L_{i-1}} \\
    &= w_{i-1}(x) \frac{\pi_i(x)}{\pi_{i-1}(x)}
        & \madd{\text{cancel } K_i(x, x') \text{ and } \pi_i(x')} \\
    &= \madd{w_{i-1}(x) \frac{\pi(\theta) \prod_{j=1}^M f(z^{(j)\prime} \mid \theta) 
                        \sum_{j=i}^M \I_{A_{\varepsilon_i, y}}(z^{(j)})}
                       {\pi(\theta) \prod_{j=1}^M f(z^{(j)\prime} \mid \theta) 
                       \sum_{j=i}^M \I_{A_{\varepsilon_{i-1}, y}}(z^{(j)})}}
        & \madd{\text{definition of } \pi_i(x)} \\
    &= w_{i-1}(x) \frac{\sum_{j=i}^M \I_{A_{\varepsilon_i, y}}(z^{(j)})}
        {\sum_{j=i}^M \I_{A_{\varepsilon_{i-1}, y}}(z^{(j)})}
        & \madd{\text{cancel prior and likelihood.}}
\end{align*}
In other words, when the distance threshold $\gls{epsilon}_{i-1}$ is contracted
to $\gls{epsilon}_i$, the particles' weights are multiplied by the proportion of
simulated datasets that are still inside the new threshold. The user may
specify a final tolerance $\gls{epsilon}$, or a final acceptance rate of the
\gls{MCMC} kernel, and the algorithm will be stopped when either of these
termination conditions is reached. The latter condition stops the algorithm
when the particles are not moving around very much, implying little change in
the estimated target.

\subsection{Justification for approach}
\label{subsec:just}

\add{We present here a non-rigorous justification for the use of
\gls{ABC} for the problem at hand, as opposed to more frequently-used
approaches for fitting mathematical models (see \cref{chp:prelim}). Consider a
contact network model with parameters $\theta$, and an estimated transmission
tree \gls{T}. Taking a Bayesian approach, our aim is to obtain a sample from
the posterior distribution on the model's parameters given our data,}
\[
    \madd{\post(\theta \mid \gls{T}) = \frac{\lik(\gls{T} \mid \theta) \prior(\theta)}
    {\int_{\Theta}\lik(\gls{T} \mid \theta) \prior(\theta) \d\theta}.}
\]
\add{For all but the simplest models, the normalizing constant in the
denominator is an intractable integral. What we shall argue here is that, in
contrast to most commonly studied mathematical models, the likelihood
$\lik(\gls{T} \mid \theta)$ is also likely to be intractable in our case.}

\begin{figure}
    \centering
    \includegraphics[width=0.6\textwidth]{transtree}
    \caption[
        Illustration of an estimated transmission tree without labels and two
        possible underlying complete transmission trees with labels.
    ]{
        Illustration of an estimated transmission tree without labels (left)
        and two possible underlying complete transmission trees with labels
        (right). In the top right scenario, the epidemic began with node $a$
        who transmitted first to $b$ and then to $c$. In the bottom right
        scenario, $b$ was the index case; $b$ infected $c$, who went on to
        infect $a$. A transmission tree estimated from a viral phylogeny would
        have the same topology and tip labels in both cases.
    }
    \label{fig:tt}
\end{figure}

\add{As discussed in \cref{subsec:tt}, the internal nodes of transmission trees
represent transmission events, and are labelled with the donor in the
associated transmission pair. However, when we estimate a transmission tree
from viral sequence data, we generally only know the labels of the tips of the
tree, not the labels of the internal nodes. In viral phylogenies, the
transmissions are at least partially preserved through the evolutionary
relationships among the viruses, but the directionality of those transmissions
is unknown. Thus, a single estimated transmission tree can correspond to many
possible pathways of the epidemic through the network. \Cref{fig:tt}
illustrates this concept for a simple transmission tree with three tips. When
calculating a likelihood given a transmission tree, we must sum over all
possible labellings of the internal nodes. Let $\L$ be the set of such
labellings. Then}
\begin{align}
    \madd{\lik(\gls{T} \mid \theta) = \sum_{l \in \L} \lik(\gls{T},\, l \mid \theta).}
    \label{eq:lik1}
\end{align}
\add{A contact network model assigns a probability density to each possible
contact network. Transmission trees are realized over particular contact
networks, not over the model itself. Therefore, we must also sum over all
contact networks which could be generated by the model. Let $\G$ be the set of
all possible contact networks. Summing \cref{eq:lik1} over $\G$ gives}
\begin{align}
    \madd{\lik(\gls{T} \mid \theta) = \sum_{G \in \G} \sum_{l \in \L} 
        \lik(\gls{T},\, l \mid G, \theta) \lik(G \mid \theta).}
    \label{eq:lik2}
\end{align}
\add{This can be simplified somewhat by noticing that, given a specific
contact network, the labelled transmission tree depends only on that network
and not on the model that generated it. That is, $\lik(\gls{T}, \nu \mid G,
\theta) = \lik(\gls{T},\, l \mid G)$, and}
\begin{align}
    \madd{\lik(\gls{T} \mid \theta) = \sum_{G \in \G} \lik(G \mid \theta) \sum_{l \in \L} 
    \lik(\gls{T}, \nu \mid G)}
    \label{eq:lik3}
\end{align}
\add{Under the assumption that both transmission and removal are Poisson
processes, calculating $\lik(\gls{T},\, l \mid G)$ can be accomplished by a
straightforward modification of the Gillespie simulation algorithm
(\cref{alg:nettree}). Rather than choosing transmission or removal events
according to their probabilities, the events would be deterministically chosen
based on the transmission tree and the probabilities of each event would be
multiplied together. Assuming efficient data structures for storing lists of
nodes and edges, the complexity of this calculation would be $O(|\gls{T}|)$.
The number of possible labellings of internal nodes of $\gls{T}$ is easily seen
to be $2^{(|\gls{T}|-1)/2}$ by noticing that each of the $(|\gls{T}|-1)/2$
internal nodes must be labelled with the same label as either its right child
or its left child. Although exponential calculations of this nature can are
often be simplified on trees using dynamic programming (\eg
\autocite{pupko2000fast}), it cannot be straightforwardly applied in this case
because the subtrees' probabilities depend on the existing epidemic progress
(their parents and siblings). Hence, calculating the inner sum over labels may
take time $O(2^{(|\gls{T}|-1)/2})$.}

\add{The outer sum, over all contact networks, is also difficult to evaluate
in general. There are $2^{\gls{N}(\gls{N}-1)}$ directed graphs on \gls{N}
nodes~\autocite{harary2014graphical}. There must be at least as many nodes in
the contact network as the number of tips in the tree, which is
$(|\gls{T}|+1)/2$. Of course, it is very likely that there are more nodes in
the network than observed tips because some individuals are never infected
and/or some infected individuals are never sampled. The complexity of
calculating $\lik(G \mid \theta)$ is obviously dependent on the particular
model being investigated. For the \gls{BA} model, we might have to sum over all
possible orders in which the nodes could be added, and all assignments of edges
to the nodes which generated them. However, even in the case that calculating
$\lik(G \mid \theta)$ can be done in constant time, the sum (\ref{eq:lik3})
still has at least $O(2^{|\gls{T}|^2})$ terms.}

\add{We have shown that both the normalizing constant $\int_\Theta \lik(\gls{T}
\mid \theta) \prior(\theta) \d\theta$ and the likelihood $\lik(T \mid \theta)$
are likely computationally prohibitive to calculate. If this is the case, the
problem of fitting contact network models to phylogenies seems to be of the
\emph{doubly-intractable} type~\autocite{murray2012mcmc}, which would imply that
these models are not amenable to neither \gls{ML} nor Bayesian inference
techniques. Although both methods are able to cope with an intractable
normalizing constant (for example, by local search for \gls{ML} or Bayesian
\gls{MCMC}), neither can avoid the intractable likelihood calculations. This
justifies the use of \gls{ABC}, which is a likelihood-free method.}

\add{We have not proven here that \cref{eq:lik3} is impossible to calculate in
polynomial time - it could be possible to algebraically simplify the sum into a
tractable expression. Furthermore, under certain models, a large proportion of
$\G$ may have zero probability, which would enable the simplification of the
outer sum on a model-specific basis. It should also be noted that extensions of
Bayesian \gls{MCMC} have been developed for doubly-intractable
problems~\autocite{liang2010double, murray2012mcmc}, which might be adaptable
to the problem at hand. These have not been as widely used as \gls{ABC}, nor
are they as easily parallelizable as \gls{SMC}.}

\section{Analysis of \acrlong{BA} model with synthetic data}
\label{sec:ba}
\glsreset{BA}

\subsection{Why study the \acrlong{BA} model?}
\label{subsec:whyba}

\add{We developed \software{netabc} with the objective of extracting useful,
quantitative information about network structures from viral phylogenies. An
important aspect of ``usefulness'' is model specification and the biological or
epidemiological interpretation of the parameters. We want the model to be
realistic, but no so complicated that it becomes difficult to interpret. At
least some of the parameters should be of interest from a theoretical or
practical perspective, or there would be no point in estimating them. Since
\software{netabc} is a phylodynamic method, intended to be used with viral
sequence data, we would also like to choose parameters which may be difficult
to estimate with more standard methods. Otherwise, our method provides no
advantage. The \gls{BA} model (\cref{subsec:pa}) satisfies these criteria,
albeit some better than others. The purported realism of the model stems from
the fat-tailed degree distributions it produces, which are similar to those
observed in real world sexual networks~\autocite{colgate1989risk,
liljeros2001web, schneeberger2004scale, clemenccon2015statistical,
rothenberg2007large}. Moreover, the ``rich get richer'' phenomenon, where
popular individuals attract new connections at an elevated rate, is intuitively
reasonable for both sexual~\autocite{de2007preferential} and
\gls{IDU}~\autocite{dombrowski2013topological} networks. However, the model is
very simple, assuming that all nodes form the same number of links when added
to the network and share the same preference for popular individuals.}

\add{In this thesis, we consider four parameters related to the \gls{BA} model,
denoted \gls{N}, \gls{m}, \gls{alpha}, and \gls{I} (see \cref{subsec:pa}). The
first three of these parameterize the network structure, while \gls{I} is
related to the simulation of transmission trees over the network. However, we
will refer to all four as \gls{BA} parameters. \gls{N} denotes the total number
of nodes in the network, or equivalently, susceptible individuals in the
population. \gls{m} is the number of new undirected edges added for each new
vertex, or equivalently one-half of the average degree. \gls{alpha} is the
power of preferential attachment -- new nodes are attached to existing nodes of
degree $d$ with probability proportional to $d^{\gls{alpha}} + 1$. Finally,
\gls{I} is the number of infected individuals at the time when sampling occurs.
The \gls{alpha} parameter is unitless, while \gls{m} has units of edges or
connections per vertex, and \gls{N} and \gls{I} both have units of nodes or
individuals.}

\add{From a public health standpoint, all four parameters are of some interest.
The prevalence \gls{I} can be used to estimate the resources required to combat
an ongoing epidemic, while total susceptible population size \gls{N} provides a
similar metric for preventative measures. The average degree of the network, in
this case $2\gls{m}$, is directly related to \gls{R0}, the basic reproductive
number~\autocite{britton2002bayesian}. \gls{R0} quantifies the average number
of secondary infections ultimately caused by one infected individual; higher
\gls{R0} generally indicates faster epidemic growth and/or larger eventual
epidemic size~\autocite{anderson1992infectious}. In a homogeneously mixed
population, the theoretically expected proportion of the population which must
be vaccinated to control an epidemic (the \defn{vaccination threshold}) can be
expressed in terms of \gls{R0}~\autocite{anderson1982directly}. Although
optimal vaccination strategies may differ in heterogeneous contact
structures~\autocite{ma2013importance}, it is reasonable to suppose that there
would still be a relationship between \gls{m}, \gls{R0}, and the vaccination
threshold. The preferential attachment power \gls{alpha} quantifies the degree
to which high-degree nodes, also called
superspreaders~\autocite{kemper1980identification}, characterize the network
structure. Superspreaders have been hypothesized to play a disproportionately
greater role in the spread of several diseases~\autocite{stadler2013uncovering,
shen2004superspreading}. If so, network-based
interventions~\autocite{little2014using, wang2015targeting} may be worth
considering as part of an epidemic control strategy. \gls{alpha} can also offer
some insight into how the network would react to the removal of nodes.
\textcite{dombrowski2013topological} found evidence of preferential attachment
in \gls{IDU} networks, and suggested that as a consequence of this
characteristic, the removal of random nodes (such as through a police
crackdown) might inadvertently make it easier for epidemics to spread. When
individuals with only one or two connections lose them, they might tend to seek
out well-known (that is, high-degree) members of the community, thus increasing
those individuals' connectivity even further. Although we do not consider a 
dynamic network in this work, it is not unreasonable that the network could be
close to static over short periods of time, and this static structure might be
informative of future dynamic behaviour.}

\add{Though it is theoretically possible to estimate all four \gls{BA}
parameters using more conventional approaches, the cost of doing so may be
high, in addition to other situation-specific challenges. In theory, any
network parameter can be estimated by explicitly constructing the contact
network, although this is highly resource intensive and is hampered by
misreporting and other challenges~\autocite{eames2015six}. All parameters
become more difficult to estimate when the infected population is ``hidden''
due to illegal or stigmatized behaviour, as is sometimes the case with
\gls{HIV} outbreaks among \gls{IDU}, \gls{MSM}, or sex workers. In such cases,
phylodynamic methods may offer the advantage of providing information about the
whole population from only a small sample. A survey, for example, will not tell
us if there are large groups of the population that we simply have not sampled.
Our hope is that estimating \gls{N} and \gls{I} phylogenetically might provide
this additional information. The average degree of the network, $2\gls{m}$, is
also estimable by a survey, although individuals may be unwilling or unable to
disclose how many contacts they have had. Sequence data also provide an
advantage in this respect -- they are objective and do not share the same
biases as self-reported partner counts. The estimation of \gls{alpha} is more
complex, as this parameter is most strongly reflected in the connectivity of
very high degree nodes, who are rare in the population. Locating them might
require contact tracing, or respondent-driven
sampling~\autocite{heckathorn1997respondent}. Even if the full degree
distribution of a network is available, there are models other than
preferential attachment which can produce scale-free
networks~\autocite[\eg][]{kumar2000stochastic}. \textcite{de2007preferential}
were able to estimate \gls{alpha} by maximum likelihood using partner count
data from several sequential time intervals, but they admit such detailed data
are not usually available. Moreover, their dataset was constructed via a random
survey, which would likely miss the few high-degree nodes characterizing a
power law degree distribution. In summary, each of the \gls{BA} parameters may
be estimated without phylodynamics, but there are sufficient difficulties that
we believe an alternative method using sequence data is warranted.} 

\subsection{Using synthetic data to investigate identifiability and sources of
estimation error}

\add{We have argued that the parameters of the \gls{BA} model are interesting
and worth estimating with phylodynamic methods. However, these estimates will
only constitute ``useful'' information about the network if the parameters are
identifiable from phylogenetic data. Roughly speaking, the identifiability of a
parameter says how much information about that parameter can possibly be
obtained from the observed data. If the parameters of the \gls{BA} model do not
influence tree shape at all, then we cannot possibly estimate them -- the
posterior distribution will exactly resemble the prior, no matter how accurate
a representation of the posterior we are able to produce. Hence, before
proceeding with a full validation of \software{netabc} on simulated data, we
undertook two experiments designed to assess the identifiability of the
\gls{BA} parameters. These experiments only investigated one parameter of the
\gls{BA} model at a time while holding all others fixed, a strategy commonly
used when performing sensitivity analyses of mathematical models. This allowed
us to perform a fast preliminary analysis without dealing with the ``curse of
dimensionality'' of the full parameter space. The experiments are motivated and
described on a high level here, with more detail provided in the next section.}

\add{First, we simulated trees under three different values of each parameter,
and asked how well we could tell the different trees apart. The better we are
able to distinguish the trees, the more identifiability we might expect for the
corresponding parameter when we attempt to estimate it with \gls{ABC}. This
experiment also had the secondary purpose of validating our choice of the tree
kernel as a distance measure in \gls{ABC}. To tell the trees apart, we used a
classifier based on the tree kernel, but we also tested two other tree shape
statistics: one which considers only the topology, and another which considers
only branching times. Since the tree kernel incorporates both of these sources
of information, we expected it to outperform the other two statistics. Finally,
the tree kernel can be ``tuned'' by adjusting the values of the meta-parameters
\gls{lambda} and \gls{sigma}. The results of this experiment were used to
select values for these meta-parameters to carry forward to the rest of the
thesis, based on their accuracy in distinguishing the different trees. }

\add{A second experiment was designed to test whether we could actually
estimate the parameters numerically, rather than just telling three different
values apart, and also to assess how identifiability varied in different
regions of the parameter space. An individual tree was compared to simulated
trees on a one-dimensional grid of values of one \gls{BA} parameter, to obtain
a ``distribution'' of kernel score values. From this distribution, estimates
and credible intervals of the parameter could be calculated. Repeating this
experiment with trees located throughout the parameter space allowed us to
better quantify the identifiability. Furthermore, doing marginal estimation
(that is, estimating one parameter with all others fixed) can provide insight
into any biases observed when doing joint estimation with \gls{ABC}. If grid
search is inaccurate, it indicates a lack of parameter identifiability.
However, if the marginal grid search estimates are accurate but the estimates
obtained with \gls{ABC} are biased, this points to confounding between the
parameters which could only be observed when they are all estimated jointly.}

\add{After these preliminary experiments, the strategy we used for testing
\software{netabc} was a standard simulation-based validation. Transmission
trees were simulated under several combinations of parameter values, and we
tried to recover these values with \software{netabc}. We then used a
multivariable analysis to investigate how accuracy of these estimates was
influenced by the true parameter values.}

\add{In the previous section, we argued that the \gls{BA} model parameters were
worth investigating, and here we have presented several computational
experiments designed to assess their identifiability. There is a final, more
technical aspect of our method's ``usefulness'' to consider, which is the
accuracy of the \gls{ABC} approximation to the posterior. As discussed in
\cref{sec:abc}, \gls{ABC} does not target the posterior distribution directly,
but rather an approximate posterior derived from simulated data and a distance
function. \gls{ABC} \emph{assumes} that this approximate posterior resembles
the true posterior, and it is critical for our estimates' relevance that this
assumption holds. There are two potential causes of an inaccurate \gls{ABC}
approximation~\autocite{fearnhead2012constructing}. First, the Monte Carlo
approximation to the \gls{ABC} target distribution may be poor, due to the
settings used for \gls{ABC}-\gls{SMC}. Second, the \gls{ABC} target
distribution may not resemble the posterior, due to a poor choice of distance
function. We designed two experiments to investigate the impact of these
sources of error.}

\add{The Monte Carlo approximation error is fairly easily quantified by simply
increasing the computing power used for \gls{SMC}. We ran one simulation using
a larger number of particles, more simulated datasets per particle, and a
higher value for \gls{alphaess}. A substantial improvement in accuracy
resulting from these changes would likely indicate a high Monte Carlo error
with the lower settings. The second issue, the resemblance of the \gls{ABC}
target distribution to the true posterior, is somewhat more difficult to
investigate. We do not have access to the true posterior, even for simulations
where the true parameter values are known. To address this source of error, we
performed marginal parameter estimation with \gls{ABC} by informing
\software{netabc} of some of the true parameter values. Any inaccuracy or bias
observed only in the joint estimation results, but not the marginal estimates, 
is most easily explained by interdependence between parameters in the true
posterior. However, errors observed in both marginal and joint estimates could
be due to either the shape of the true posterior or an inaccurate \gls{ABC}
approximation, and we have no way to distinguish one from the other. In other
words, this experiment provided only an upper bound on the error due to an
inaccurate \gls{ABC} approximation.}

\subsection{Methods}

\del{We investigated four parameters related to the \gls{BA} contact network
model, denoted \gls{N}, \gls{m}, \gls{alpha}, \gls{I} (see \cref{subsec:pa}).
The first three of these are parameters of the model itself, while \gls{I} is
related to the simulation of transmission trees over the network. However, we
will refer to all four as \gls{BA} parameters. \gls{N} denotes the total number
of nodes in the network, or equivalently, susceptible individuals in the
population. When a node is added to the network, \gls{m} new undirected edges
are added incident to it, and are attached to existing nodes of degree $d$ with
probability proportional to $d^{\gls{alpha}} + 1$ (\cref{subsec:pa}). To
simulate transmission trees over a \gls{BA} network, we allowed an epidemic to
spread until \gls{I} nodes were infected, and sampled a transmission tree at
that time.}

\add{For all simulations,} we assumed that all contacts had symmetric
transmission risk, which was implemented by replacing each undirected edge in
the network with two directed edges (one in each direction). Nodes in our
networks followed simple \gls{SI} dynamics, meaning that they became infected
at a rate proportional to their number of infected neighbours, and never
recovered. We did not consider the time scale of the transmission trees in
these simulations, only their shape. Therefore, the transmission rate along
each edge in the network was set to 1, the removal rate of each node was set to
0, and all transmission trees' branch lengths were scaled by their mean. The
\textit{igraph} library's implementation of the BA
model~\autocite{csardi2006igraph} was used to generate the graphs. The analyses
were run on Westgrid (\url{https://www.westgrid.ca/}) and a local computer
cluster. With the exception of our own C programs, all analyses were done in
\software{R}, and all packages listed below are \software{R} packages.
\add{Code to run all experiments is freely available at
    \url{https://github.com/rmcclosk/thesis}.}

\subsubsection*{Classifiers for BA model parameters based on tree shape}
\label{subsec:kernel}

\glsreset{nltt}

\add{Our first computational experiment was designed as an exploratory analysis
of the four \gls{BA} model parameters defined above: \gls{alpha}, \gls{I},
\gls{m}, and \gls{N}. The objective of this experiment was to determine whether
any of the four parameters were identifiable from the shape of the transmission
tree, as quantified by the tree kernel. Each of the \gls{BA} model parameters
was varied one at a time, while holding the other parameters at fixed, known
values. Contact networks were generated according to each set of parameter
values, and transmission trees were simulated over the networks. We then
evaluated how well a classifier based on the tree kernel could differentiate
the trees simulated under distinct parameter values. If the classifier's
cross-validation accuracy was high, this could be taken as an indication that
the parameter in question was identifiable in the range of values considered. 
A caveat of this preliminary analysis is that, since all parameters but one
were held at known values, nothing could be said about the identifiability of
\emph{combinations} of parameters; this issue will be explored later by jointly
estimating all parameters with \gls{ABC}}.

\add{In addition to testing for identifiability, a secondary objective of
this analysis was to validate the use of the tree kernel as a distance measure
for \gls{ABC} in our context. As discussed in \cref{sec:abc}, the choice of
distance function is extremely important for the accuracy of the \gls{ABC}
approximation to the posterior. Therefore, we evaluated two additional tree
statistics in the same manner as we evaluated the tree kernel (that is, by
constructing and testing a classifier). First, we considered Sackin's
index~\autocite{shao1990tree}, which measures the degree of imbalance or
asymmetry in a phylogeny (see \cref{subsec:treeshape}). Sackin's index is
widely used for characterizing phylogenies~\autocite{frost2013modelling} and
has been demonstrated to vary between transmission trees simulated under
different contact network types~\autocite{leventhal2012inferring}. Sackin's
index does not take branch lengths into account, considering only the tree's
topology. The other statistic we considered was the
\gls{nltt}~\autocite{janzen2015approximate}, which compares two trees based on
normalized distributions of their branching times (see
\cref{subsec:treeshape}). In contrast with Sackin's index, the \gls{nltt} does
not explicitly consider the trees' topologies, but it does use their normalized
branch lengths. While the \gls{nltt} is a newly developed statistic not yet in
widespread use, the unnormalized \gls{ltt}~\autocite{nee1992tempo} was the
basis of seminal early work extracting epidemiological information from
phylogenies~\autocite{holmes1995revealing}. We expected the tree kernel to
classify the \gls{BA} parameters more accurately than either Sackin's index or
the \gls{nltt}, since the tree kernel takes both topology and branch lengths
into account.}

This experiment involved a large number of variables that were varied
combinatorially. For ease of exposition, we will describe a single experiment
first, then enumerate the values of all variables for which the experiment was
repeated. The parameters of the tree kernel, $\lambda$ and $\sigma$
(\cref{subsec:treeshape}), will be referred to as \defn{meta-parameters} to
distinguish them from the parameters of the \gls{BA} model. 

The attachment power parameter \gls{alpha} was varied among three values: 0.5,
1.0, and 1.5. For each value, the \software{sample\_pa} function in the
\software{igraph} package was used to simulate 100 networks, with the other
parameters set to \gls{N} = 5000 and \gls{m} = 2. This step yielded a total of
300 networks. An epidemic was simulated on each network using our
\software{nettree} binary until \gls{I} = 1000 nodes were infected, at which
point 500 of them were sampled to form a transmission tree. A total of 300
transmission trees were thus obtained, comprised of 100 trees for each of the
three values of \gls{alpha}. The trees were ``ladderized'' so that the subtree
descending from the left child of each node was not smaller than that
descending from the right child. Summary statistics, such as Sackin's index and
the ratio of internal to terminal branch lengths, were computed for each
simulated tree using our \software{treestat} binary. The trees were visualized
using the \software{ape} package~\autocite{paradis2004ape}. \add{Both the tree
kernel and the \gls{nltt} are pairwise statistics, and the \glspl{SVM}
classifiers we used to investigate them operate on pairwise distance matrices.}
Our \software{treekernel} binary was used to calculate the value of the kernel
for each pair of trees, with the meta-parameters set to $\lambda = 0.3$ and
$\sigma = 4$. These values were stored in a symmetric 300 $\times$ 300 kernel
matrix.  Similarly, we computed the \gls{nltt} statistic between each pair of
trees using our \software{treestat} binary, and stored them in a second $300
\times 300$ matrix.

To investigate the identifiability of \gls{alpha} from tree shape, we
constructed classifiers for \gls{alpha} based on the three tree shape
statistics discussed above. The \software{kernlab}
package~\autocite{zeileis2004kernlab} was used to create a \gls{kSVM}
classifier using the computed kernel matrix, and the \software{e1071}
package~\autocite{meyer2015e1071} was used to create ordinary \gls{SVM}
classifiers using the pairwise \gls{nltt} matrix and Sackin's index values.
\del{Finally, we performed an ordinary linear regression of \gls{alpha} against
Sackin's index.} Each of these classifiers was evaluated with 1000 two-fold
cross-validations \add{with equally-sized folds}. We also performed a
\gls{kPCA} projection of the kernel matrix, and used it to visualize the
separation of the different \gls{alpha} values in the tree kernel's feature
space. A schematic of this experiment is presented in \cref{fig:kernelexpt}.

\begin{figure}[ht]
    \centering
    \includegraphics{kernel-expt.pdf}
    \caption[
        Schematic of classifier experiments investigating identifiability of BA
        model parameters from tree shapes.
    ]{
        Schematic of classifier experiments investigating identifiability of BA
        model parameters from tree shapes. The parameters of the BA model were
        varied one at a time \add{while holding all others fixed}. Transmission
        trees were simulated under three different values of each
        parameter\del{, then compared pairwise using the tree kernel.}
        Classifiers were constructed for each parameter \add{based on three
        tree shape statistics}, and their accuracy was evaluated by
        cross-validation. Kernel-\gls{PCA} projections were used to visually
        examine the separation of the trees in the feature space defined by the
        tree kernel.
    }
    \label{fig:kernelexpt}
\end{figure}

Similar experiments were performed with the values shown in
\cref{tab:kernelexpt}. The other three \gls{BA} parameters, \gls{N}, \gls{m},
and \gls{I}, were each varied while holding the others fixed. The experiments
for \gls{alpha}, \gls{m}, and \gls{N} were repeated with three different values
of \gls{I}. All experiments were repeated with trees having three different
numbers of tips. Kernel matrices were computed for all pairs of the
meta-parameters \gls{lambda} = \sett{0.2, 0.3, 0.4} and \gls{sigma} =
\sett{\nicefrac18, \nicefrac14, \nicefrac12, 1, 2, 4, 8}.

\begin{landscape}
\begin{table}[ht]
    \centering
    \input{\tablepath/kernel-expt}
    \caption[
        Values of parameters and meta-parameters used in classifier experiments
        to investigate identifiability of BA model parameters from tree shapes.
    ]{
        Values of parameters and meta-parameters used in classifier experiments
        to investigate identifiability of BA model parameters from tree shapes.
        Each row corresponds to one of the BA model parameters. One kernel
        matrix was created for every combination of values except the one
        indicated in the ``varied parameter'' column, which was varied when
        producing simulated trees.
    }
    \label{tab:kernelexpt}
\end{table}

\begin{table}[ht]
    \centering
    \input{\tablepath/gridsearch-expt}
    \caption[
        Values of parameters and meta-parameters used in grid search
        experiments to further investigate identifiability of BA model
        parameters.
    ]{
        Values of parameters and meta-parameters used in grid search
        experiments to further investigate identifiability of BA model
        parameters. Trees were simulated under the test values, and compared to
        a grid of trees simulated under the grid values. Kernel scores were
        used to calculate point estimates and credible intervals for each
        parameter, which were compared to the test values.
    }
  \label{tab:gridexpt}
\end{table}
\end{landscape}

\subsubsection*{Grid search}

\add{The previous experiment was an exploratory analysis intended to determine
which of the \gls{BA} parameters were identifiable, and whether the tree kernel
could potentially be used to distinguish different parameter values when all
others were held fixed. In this experiment, which was still of an exploratory
nature, we continued to consider one parameter at a time while fixing the other
three. However, rather than checking for identifiability, we were now
interested in quantifying the accuracy and precision of kernel score-based
estimates. This was done by examining the distribution of kernel scores on a
grid of parameter values, when trees simulated according to those values were
compared with a single simulated test tree.}

As in the previous section, we will begin by describing a single experiment,
and then list the variables for which similar experiments were performed. We
varied \gls{alpha} along a narrowly spaced grid of values: 0, 0.01, \ldots, 2.
For each value, fifteen networks were generated with \software{igraph}, and
transmission trees were simulated over each using \software{nettree}. These
trees will be referred to as ``grid trees''. Next, one further test tree was
simulated with the test value \gls{alpha} = 0. Both the grid trees and the test
tree had 500 tips, and were simulated with the other \gls{BA} parameters set to
\add{the known values} $\gls{N} = 5000$, $\gls{m} = 2$, and $\gls{I} = 1000$.
The test tree was compared to each of the grid trees using the tree kernel,
with the meta-parameters set to $\gls{lambda} = 0.3$ and $\gls{sigma} = 4$,
using the \software{treekernel} binary. The median kernel score was calculated
for each grid value, and the scores were normalized such that the area under
the curve was equal to 1. \del{The grid value with the highest median kernel
score was taken as the point estimate for the test value.} \add{For all
parameters except \gls{m}}, 50\% and 95\% highest density intervals were
obtained using the \software{hpd} function in the \software{TeachingDemos}
package~\autocite{snow2013teachingdemos}. \add{Since the \software{hpd}
function assumes a continuous distribution, we implemented our own version for
discrete distributions to use for \gls{m}.}

Each experiment of the type just described was repeated ten times with the same
test value. Similar experiments were performed for each of the four \gls{BA}
parameters, with several test values and trees of varying sizes. The variables
are listed in \cref{tab:gridexpt}. A graphical schematic of the grid search
experiments is shown in \cref{fig:gridexpt}. 

\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{gridsearch-expt}
    \caption[
        Schematic of grid search experiment to further investigate
        identifiability of BA model parameters from tree shapes.
    ]{
        Schematic of grid search experiment to further investigate
        identifiability of BA model parameters from tree shapes. Trees were
        simulated along a narrowly spaced grid of values of one parameter
        (``grid trees'') \add{with all other parameters fixed to known values}.
        Separate trees were simulated for a small subset of the grid values
        (``test trees''), \add{also holding the other parameters fixed}. Each
        test tree was compared to every grid tree using the tree kernel, and
        the resulting kernel scores were normalized to resemble a probability
        density from which the mode and 95\% highest density interval were
        calculated.
    }
    \label{fig:gridexpt}
\end{figure}

\subsubsection*{Approximate Bayesian computation}

\add{Our final synthetic data experiment was designed to test the full
\gls{ABC}-\gls{SMC} algorithm by jointly estimating the four parameters of the
\gls{BA} model. We used the standard validation approach of simulating
transmission trees under the model with known parameter values and attempting
to recover those values with \software{netabc}. The algorithm was not informed
of any of the true parameter values for the main set of simulations. Despite
the fact that the parameter values used to generate the simulated transmission
trees were known, the true posterior distributions on the \gls{BA} parameters
were unknown. Therefore, any apparent errors or biases in the estimates could
be due to either poor performance of our method, or to real features of the
posterior distribution. The latter type of error reflects on the suitability of
the model, but does not invalidate the use of our method in cases where the
parameters are more identifiable. Two retrospective experiments were performed
to disambiguate some of the observed errors: one where we ran a simulation with
increased computational power to test for an increase in accuracy, and a second
where we estimated parameters marginally to remove confounding from the other
parameters in the joint posterior.}

\del{We simulated three trees each under a variety of parameter values and ran
the \software{netabc} program to estimate posterior distributions for the
parameters.} The parameter values and priors used are listed in
\cref{tab:abcexpt}. The tree kernel meta-parameters were set to $\gls{lambda} =
0.3$ and $\gls{sigma} = 4$. The \gls{SMC} algorithm was run with 1000
particles, five sampled datasets per particle, and \gls{alphaess} \del{(not to
be confused with the \gls{BA} preferential attachment parameter, see
\cref{subsec:adaptsmc})} set to 0.95. The algorithm was stopped when the
acceptance rate of the \gls{MH} kernel dropped below 1.5\%, the same criterion
used by \textcite{del2012adaptive}. \add{For visualization,} approximate
marginal posterior densities for each parameter were calculated using the
\software{density} function in \software{R} applied to the final weighted
population of particles. \del{Credible intervals were obtained for each
parameter using the \software{HPDinterval} function in the \software{coda}
package~\autocite{plummer2006coda}.} \add{Posterior means obtained for each
parameter using the \software{wtd.mean} function in the \software{Hmisc}
package~\autocite{harrell2016hmisc}. Credible intervals were obtained using the
\software{hpd} function in the \software{TeachingDemos}
package~\autocite{snow2013teachingdemos} for \gls{alpha} \gls{I}, and \gls{N}, 
and using our own implementation for discrete distributions for \gls{m}.}

\begin{table}[ht]
    \centering
    \input{\tablepath/abc-expt}
    \caption[
        Parameter values used in simulation experiments to test accuracy of
        \gls{BA} model fitting with \software{netabc}.
    ]{
        Parameter values used in simulation experiments to test accuracy of
        \gls{BA} model fitting with \software{netabc}. Trees were simulated
        under the test values, and \software{netabc} was used to estimate
        posterior distributions on the \gls{BA} parameters for each simulated
        tree. \software{Netabc} was na\"ive to the true parameter values.
    }
    \label{tab:abcexpt}
\end{table}

\add{To evaluate the effects of the true parameter values on the accuracy of
the posterior mean estimates, we analyzed the \gls{alpha} and \gls{I}
parameters individually using \glspl{GLM}. The response variable was the error
of the point estimate, and the predictor variables were the true values of
\gls{alpha}, \gls{I}, and \gls{m}. We did not test for differences across true
values of \gls{N}, because \gls{N} was not varied in these simulations. The
distribution family and link function for the \glspl{GLM} were chosen as
Gaussian and inverse, respectively, by examination of residual plots and
\gls{AIC}. The $p$-values of the estimated \glspl{GLM} coefficients were
corrected using Holm-Bonferroni correction~\autocite{holm1979simple} with $n =
6$ (two \glspl{GLM} with three predictors each). Because there was clearly
little to no identifiability of \gls{N} and \gls{m} with \gls{ABC} (see results
in next section), we did not construct \glspl{GLM} for those parameters.}

Two further simulations were performed to address \del{potential sources of
error} \add{the possible impact of two types of model misspecification}. To
consider the effect of heterogeneity among nodes, we generated a network where
half the nodes were attached with power $\gls{alpha} = 0.5$ and the other half
with power $\gls{alpha} = 1.5$. The other parameters for this network were
$\gls{N} = 5000$, $\gls{I} = 1000$, and $\gls{m} = 2$. To investigate the
effects of potential sampling bias~\autocite{karcher2016quantifying}, we
simulated a transmission tree where the tips were sampled in a peer-driven
fashion, rather than at random. That is, the probability to sample a node was
twice as high if any of that node's network peers had already been sampled. The
parameters of this network were $\gls{N} = 5000$, $\gls{I} = 2000$, $\gls{m} =
2$, and $\gls{alpha} = 0.5$.

\add{To assess the impact of the \gls{SMC} settings on \software{netabc}'s
accuracy, we ran \software{netabc} twice on the same simulated transmission
tree. For the first run, the \gls{SMC} settings were the same as in the other
simulations: 1000 particles, 5 simulated transmission trees per particle, and
\gls{alphaess} = 0.95. The second run was performed with 2000 particles, 10
simulated transmission trees per particle, and \gls{alphaess} = 0.97. To
investigate the extent to which errors in the estimated \gls{BA} parameters
were due to true features of the posterior, rather than an inaccurate \gls{ABC}
approximation, we performed marginal estimation for one set of parameter
values. Each combination of 1, 2, or 3 model parameters (14 combinations total)
was fixed to their known values, and the remaining parameters were estimated
with \software{netabc}. The parameter values were $\gls{alpha} = 0.0$, $\gls{m}
= 2$, $\gls{I} = 2000$, and $\gls{N} = 5000$.}

\subsection{Results}

\subsubsection*{Classifiers for BA model parameters based on tree shape}



Trees simulated under different values of \gls{alpha} were visibly quite
distinct (\cref{fig:alphatrees}). In particular, higher values of \gls{alpha}
produce networks with a small number of highly connected nodes, which, once
infected, are likely to transmit to many other nodes. This results in a more
unbalanced, ladder-like structure in the phylogeny, compared to networks with
lower \gls{alpha} values. None of the other three parameters produced trees
that were as easily distinguished from each other
(\cref{fig:Itrees,fig:mtrees,fig:Ntrees,fig:Itrees}).  Sackin's index, which
measures tree imbalance, was significantly correlated with all four parameters
    (for \gls{alpha}, \gls{I}, \gls{m}, and \gls{N} respectively: Spearman's rho =
    0.85,
     \ensuremath{-0.12},
     \ensuremath{-0.13},
     0.09;
     $p$-values
     ${<}10^{-5}$,
     $0.003$,
     ${<}10^{-5}$,
     ${<}10^{-5}$).
The ratio of internal to terminal branch lengths was negatively correlated with
\gls{alpha} and \gls{I}, and positively correlated with \gls{m} and \gls{N}
  (Spearman's rho
    \ensuremath{-0.8},
    \ensuremath{-0.69},
    0.09,
    0.17;
all $p < 10^{-5}$).

\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{kernel-alpha-tree.pdf}
    \caption[
        Simulated transmission trees under three different values of
        preferential attachment power (\gls{alpha}) parameter of \acrshort{BA}
        model.
    ]{
        Simulated transmission trees under three different values of
        preferential attachment power (\gls{alpha}) parameter of \acrshort{BA}
        model. Epidemics were simulated on \gls{BA} networks of 5000 nodes,
        with \gls{alpha} equal to 0.5, 1.0, or 1.5, until 1000 individuals were
        infected. Transmission trees were created by randomly sampling 500
        infected nodes. Higher \gls{alpha} values produced networks with a
        small number of highly-connected nodes, resulting in highly unbalanced,
        ladder-like trees.
    }
  \label{fig:alphatrees}
\end{figure}

\Cref{fig:kpca} shows \gls{kPCA} projections of the simulated trees onto the
first two principal components of the kernel matrix. The figure shows only the
simulations with 500-tip trees and 1000 infected nodes. The three \gls{alpha}
and \gls{I} values considered are well separated from each other in the feature
space \add{mapped to by the tree kernel}. On the other hand, the three \gls{N}
values overlap significantly, and the three \gls{m} values are virtually
indistinguishable. Similar observations can be made for other values of \gls{I}
and the number of tips (\cref{fig:alphakpca,fig:Nkpca,fig:Ikpca,fig:mkpca}).
The values of \gls{I} and \gls{N} separated more clearly with larger numbers of
tips, and in the case of \gls{N}, with larger epidemic sizes
\add{(\cref{fig:Ikpca,fig:Nkpca})}.

\begin{figure}[ht]
    \centering
    \includegraphics{kernel-kpca.pdf}
    \caption[
        Kernel-\gls{PCA} projections of simulated trees under varying \gls{BA}
        parameter values.
    ]{
        Each parameter of the \gls{BA} model was individually varied to produce
        300 simulated trees with 500 tips each. Kernel matrices were formed
        from all pairwise kernel scores among each set of 300 trees. The trees
        were projected onto the first two principal components of the kernel
        matrix calculated using \gls{kPCA}. The other parameters, which were
        not varied, were set to $\gls{alpha} = 1$, $\gls{I} = 1000$, $\gls{m} =
        2$, and $\gls{N} = 5000$. The tree kernel meta-parameters were
        $\gls{lambda} = 0.3$ and $\gls{sigma} = 4$.
  }
  \label{fig:kpca}
\end{figure}



The accuracy of each classifier, which is the proportion of trees assigned the
correct parameter value, \add{is shown in} \del{varied based on the parameter
being tested} \cref{fig:rsquared} \add{Since there were three possible values,
random guessing would produce an accuracy of 0.33.} Classifiers based on
\del{two other tree statistics,} the \gls{nltt} and Sackin's index generally
exhibited worse performance than the tree kernel, although the magnitude of the
disparity varied between the parameters (\cref{fig:rsquared}, centre and
right). The results were largely robust to variations in the tree kernel
meta-parameters \gls{lambda} and \gls{sigma}, although accuracy varied between
different epidemic and sampling scenarios
(\cref{fig:alphacrossv,fig:mcrossv,fig:Icrossv,fig:Ncrossv}). \add{For all
parameters except \gls{m}, the absolute number of tips in the tree had a much
greater impact on accuracy than the proportion of infected individuals these
tips represented. However, for \gls{m}, both the number and proportion of
sampled tips had a strong impact or the accuracy of the \gls{kSVM}
(\cref{fig:mcrossv}).}

\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{kernel-rsquared.pdf}
    \caption[
        Cross-validation accuracy of kernel-SVM, nLTT-based SVM, and Sackin's
        SVM classifiers for BA model parameters.
    ]{
        Cross-validation accuracy of kernel-SVM classifier (left), SVM
        classifier using \gls{nltt} (centre), and SVM using Sackin's index
        (right) for \gls{BA} model parameters. Kernel meta-parameters were set
        to $\gls{lambda} = 0.3$ and $\gls{sigma} = 4$. Each point was
        calculated based on 300 simulated transmission trees over networks with
        three different values of the parameter being tested, assuming perfect
        knowledge of the other parameters. Vertical lines are empirical 95\%
        confidence intervals based on 1000 two-fold cross-validations. \add{The
        classifiers for \gls{I} were not evaluated with 1000-tip trees, because
        one of the tested \gls{I} values was 500, and it is not possible to
        sample a tree of size 1000 from 500 infected individuals.}
    }
    \label{fig:rsquared}
\end{figure}

The \gls{kSVM} classifier for \gls{alpha} had an average accuracy of 
    0.92,
compared to 
    0.6
for the \gls{nltt}-based SVM, and
    0.77
for Sackin's index. There was little variation about the mean for different
tree and epidemic sizes. No classifier could accurately identify \gls{m} in any
epidemic scenario, with average accuracy values of 
  0.35 for \gls{kSVM},
  0.32 for the \gls{nltt}, and
  0.38
for Sackin's index. Again, there was little variation in accuracy between
epidemic scenarios, although the accuracy of the \gls{kSVM} was slightly higher
on 1000-tip trees 
    (average 
     0.33,
     0.35,
     0.38
     for 100, 500, and 1000 tips respectively).

The accuracy of classifiers for \gls{I} \del{varied significantly
with}\add{appeared to be strongly influenced by} the number of tips in the
tree. For 100-tip trees, the average accuracy values were
  0.59,
  0.58, and
  0.34
for the tree kernel, \gls{nltt}, and Sackin's index respectively. For 500-tip
trees, the values increased to
  0.99,
  0.76, and
  0.37.
Finally, the performance of classifiers for $N$ depended heavily on the
epidemic scenario. The accuracy of the \gls{kSVM} classifier ranged from
  0.36
for the smallest epidemic and smallest sample size, to
  0.81
for the largest. Likewise, accuracy for the \gls{nltt}-based SVM ranged from 
  0.33
to
  0.63.
Sackin's index did not accurately classify $N$ in any scenario, with an average
accuracy of
  0.35
and little variation between scenarios.

\subsubsection*{Marginal parameter estimates with grid search}



\del{The accuracy of grid search estimates largely paralleled that of the
\gls{kSVM} classifiers.} \Cref{fig:gridest} shows point estimates and
\add{50\%} and 95\% highest density intervals for each of the \gls{BA}
parameters, for one replicate experiment with 500-tip trees. Plots showing the
point estimates for all replicates can be found in
\cref{fig:gridptalpha,fig:gridptI,fig:gridptm,fig:gridptN}. For all parameters
except \gls{m}, the error of point estimates was negatively correlated with the
number of sampled tips in the tree (for \gls{alpha}, \gls{I}, and \gls{N}
respectively: Spearman's $\rho$ = 
    \ensuremath{-0.22},
    \ensuremath{-0.51}, 
    \ensuremath{-0.16}; 
$p$-values
    $4\!\times\!10^{-4}$,
    ${<}10^{-5}$,
    $0.01$).
The 95\% highest density intervals obtained for all parameters were extremely
wide, occupying $>$75\% of the grid in all cases (\cref{fig:gridest}).

\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{gridsearch-example}
    \caption[
        Grid search estimates of \gls{BA} model parameters for one replicate
        experiment with trees of size 500.
    ]{
        Grid search estimates of \gls{BA} model parameters for one replicate
        experiment with trees of size 500. Point estimates (dots), 95\%
        \glspl{HDI} (lines), and 50\% \glspl{HDI} (notches) for each \gls{BA}
        model parameter, obtained using grid search. Networks and transmission
        trees were simulated over a grid of values for each parameter while
        holding the others fixed \add{to known values}. For a subset of the
        grid values ($x$-axis), test networks and trees were created and
        compared to each tree on the grid using the tree kernel. The kernel
        scores along the grid were normalized to resemble a probability
        distribution, from which the mode and highest density interval were
        calculated.
    } 
    \label{fig:gridest}
\end{figure}

\add{Across all replicates, $R^2$ values for the correlations between the
estimated and true values were
    $0.91$,
    $0.91$,
    $0.25$, and
    $0.54$
for \gls{alpha}, \gls{I}, \gls{m}, and \gls{N} respectively. The mean absolute
errors of the point estimates were
    $0.14$,
    $310$,
    $1.31$, and
    $2419$,
representing
    $7$\%,
    $8$\%,
    $26$\%, and
    $17$\%
of the respective grids. Note that \cref{fig:gridest} contains only one
replicate data point per parameter value, out of ten total. For \gls{I} and
\gls{N}, relative errors may be more appropriate to consider. An overestimate
of 100 individuals would be very misleading if the true population was only of
size 100, but almost negligible in a population of size 5000. The mean relative
errors for \gls{I} and \gls{N} respectively were
    $18$\% and 
    $31$\%.}

\add{Qualitatively, \gls{alpha} and \gls{I} exhibited weak identifiability
within particular sections of the grid (\cref{fig:gridest}). The 50\%
\glspl{HDI} for \gls{alpha} were similar for the values $\gls{alpha}
\leq 0.5$ (on average 
    0.02 -
    0.84)
and for $\gls{alpha} \geq 1.5$ 
    (1.26 -
    2).
For \gls{I}, similar 50\% \gls{HPD} were observed for $\gls{I} \leq 1500$
(average 
    [650 -
     2846])
and for $\gls{I} > 3000$ 
    ([2596 -
      4802]).
No similar patterns were observed for \gls{m} or \gls{N} (although the 50\%
\glspl{HDI} appear to be identical for $\gls{m} > 2$ in \cref{fig:gridexpt},
this was not consistent across replicates).}

\add{\Cref{fig:gridalpha,fig:gridI,fig:gridm,fig:gridN} show kernel score
distributions of kernel scores along the grid for each parameter. The
distributions for some values, such as $\gls{alpha} = 1.25$, $\gls{I} = 500$
and $4500$, $\gls{m} = 1$, and $\gls{N} = 1000$, exhibited distinct peaks
around the true value. This indicates that these values produce distinctively
shaped trees that can be identified with the tree kernel, when the other
parameter values are fixed and known. However, for the majority of values of
each parameter, the score distributions were fairly flat around the true value. 
This means there is a range of values which produce similarly shaped trees, and
the parameter is less identifiable within that range. The exception was
\gls{I}, whose score distributions exhibited a more or less rounded shape with
the highest point near the true value.}

\del{The \gls{alpha} parameter was the most accurately estimated,
with point estimates having an average deviation of 
    0.14
from the true value, on a grid from 0 to 2. The error of point estimates varied
significantly between true values of \gls{alpha}
    (one-way \gls{ANOVA}, $p$ ${<}10^{-5}$). In
particular, errors were lower for the values \gls{alpha} = 1.0 and 1.25 than
for the other values
    (average errors 
    0.03
    for \gls{alpha} = 1.0 or 1.5 vs.
    0.17
    for \gls{alpha} $\neq$ 1.0 or 1.5),
and this difference was significant
    (Wilcoxon rank-sum test, $p {<}10^{-5}$,
\cref{fig:gridptalpha}). These two values exhibited different qualitative
behaviour than the other values in terms of the distribution of kernel scores
along the grid (\cref{fig:gridalpha}). In particular, there was a pronounced
peak in scores around the true value, in contrast to the other values where the
scores were flat around the true value. The effect was most obvious for the
value \gls{alpha} = 1.25.}

\subsubsection*{Joint parameter estimates with \software{netabc}}



\Cref{fig:abcpt} shows \del{MAP} \add{stratified posterior mean} point
estimates of the \gls{BA} model parameters \add{\gls{alpha} and \gls{I}}
obtained with \gls{ABC} on simulated data. \add{The parameters $m$ and $N$ were
not identifiable with ABC for any parameter combinations (\cref{fig:abcpt2}).}
\del{The estimates shown correspond only to the simulations where \gls{m} was
set to 2, however the results for $\gls{m} = 3$ and $\gls{m} = 4$ were
similar.} Average boundaries of 95\% \gls{HPD} intervals are given in
\cref{tab:abchpd}.

\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{abc-boxplot}
    \caption[
        Posterior mean point estimates for BA model parameters $\alpha$ and $I$
        obtained by running \textit{netabc} on simulated data, stratified by
        true parameter values.
    ]{
        Posterior mean point estimates for BA model parameters $\alpha$ and $I$
        obtained by running \textit{netabc} on simulated data, stratified by
        true parameter values. First row of plots contains true versus
        estimated values of $\alpha$; second row contains true versus estimated
        values of $I$. Columns are stratified by $\alpha$, $I$, and $m$
        respectively. Dashed lines indicate true values. 
    }
    \label{fig:abcpt}
\end{figure}

\begin{table}[ht]
    \centering
    \input{\tablepath/abc-hpd.tex}
    \caption[
        Average posterior mean point estimates and 95\% \gls{HPD} interval
        widths for \gls{BA} model parameter estimates obtained with
        \software{netabc} on simulated data.
    ]{
        Average posterior mean point estimates and 95\% \gls{HPD} interval
        widths for \gls{BA} model parameter estimates obtained with
        \software{netabc} on simulated data. Three transmission trees were
        simulated under each combination of the listed parameter values, and
        the parameters were estimated with \gls{ABC} without training.
    }
    \label{tab:abchpd}
\end{table}

\add{Across all simulations, the median [\gls{IQR}] absolute errors of the parameter 
estimates obtained with \software{netabc} were
    0.11 
    [0.03 - 
    0.25]
for \gls{alpha},
    492 
    [294 - 
    782]
for \gls{I},
    1 
    [0 - 
    1]
for \gls{m}, and
    4153 
    [3660 - 
    4489]
for \gls{N}. These errors comprised, respectively,
    6\%,
    11\%,
    17\%, and
    29\%
of the regions of nonzero prior density. For \gls{I} and \gls{N}, relative
errors were
    38\%
    [20 - 
    50\%]
and
    83\%
    [73 - 
    90\%].
Average 95\% \gls{HPD} interval widths were
    0.68,
    2454,
    3.01, and
    12046,
representing 
    34\%,
    55\%,
    50\%, and
    83\%
of the nonzero prior density regions. Point estimates of \gls{I} were upwardly
biased: \gls{I} was overestimated in
    69
out of 
    72
simulations
    (96\%).
The estimates for \gls{m} and \gls{N} were similar across all simulations
(median [\gls{IQR}] point estimates
    3
    [3 - 
    3]
and 
    9153
    [8660 - 
    9489])
regardless of the true values of any of the \gls{BA} parameters.}

\add{To analyze the effects of the true parameter values on the
accuracy our estimates of \gls{alpha} and \gls{I}, we fitted one \gls{GLM}
for each of these two parameters, with error rate as the dependent variable and
the true parameter values as independent variables. Since the estimates of
\gls{m} and \gls{N} were roughly equal across all simulations
(\cref{fig:abcpt2}), \glspl{GLM} were not fitted for these parameters. The
estimated coefficients are shown in \cref{tab:glmalpha,tab:glmI}. The \gls{GLM}
were fitted using the inverse link function. That is, if $p$ is the true value
of the parameter and $\hat{p}$ is a random variable representing our estimate
of the parameter, the \gls{GLM} posits a relationship of the form}
\[
    \madd{\E(|p-\hat{p}|) = (\beta_0 + \beta_\alpha \alpha + \beta_I I + \beta_m m)^{-1}},
\]
\add{where the $\beta$'s are coefficients to be fitted. If the true value
\gls{alpha}, say, is increased by one, the \emph{inverse} of the expected
absolute error will increase by $\beta_\alpha$. If $\beta_\alpha$ is positive,
it means that the absolute error decreases as the true value of \gls{alpha}
increases.}



% latex table generated in R 3.2.3 by xtable 1.8-2 package
% Mon Jul 18 11:53:42 2016
\begin{table}[ht]
\centering
\begin{tabular}{llll}
  \hline
Parameter & Estimate & Standard error & $p$-value \\ 
  \hline
(Intercept) & $2$ & $0.6$ & $0.01$ \\ 
  $\alpha$ & $10$ & $2$ & ${<}10^{-5}$ \\ 
  $I$ & $-3\!\times\!10^{-4}$ & $2\!\times\!10^{-4}$ & $0.7$ \\ 
  $m$ & $0.5$ & $0.2$ & $0.01$ \\ 
   \hline
\end{tabular}
\caption[Parameters of a fitted \gls{GLM} relating error in estimated \gls{alpha} to true values of \gls{BA} parameters.]{Parameters of a fitted \gls{GLM} relating error in estimated \gls{alpha} to true values of \gls{BA} parameters. \gls{GLM} was fitted with a Gaussian distribution and inverse link function. Coefficients are interpretable as additive effects on the inverse of the mean error.} 
\label{tab:glmalpha}
\end{table}
% latex table generated in R 3.2.3 by xtable 1.8-2 package
% Mon Jul 18 11:53:42 2016
\begin{table}[ht]
\centering
\begin{tabular}{llll}
  \hline
Parameter & Estimate & Standard error & $p$-value \\ 
  \hline
(Intercept) & $0.004$ & $5\!\times\!10^{-4}$ & ${<}10^{-5}$ \\ 
  $\alpha$ & $-0.001$ & $2\!\times\!10^{-4}$ & ${<}10^{-5}$ \\ 
  $I$ & $-4\!\times\!10^{-7}$ & $2\!\times\!10^{-7}$ & $0.05$ \\ 
  $m$ & $-7\!\times\!10^{-5}$ & $8\!\times\!10^{-5}$ & $1$ \\ 
   \hline
\end{tabular}
\caption[Parameters of a fitted \gls{GLM} relating error in estimated \gls{I} to true values of \gls{BA} parameters.]{Parameters of a fitted \gls{GLM} relating error in estimated \gls{I} to true values of \gls{BA} parameters. GLM was fitted with a Gaussian distribution and inverse link function. Coefficients are interpretable as additive effects on the inverse of the mean error.} 
\label{tab:glmI}
\end{table}


\add{The \gls{GLM} analysis indicated that the error in estimates of
\gls{alpha} decreased with larger true values of \gls{alpha} 
    ($p {<}10^{-5}$)
and \gls{m}
    ($p =0.01$)
but was not significantly affected by \gls{I} (\cref{tab:glmalpha}).
Qualitatively, \gls{alpha} seemed to be only weakly identifiable between the
values of 0 and 0.5 (\cref{fig:abcpt}). The error in the estimated prevalence
\gls{I} was slightly lower for smaller values of \gls{alpha}
    ($p {<}10^{-5}$)
and \gls{I}
    ($p =0.05$),
but was not significantly affected by the true value of \gls{m}
(\cref{tab:glmI}).}

\del{The accuracy of the parameter estimates obtained with ABC paralleled the
results from the \gls{kSVM} classifier. Of the four parameters, $\alpha$ was
the most accurately estimated, with point estimates having a median [IQR]
absolute error of 
    0.11 
    [0.03 - 
    0.25].
The errors when the true value of $\alpha$ was zero were significantly greater
than those for the other values 
    (Wilcoxon rank-sum test, $p$ = 
    $0$).
Errors in estimating $\alpha$ did not vary across the true values of $m$ or $I$
(both one-way ANOVA).}

\del{Estimates for $I$ were relatively accurate, with point estimate errors of
    492 
    [294 - 
    782] individuals.
These errors were significantly higher when the true value of $\alpha$ was
at least 1
    (Wilcoxon rank-sum test, $p$ = 
    $0$)
and when the true value of $I$ was 2000 ($p < 10^{-5}$). The true value of $m$
did not affect the estimates of $I$ (one-way ANOVA).}

\del{The $m$ parameter was estimated correctly in
    37 \%
of simulations barely better than random guessing. The true values of the other
parameters did not significantly affect the
estimates of $m$ (both one-way ANOVA).}

\del{Finally, the total number of nodes $N$ was consistently over-estimated by about
a factor of two (error 4153
[3660 - 4489] individuals). No parameters influenced the accuracy of the $N$
estimates (all one-way ANOVA).}



The dispersion of the \gls{ABC} approximation to the posterior also varied
between the parameters (\cref{tab:abchpd}). \gls{HPD} intervals around
\gls{alpha} and \gls{I} were often narrow relative to the region of nonzero
prior density, whereas the intervals for \gls{m} and \gls{N} were more widely
dispersed. \Cref{fig:abclow1,fig:abclow2} \del{shows the distributions for one
simulation.} \add{show one- and two-dimensional marginal distributions for a
simulation with relatively low error. Each parameter was chosen based on its
mean error rate across all simulations. The parameters for this simulation were 
    $\gls{alpha} = 1.5$,
    $\gls{I} = 1000$,
    $\gls{m} = 4$, and
    $\gls{N} = 5000$.
\Cref{fig:abchigh1,fig:abchigh2} show the equivalent marginals for a different
simulation with relatively high error rates for each individual parameter. The
parameters were
    $\gls{alpha} = 0$,
    $\gls{I} = 2000$,
    $\gls{m} = 2$, and
    $\gls{N} = 5000$.
The two-dimensional marginals indicate some dependence between pairs of
parameters, particularly \gls{I} and \gls{N} which show a diagonally shaped
region of high posterior density.} 

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8\textwidth]{{abc-posterior/1.5_1000_4_5000_0}.pdf}
    \caption[
        One-dimensional marginal posterior distributions of \gls{BA} model
        parameters estimated with low error by \software{netabc} from a
        simulated transmission tree.
    ]{
        One-dimensional marginal posterior distributions of \gls{BA} model
        parameters estimated with low error by \software{netabc} from a
        simulated transmission tree. Dashed lines indicate true values, solid
        lines indicate posterior means, and shaded areas show 95\%
        \acrlong{HPD} intervals.
    }
    \label{fig:abclow1}
\end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{{abc-posterior-2d/1.5_1000_4_5000_0}.png}
    \caption[
        Two-dimensional marginal posterior distributions of \gls{BA} model
        parameters estimated with low error by \software{netabc} from a
        simulated transmission tree.
    ]{
        Two-dimensional marginal posterior distributions of \gls{BA} model
        parameters estimated with low error by \software{netabc} from a
        simulated transmission tree. White circles indicate true values,
        magenta diamonds indicate posterior means.
    }
    \label{fig:abclow2}
\end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8\textwidth]{{abc-posterior/0.0_2000_2_5000_0}.pdf}
    \caption[
        One-dimensional marginal posterior distributions of \gls{BA} model
        parameters estimated with high error by \software{netabc} from a
        simulated transmission tree.
    ]{
        One-dimensional marginal posterior distributions of \gls{BA} model
        parameters estimated with high error by \software{netabc} from a
        simulated transmission tree. Dashed lines indicate true values, solid
        lines indicate posterior means, and shaded areas show 95\%
        \acrlong{HPD} intervals.
    }
    \label{fig:abchigh1}
\end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{{abc-posterior-2d/0.0_2000_2_5000_0}.png}
    \caption[
        Two-dimensional marginal posterior distributions of \gls{BA} model
        parameters estimated with high error by \software{netabc} from a
        simulated transmission tree.
    ]{
        Two-dimensional marginal posterior distributions of \gls{BA} model
        parameters estimated with high error by \software{netabc} from a
        simulated transmission tree. White circles indicate true values,
        magenta diamonds indicate posterior means.
    }
    \label{fig:abchigh2}
\end{figure}



To test the effect of model misspecification, we simulated one network where
the nodes exhibited heterogeneous preferential attachment power (half 0.5, the
other half 1.5), with $\gls{m} = 2$, $\gls{N} = 5000$, and $\gls{I} = 1000$.
The posterior mean [95\% \gls{HPD}] estimates for each parameter were: 
\gls{alpha},
  1.03 
  [0.67 -
   1.18];
\gls{I},
  1474 
  [511 -
   2990];
\gls{m},
  3 
  [1 -
   5];
\gls{N},
  9861 
  [3710-
   14977].
\del{The one-dimensional marginal approximate posterior distributions for this
simulation are shown in \cref{fig:mixed}.} To test the effect of sampling bias,
we sampled one transmission tree in a peer-driven fashion, where the
probability to sample a node was twice as high if one of its peers had already
been sampled. The parameters for this experiment were $\gls{N} = 5000$,
$\gls{m} = 2$, $\gls{alpha} = 0.5$, and $\gls{I} = 2000$. The estimated values
were: \gls{alpha},
  0.3 
  [0 -
   0.63];
\gls{I},
  2449 
  [1417 -
   3811];
\gls{m},
  3 
  [2 -
   5];
\gls{N},
  9132 
  [2852 -
   14780].
\del{The approximate posterior distributions are shown in \cref{fig:peerdriven}.}
Both of these results were in line with estimates obtained on other simulated
datasets (\cref{tab:abchpd}), although the estimate of peer-driven sampling for
\gls{alpha} was somewhat lower than typical.



\add{\Cref{fig:marginal} shows the effect of performing marginal ABC estimation
of each of the BA parameters on the same simulated transmission tree. The
estimates of $m$ were apparently unaffected by marginalizing out the other
parameters, corroborating the previous experiments' findings that $m$ is not an
identifiable parameter from scaled tree shapes. Compared to allowing all
parameters to vary, estimates of $\alpha$, $I$, and $N$ were improved by
    41\%,
    59\%, and
    46\%
when all other parameters were fixed. \Cref{fig:better} shows the impact of
increasing the number of particles, simulated datasets, and
$\alpha_{\text{ESS}}$ parameter on the accuracy of a single simulation. The
results of the two simulations were similar, but surprisingly, the results with
higher SMC settings were slightly worse (by
    10\%,
    8\%, and
    11\%
for $\alpha$, $I$, and $N$ respectively). However, the 50\% HPD interval for
$I$ was closer to the true value of 2000 with the improved settings
    (2338 - 
     3423, vs.
     2810 - 
     3767 with basic settings).
The estimate of $m$, 3 in both cases, was unaffected by the settings.}

\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{abc-marginal.pdf}
    \caption[
        Marginal posterior mean estimates and 50\%/95\% \gls{HPD} intervals of
        \gls{BA} model parameters when some parameters were fixed.
    ]{
        Marginal posterior mean estimates (points), 50\% \gls{HPD} intervals
        (notches), and 95\% \gls{HPD} intervals (lines) of \gls{BA} model
        parameters when some parameters ($x$-axis) were fixed. Parameters were
        fixed by specifying a Dirac-delta prior at the true value. True values
        are indicated by horizontal dashed lines.
    }
    \label{fig:marginal}
\end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.7\textwidth]{better-smc}
    \caption[
        Comparison of \gls{BA} parameter estimates obtained with
        \software{netabc} on the same dataset with different \gls{SMC}
        settings.
    ]{
        Comparison of \gls{BA} parameter estimates obtained with
        \software{netabc} on the same dataset with different \gls{SMC}
        settings. Points are posterior means, notches are 50\% \gls{HPD}
        intervals, and lines are 95\% \gls{HPD} intervals.
    }
    \label{fig:better}
\end{figure}

\section{Application to real world HIV data}
\label{sec:hiv}

\subsection{Methods}

Because the \gls{BA} model assumes a single connected contact network, it is
most appropriate to apply to groups of individuals who are epidemiologically
related. Therefore, we searched for published \gls{HIV} datasets which
originated from existing clusters, either phylogenetically or geographically
defined. \add{To identify datasets fitting these criteria, we used the
\software{Entrez} module in the \software{BioPython}
library~\autocite{cock2009biopython} to identify all studies which were linked
to at least 150 sequences of the same \gls{HIV} gene in GenBank (635 at the
time when the data was collected). We manually curated a subset of these
articles which, based on their title and abstract, appeared to have sampled one
sequence per individual in a group likely to be epidemiologically related. For
example, studies were excluded if they were investigating response to a
particular drug, pregnant women or pediatric \gls{HIV} patients, intra-host
evolution, or a multi-region or multi-country cohort. We acknowledge that our
perusal of the complete set of articles was rather cursory, often limited to
reading the title, and it is quite possible that we failed to identify other
studies which would have been suitable to include. Each potential dataset was
revisited, and those without sampling time annotation in GenBank were excluded.
We also excluded studies where all sequences were sampled at the same
timepoint, which was necessary because the method we used to time scale the
tree requires non-contemporaneous tips.} The datasets are summarized in
\cref{tab:data}. In addition \add{to the published data}, we analyzed an
in-house dataset sampled from \gls{HIV}-positive individuals in British
Columbia, Canada. \add{For clarity, we will refer to each dataset by its risk
group and location of origin in the text. For example, the
\textcite{zetterberg2004two} data will be referred to as IDU/Estonia.}

\begin{table}[ht]
    \centering
    \input{\tablepath/realdata-bc}
    \caption[
        Characteristics of published \gls{HIV} datasets analyzed with
        \software{netabc}.
    ]{
        Characteristics of published \gls{HIV} datasets analyzed with
        \software{netabc}. Abbreviations: \acrshort{MSM}, \acrlong{MSM}; HET,
        heterosexual; \acrshort{IDU}, \acrlong{IDU}. The HET data were sampled
        from a primarily heterosexual risk environment but did not explicitly
        exclude other risk factors. The number of sequences column indicates
        how many sequences were included in our analysis; there may have been
        additional sequences linked to the study which we excluded for various
        reasons (see methods).
    }
  \label{tab:data}
\end{table}

We downloaded all sequences associated with each published study from GenBank.
\add{For the IDU/Romania data, only sequences from \gls{IDU} (whose sequence
identifiers included the letters ``DU'') were included in the analysis.
\textcite{kao2011surveillance} (MSM/Taiwan) found a strong association in their
study population between subtype and risk group - subtype B was most often
associated with \gls{MSM}, whereas \gls{IDU} were usually infected with a
circulating recombinant form. Since there were many more subtype B sequences in
their data than sequences of other subtypes, we restricted our analysis to the
subtype B sequences and labelled this dataset as \gls{MSM}. Two datasets
(HET/Uganda and HET/Malawi) included both \textit{env} and \textit{gag}
sequences. Each gene was analyzed separately to assess the robustness of
\software{netabc} to the particular \gls{HIV} gene sequence used to estimate a
transmission tree. The IDU/Estonia data also sequenced both genes, but the
highly variable coverage and high homology of the \textit{gag} sequences made
it impossible to obtain a sufficiently large block of non-identical sequences
to analyze. Therefore, we analyzed only \textit{env} for this dataset.}

\del{For the \textcite{novitsky2014impact} data,} Each \textit{env} sequence
was aligned pairwise to the HXB2 reference sequence (GenBank accession number
K03455), and the hypervariable regions were clipped out with
\software{BioPython} version 1.66+~\autocite{cock2009biopython}. Sequences were
multiply aligned using \software{MUSCLE} version 3.8.31
\autocite{edgar2004muscle}, and alignments were manually inspected with
\software{Seaview} version 4.4.2 \autocite{gouy2010seaview}. \add{Duplicated
sequences were removed with \textit{BioPython}.} Phylogenies were constructed
from the nucleotide alignments by approximate maximum likelihood using
\software{FastTree2} version 2.1.7 \autocite{price2010fasttree} with the
\gls{GTR} model~\autocite{tavare1986some}. Transmission trees were estimated by
rooting and time-scaling the phylogenies by root-to-tip regression, using a
modified version of Path-O-Gen (distributed as part of
BEAST~\autocite{drummond2007beast}) as described
previously~\autocite{poon2015phylodynamic}. \add{Due to the removal of
duplicated sequences, all estimated transmission trees were fully binary.}

\add{To check if our results were robust to the choice of phylogenetic
reconstruction method, we built and reanalyzed phylogenies for the datasets
with the lowest and highest estimated $\alpha$ values (mixed/Spain and
IDU/Estonia) with \textit{RAxML}~\autocite{stamatakis2014raxml} with the
GTR+$\Gamma$ model of sequence evolution and rate heterogeneity. The trees were
rooted and time-scaled with \textit{Least Square
Dating}~\autocite[\textit{LSD},][]{to2016fast}. For expediency, the analysis
was run with the prior $m \sim \text{DiscreteUniform}(2, 5)$, which defines a
smaller total search space than the prior allowing $m = 1$.}

\del{Three} \add{Four} of the datasets (MSM/Shanghai, HET/Botswana, HET/Uganda, 
and MSM/USA) were initially larger than the others, containing 1265, 1299,
1026/915 (\textit{env}/\textit{gag}), and 648 sequences respectively. To ensure
that the analyses were comparable, we reduced these to a number of sequences
similar to the smaller datasets. For the MSM/Shanghai dataset, we detected a
cluster of size 280 using a patriotic distance cutoff of 0.02 as described
previously~\autocite{poon2015impact}. Only sequences within this cluster were
carried forward. For the HET/Uganda, HET/Botswana, and MSM/USA datasets, no
large clusters were detected using the same cutoff, so we analyzed subsets of
size 225, 180, and 180 respectively. \add{The subset of the HET/Uganda data was
chosen by eye such that the individuals were monopolistic in both the
\textit{gag} and \textit{env} trees. The other subsets were arbitrarily chosen
subtrees from phylogenies of the complete datasets.}

For all datasets, we used the priors $\gls{alpha} \sim \Uniform(0, 2)$ and
\gls{N} and \gls{I} jointly uniform on the region $\{n \leq \gls{N} \leq
10000$, $n \leq \gls{I} \leq 10000$, $\gls{I} \leq \gls{N}\}$, where $n$ is the
number of tips in the tree (see \cref{tab:data}). Since the value $\gls{m} = 1$
produces networks with no cycles, which we considered fairly implausible, we
ran one analysis with the prior $\gls{m} \sim \DiscreteUniform(1, 5)$, and one
with the prior $\gls{m} \sim \DiscreteUniform(2, 5)$. The other parameters to
the SMC algorithm were the same as used for the simulation experiments, except
that we used 10000 particles instead of 1000 to increase the accuracy of the
estimated posterior. This was computationally feasible due to the small number
of runs required for this analysis.

Empirical studies of contact networks often report the exponent \gls{gamma} of
the power law degree distribution~\autocite{colgate1989risk, liljeros2001web,
schneeberger2004scale, clemenccon2015statistical, rothenberg2007large,
brown2011transmission}. Although the \gls{BA} model does not produce networks
with true power law degree distributions except when $\gls{alpha} = 1$, the
power law still provides a reasonable approximation to the slope when
$\gls{alpha} \neq 1$ (\cref{fig:powerlaw}).  To compare our results to
\add{existing network} literature we simulated 100 networks each according to
the posterior mean parameter estimates obtained for each investigated dataset.
\add{Although the \gls{BA} model does not produce power law networks except
when $\gls{alpha} = 1$, simulations show that the power law fit still captures
the slope of the degree distribution reasonably well (\cref{fig:powerlaw}).}
\gls{gamma} was calculated for each network using the
\software{fit\_power\_law} function in \software{igraph}, with the `R.mle'
implementation. The median of the 100 \gls{gamma} values was taken as a point
estimate for the associated dataset.

\subsection{Results}



\del{We applied \software{netabc} to five published HIV datasets (\cref{tab:data}).
and found substantial heterogeneity among the parameter
estimates.} \add{Posterior mean point estimates and 50\% and 95\% \gls{HPD}
intervals for each parameter are shown in \cref{fig:abchpd}.} \del{and marginal
posterior distributions in
\cref{fig:cuevas,fig:li,fig:niculescu,fig:novitsky,fig:wang}}.
\add{\Cref{fig:abchpdm2} shows point estimates and \gls{HPD} intervals obtained
when the value $\gls{m} = 1$ was disallowed by the prior. Since the results
indicated that $\gls{m} = 1$ was the most credible value for several datasets,
all results discussed henceforth are for the prior $\gls{m} \sim
\DiscreteUniform(1, 5)$ unless otherwise stated.}

\begin{figure}[ht]
    \centering
    \includegraphics{realdata-hpd-bc}
    \caption[
        Posterior means and 50\%/95\% \gls{HPD} intervals for parameters of the
        \gls{BA} network model, fitted to eleven
        \gls{HIV} datasets with \software{netabc}.
    ]{
        Posterior means (points), 50\% \gls{HPD} intervals (notches), and 95\%
        \gls{HPD} intervals (lines) for parameters of the \gls{BA} network
        model, fitted to eleven \gls{HIV} datasets with \software{netabc}.
        Legend labels indicate risk group and country of origin. Abbreviations:
        \acrshort{IDU}, \acrlong{IDU}; \acrshort{MSM}, \acrlong{MSM}; HET,
        heterosexual. Note that posterior means can fall outside of \gls{HPD} 
        intervals if the distribution is diffuse.
    }
    \label{fig:abchpd}
\end{figure}

\del{Two of the datasets (\textcite{niculescu2015recent, wang2015targeting}) had
estimated $\alpha$ values near unity for the prior allowing $m = 1$ (posterior
mean [95\% \gls{HPD}] 
  0.73 
  [0.05 - 
   1.18]
and
  0.55 
  [0.01 -
   0.99] respectively).
The estimates did not change appreciably when $m = 1$ was disallowed by the
prior, although the credible interval of the \textcite{niculescu2015recent}
data was narrower
  (0.05 - 
   1.18).
When $m = 1$ was permitted, the \textcite{li2015hiv, cuevas2009hiv} both had
low estimated $\alpha$ values
  (0.33 
  [0 - 
  0.76]
and
  0.27 
  [0 -
   0.59]). 
However, the estimates increased when $m = 1$ was not permitted, although the
HPD intervals remained roughly the same
  (0.58 
  [0.06 - 
  0.99]
and
  0.48 
  [0.02 -
   0.87]).
The \textcite{novitsky2014impact} data had a fairly low estimated $\alpha$
for both priors on $m$
  (0.55 for $m \geq 1$;
   0.53 for $m \geq 2$).
However, the confidence interval was much wider when $m = 1$ was allowed
  ([0 -
    1.75] for $m \geq 1$ vs.
   [0 -
    1.75] for $m \geq 2$).}

\add{Posterior mean point estimates for the \acrlong{PA} power \gls{alpha}
were all sub-linear, ranging from 
    0.83
for the \gls{IDU}/Estonia data to
    0.27
for the mixed/Spain data. When aggregated by risk group, the average estimates
were
    0.73
for \gls{IDU},
    0.41
for primarily heterosexual risk, and
    0.37
for \gls{MSM}. These values were obtained with \textit{gag} for the datasets
where both \textit{gag} and \textit{env} were sequenced, but the estimates for
\gls{alpha} did not change appreciably between the two genes (\cref{fig:genes}).
There was a large amount of uncertainty associated with these estimates. 95\%
\gls{HPD} intervals were very wide for most datasets, often encompassing almost
the entire range from 0 to 1 (\cref{fig:abchpd}). For all the datasets except
HET/Malawi and MSM/Beijing, the posterior mean was either outside, or very
close to the border of, the 50\% \gls{HPD} intervals. This indicates that the
posterior distributions were diffuse with heavy tails, rather than having most
of their mass around the mode.}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{realdata-genes}
    \caption[
        Posterior means and 50\%/95\% \gls{HPD} intervals for parameters of the
        \gls{BA} network model, fitted to two \gls{HIV} datasets where both
        \textit{gag} and \textit{env} genes were sequenced.
    ]{
        Posterior means (points), 50\% \gls{HPD} intervals (notches), and 95\%
        \gls{HPD} intervals (lines) for parameters of the \gls{BA} network model,
        fitted to two \gls{HIV} datasets where both \textit{gag} and
        \textit{env} genes were sequenced.
    }
    \label{fig:genes}
\end{figure}

\del{For all the datasets except \citeauthor{novitsky2014impact},
estimated values of $I$ were below 2000 when $m = 1$ was allowed, with
relatively narrow HPD intervals compared to the nonzero prior density region
  (\citeauthor{cuevas2009hiv}, 701 
  [289 -
   1279];
   \citeauthor{niculescu2015recent}, 747
  [136 - 
   2378];
  \citeauthor{li2015hiv}, 1390 
  [310 -
   2821];
   \citeauthor{wang2015targeting}, 675
  [175 - 
   1400]).
The \citeauthor{novitsky2014impact} data was the outlier, with a very high
estimated $I$, and HPD interval spanning almost the entire prior region
  (5431 
  [183 -
   8739]).
The $I$ estimates and HPD intervals were generally robust to the choice of
prior on $m$, with slightly narrower HPD intervals (compare
\cref{fig:abchpd,fig:abchpdm2}).}



\add{For all but the HET/Botswana data, the posterior mean estimates for
the prevalence \gls{I} were between
    373
(IDU/Estonia) and
    1391
(MSM/Shanghai). The HET/Botswana data had a much higher estimated \gls{I} value
    (5432)
than the other datasets, with a very wide 95\% \gls{HPD} interval covering
almost the entire prior region (\cref{fig:abchpd}). There was no significant
correlation between the number of sequences in the tree and the estimated
prevalence (Spearman correlation, 
    $p =0.7$),
indicating that the higher prevalence estimates were not simply due to
increased sampling density. When both \textit{gag} and \textit{env} sequences
were analyzed, the estimates from the \textit{env} data were higher
(HET/Uganda,
    939 for \textit{gag} vs.
    1615 for \textit{env};
HET/Malawi,
    724 for \textit{gag} vs.
    845 for \textit{env}).
As with \gls{alpha}, many of the posterior means were outside the 50\%
\gls{HPD} intervals, suggesting diffuse posterior distributions.}

\del{The posterior mean of $m$ was equal to 1 for all but the
\citeauthor{novitsky2014impact} data, when this value was allowed. However, the
upper bound of the HPD interval was different for each dataset
  (\citeauthor{niculescu2015recent}, 4;
   \citeauthor{wang2015targeting}, 1;
   \citeauthor{li2015hiv}, 1;
   \citeauthor{cuevas2009hiv}, 1).
When $m = 1$ was disallowed, the estimate for all datasets was either 2 or 3,
with HPD intervals spanning the entire prior region. The estimates for the
total number of nodes $N$ were largely uninformative for all samples, with
almost all posterior mean estimates greater than 7500 and HPD intervals
spanning almost the entire nonzero prior density region. The only exception was
the \citeauthor{li2015hiv} data, for which the estimate was lower 
  (5916)
when $m = 1$ was allowed.}

\add{The posterior means of \gls{m} were equal to one for 
  zero
of the datasets analyzed. The widths of the 95\% \gls{HPD} intervals varied
from 0 (all the mass on the estimated value) to 5 (the entire prior region).
Estimates of \gls{N} were  mostly uninformative, with very similar estimates
for all datasets (mean
    6212,
range
    5881 - 6882).
This was similar to the pattern observed for the synthetic data, where the
posterior mean always fell around the upper two-thirds mark of the region
allowed by the prior (\cref{fig:abcpt2}).}

\add{When the value $m = 1$ was disallowed by the prior, the separation in
$\alpha$ between the IDU datasets and the others became more striking
(\cref{fig:abchpdm2}). All three IDU datasets had estimated $\alpha$ values at
or above
    1.
The estimate for the MSM/Beijing data was slightly lower
    (0.85) and
the estimates for the seven remaining non-IDU datasets were bounded above by
    0.58. 
The values of $I$ were fairly robust to the choice of prior (compare
\cref{fig:abchpd,fig:abchpdm2}), although the 95\% HPD intervals were slightly
narrower (average width
    2244
for $m \geq 1$ and
    1848
for $m \geq 2$). The posterior means of $m$ for all but the HET/Botswana data
took on the value 3 with this prior, with the HPD intervals spanning the entire
prior region. This is very similar to the results observed for $m$ on simulated
data (\cref{tab:abchpd}), and suggests that $m$ is not identifiable from these
data with this prior. The results for $N$ did not change appreciably between
the two choices of prior.}



\add{For the two datasets we reanalyzed using
RAxML~\autocite{stamatakis2014raxml} and LSD~\autocite{to2016fast}, $\alpha$
was relatively robust to the choice of method (\cref{fig:methods}, posterior
means 
    0.48
vs. 
    0.48
for mixed/Spain and 
    1.02
vs.
    1.12
for IDU/Estonia). However, the estimates of $I$ were about twice as high when
RAxML was used instead of FastTree to reconstruct the trees 
    (228 
     vs. 437 for IDU/Estonia, 
    816
    vs. 1949 for mixed/Spain). }

To compare our results to the existing network literature, we estimated
values of the power law exponent \gls{gamma} for each of the datasets
investigated, using the posterior median estimates \del{with the prior allowing
$\gls{m} = 1$}. The results are summarized in \cref{tab:gamma}. All of the
estimated exponents were in the range $2 \leq \gls{gamma} \leq 2.5$, which is
on the lower end of the range $2 \leq \gls{gamma} \leq 4$ reported in the
literature. \add{Because the estimates of \gls{N} were uninformative, we also
simulated another set of networks with the estimated \gls{I} value, rather than
\gls{N}, as the number of nodes. However, none of the estimated \gls{gamma}
values were changed by this operation (not shown).}

\begin{table}
    \centering
    \input{\tablepath/realdata-gamma.tex}
    \caption[
        Estimated power law exponents for six \gls{HIV} datasets based on
        posterior mean point estimates of \gls{BA} model parameters.
    ]{
        Estimated power law exponents for six \gls{HIV} datasets based on
        posterior mean point estimates of \gls{BA} model parameters. 100
        networks were simulated using posterior mean parameter estimates
        obtained with \software{netabc}. The power law exponent \gls{gamma}
        was estimated for each, and the median of those estimates was used as a
        point estimate for the corresponding dataset.
    }
    \label{tab:gamma}
\end{table}
