<<setup, include=FALSE>>=
    library(netabc)
@

\subsection{Kernel classifiers}

<<treestats, include=FALSE>>=
    params <- c("alpha", "I", "m", "N")
    
    get.treestats <- function (param) {
        stats <- paste0("../../simulations/kernel-", param, "/statistics/*")
        d <- collect.data(stats)
        trees <- paste0("../../simulations/kernel-", param, "/tree/*")
        m <- collect.metadata(trees)
        rownames(m) <- sub("../../simulations/", "", rownames(m))
        d <- merge(d, m, by=0, suffixes=c("", ".1"))
        if (param == "alpha") {
            d <- subset(d, m == 2)
            colnames(d)[colnames(d) == "nsimnode"] <- "I"
        }
        setDT(d)
    }
    
    alpha.stats <- get.treestats("alpha")
    I.stats <- get.treestats("I")
    m.stats <- get.treestats("m")
    N.stats <- get.treestats("N")

    alpha.sackin.cor <- alpha.stats[,cor.test(alpha, sackin, method="spearman")]
    stopifnot(alpha.sackin.cor$p.value < 1e-5)

    N.ratio.cor <- N.stats[,cor.test(int.tip.ratio, N)]
    I.ratio.cor <- I.stats[,cor.test(int.tip.ratio, I)]
    stopifnot(N.ratio.cor$p.value < 1e-5)
    stopifnot(I.ratio.cor$p.value < 1e-5)
@

Trees simulated under different values of \gls{alpha} are visibly quite
distinct (\cref{fig:alphatrees}). In particular, higher values of \gls{alpha}
produce networks with a small number of highly connected nodes which, once
infected, are likely to transmit to many other nodes (\cref{fig:alphabds}).
This results in a more unbalanced, ladder-like structure in the phylogeny,
compared to networks with lower \gls{alpha} values. Sackin's index was
significantly correlated with \gls{alpha} 
    (Spearman's rho \Sexpr{round(alpha.sackin.cor$estimate, 2)},
     $p < 10^{-5}$).
None of the other three parameters produced trees which were as easily
distinguished from each other
(\cref{fig:Itrees,fig:mtrees,fig:Ntrees,fig:Itrees}). However, the ratio of
internal to terminal branch lengths was positively correlated with $N$ and
negatively correlated with $I$ (Spearman's rho
    \Sexpr{round(N.ratio.cor$estimate, 2)} and
    \Sexpr{round(I.ratio.cor$estimate, 2)},
    both $p < 1e-5$).

Kernel-\gls{PCA} projections show that all three \gls{alpha} values are well
separated from each other in feature space under several different sampling
scenarios (Figure~\ref{fig:pakpca}). With smaller trees, it becomes harder to
visually distinguish \gls{alpha} = 0.5 from \gls{alpha} = 1.0 using the first
two principal components.

With suitably chosen meta-parameters, the accuracy of the kernel-\gls{SVM}
classifier for \gls{alpha} was very high under a variety of prevalence and
sampling scenarios. Accuracy was highest, with
$R^2$ values above 0.95, for the largest trees and complete sampling (bottom
center panel). However, even for trees of size 100 sampled from an epidemic on
2000 nodes, the $R^2$ was above 0.8 (top right panel). In all cases, the
accuracy of a Sackin's index-based classifier was also quite high, at about
0.75. An \gls{SVM} classifier using only the \gls{nltt}
statistic~\autocite{janzen2015approximate} was slightly worse than Sackin's
index, with an $R^2$ of X.

\begin{figure}[ht]
  \centering
  \includegraphics{kernel-alpha-tree.pdf}
  \caption[Visibly distinctive trees simulated under three values of \gls{alpha}]{
    Epidemics simulated on \gls{BA} networks of 5000 nodes, with \gls{alpha}
    equal to 0.5, 1.0, or 1.5, until 1000 individuals were infected.
    Transmission trees were created by sampling 500 infected nodes. Higher
    \gls{alpha} values produced networks with a small number of
    highly-connected nodes, resulting in highly unbalanced, ladder-like trees.
  }
  \label{fig:alphatrees}
\end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics{kernel-kpca.pdf}
  \caption[Projection of kernel matrix for different attachment power values
  onto its first two principal components]{
    Projection of the kernel matrix for different preferential attachment power
    values onto its first two principal components, for eight simulation
    scenarios. Each point corresponds to a simulated transmission tree, and is
    coloured by preferential attachment power. Facets are number of infected
    nodes (horizontal), and number of sampled tips (vertical). The parameters
    to the tree kernel were $\lambda = 0.3$ and $\sigma = 4$, and the nLTT was
    not used. Qualitatively, trees with a larger number of tips are easier to
    separate in kernel space, regardless of what sampling proportion they
    represent. In all cases, the highest attachment power can be separated from
    the other two, but the two lowest values become hand to distinguish with in
    the 100-tip trees.
  }
  \label{fig:pakpca}
\end{figure}

We also considered the possibility of inferring the number of infected nodes,
or \defn{prevalence}, under this model. All parameters except \gls{I} were
fixed at the following values: \gls{N} = 5000, \gls{alpha} = 1.0, and \gls{m} =
2. As shown in Figure~\ref{fig:prevtrees}, the prevalence had no obvious effect
on the tree shape. However, a kernel-\gls{SVM} classifier was able to
distinguish the number of infected nodes with high accuracy ($R^2 > 0.9$;
Figure~\ref{fig:prevcrossv}). Moreover, the use of the \gls{nltt} statistic
improved classification accuracy by a small amount, in contrast to the results
for \gls{alpha}. In contrast, a Sackin's index-based classifier displayed
extremely poor performance ($R^2$ < 0.1, not shown). 

It is important to note that, if we cut off the epidemic simulation when 500
nodes are infected, the resulting tree will be shorter (in calendar time) than
if we continue until 2000 nodes are infected. However, this information is not
used when building the classifier, since the branch lengths in each tree are
scaled by their mean. Therefore, the high performance of the classifier is due
to structural differences captured by the tree kernel, rather than the trees
simply having different heights.

\subsection{Accuracy of marginal estimates}

We used grid search to obtain \defn{marginal} estimates for each network
parameter while holding all other parameters fixed. We observed that kernel
scores were highest at the values of \gls{alpha} on the grid closest to the
true values, as shown in Figure~\ref{fig:gridkernel}. However, there was a much
stronger spike in kernel scores near the true value for \gls{alpha} = 1.0 and
1.25. This is recapitulated when we look at the accuracy of point estimates
obtained by taking the grid value with the highest median kernel score. As
shown in Figure~\ref{fig:gridest}, while the estimates are generally close to
the true value, they are much closer for \gls{alpha} = 1.25 than for the other
values.

\begin{figure}[ht]
  \centering
  \includegraphics{gridsearch-alpha-kernel.pdf}
  \caption[Grid search kernel scores]{
    Grid search kernel scores for testing trees simulated under various
    \gls{alpha} values. All epidemics had \gls{I} = 1000 infected nodes, on
    \gls{BA} networks of size \gls{N} = 5000 with \gls{m} fixed at 2. Colours
    indicate the number of sampled tips.
  }
  \label{fig:gridkernel}
\end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics{gridsearch-alpha-point-estimate.pdf}
  \caption[Marginal estimates of \gls{alpha} obtained with grid search]{
    Marginal estimates of \gls{alpha} obtained with grid search. Training trees
    were simulated on a narrowly spaced grid of \gls{alpha} values, and
    compared to testing trees using the tree kernel. The \gls{alpha} value in
    the grid with the highest median kernel score was taken as the point
    estimate for the testing tree. These point estimates are shown as black
    dots. The dashed line is the identity.
  }
  \label{fig:gridest}
\end{figure}

\subsection{Accuracy of estimates with full ABC}

<<point_est, include=FALSE>>=
    f <- Sys.glob("../../simulations/abc-pa-free-m/point-estimate/*")
    d <- fread(f)
    d[,m := floor(m)]
    d[,alpha_error := abs(true_alpha - alpha)]
    d[,N_error := abs(true_N - N)]
    d[,I_error := abs(true_I - I)]
    d[,m_error := abs(true_m - m)]

    alpha.av <- anova(lm(alpha_error ~ factor(true_alpha) + factor(true_m) + factor(true_I), d))
    m.av <- anova(lm(m_error ~ factor(true_alpha) + factor(true_m) + factor(true_I), d))
    N.av <- anova(lm(N_error ~ factor(true_alpha) + factor(true_m) + factor(true_I), d))
    I.av <- anova(lm(I_error ~ factor(true_alpha) + factor(true_m) + factor(true_I), d))

    m.tbl <- d[,prop.table(table(m_error))]
    zero.alpha.test <- wilcox.test(d[true_alpha == 0, alpha_error], 
                                   d[true_alpha != 0, alpha_error])
    alpha.I.test <- wilcox.test(d[true_alpha < 1, I_error],
                                d[true_alpha >= 1, I_error])
    I.I.test <- wilcox.test(d[true_I == 1000, I_error],
                            d[true_I == 2000, I_error])
    alpha.m.test <- wilcox.test(d[true_alpha == 0 | true_alpha == 1, m_error],
                                d[true_alpha == 0.5 | true_alpha == 1.5, m_error])

    options(scipen=-1, digits=2)
@

We used kernel-\gls{ABC} to estimate the parameters of the \gls{BA} model 
on simulated trees where the true parameter values were known. Point estimates
for each parameter are shown in Figure~\ref{fig:abcpt}. Of the four parameters,
\gls{alpha} was the most accurately estimated, with a median [IQR] absolute error
of 
    \Sexpr{d[,median(alpha_error)]} 
    [\Sexpr{d[,quantile(alpha_error, 0.25)]}-\Sexpr{d[,quantile(alpha_error, 0.75)]}].
The accuracy of the estimates was not significantly different between values of
$m$ or $I$ (both one-way ANOVA,
    $p$ = \Sexpr{alpha.av["factor(true_m)", "Pr(>F)"]}
and 
    \Sexpr{alpha.av["factor(true_I)", "Pr(>F)"]}),
although the errors when the true value of \gls{alpha} was zero were
significantly greater than the other values 
    (Wilcoxon rank-sum test, $p$ = \Sexpr{zero.alpha.test$p.value}).
The error in the estimated value of $I$ was
    \Sexpr{d[,median(I_error)]} 
    [\Sexpr{d[,quantile(I_error, 0.25)]}-\Sexpr{d[,quantile(I_error, 0.75)]}].
Errors were significantly higher for $\alpha \geq 1$
    (Wilcoxon rank-sum test, $p$ = \Sexpr{alpha.I.test$p.value})
and for $I$ = 2000
    ($p$ = \Sexpr{I.I.test$p.value}),
but not for any values of $m$
    (one-way ANOVA, $p$ = \Sexpr{I.av["factor(true_m)", "Pr(>F)"]}).
The $m$ parameter was estimated correctly in
    \Sexpr{as.integer(m.tbl[1] * 100)} \%
of simulations, with an error of one in
    \Sexpr{as.integer(m.tbl[2] * 100)} \%
and of two or more in 
    \Sexpr{as.integer(sum(m.tbl[3:length(m.tbl)]) * 100)} \%
(the only possible $m$ values were 2, 3, 4, or 5). The true values of
$m$ and $I$ did not significantly affect the error
    (one-way ANOVA, $p$ = \Sexpr{m.av["factor(true_m)", "Pr(>F)"]} and
                          \Sexpr{m.av["factor(true_I)", "Pr(>F)"]}),
but the accuracy was significantly lower for integral than non-integral
values of \gls{alpha}
    (Wilcoxon rank-sum test, $p$ = \Sexpr{alpha.m.test$p.value}).
Finally, the total number of nodes \gls{N} was consistently over-estimated by
about a factor of two
    (error \Sexpr{d[,median(N_error)]} 
    [\Sexpr{d[,quantile(N_error, 0.25)]}-\Sexpr{d[,quantile(N_error, 0.75)]}]).
No other parameters influenced the accuracy of the $N$ estimates 
    (one-way ANOVA, $p \geq$ \Sexpr{min(N.av[,"Pr(>F)"])}).

Figure~\ref{fig:abcex} shows the \gls{ABC} approximation to the
posterior distribution on the \gls{BA} parameters for one simulation
(equivalent plots for all the simulations can be found in the supplemental
materials). \Gls{HPD} intervals around \gls{alpha} and \gls{I} were narrow
relative to the region of nonzero prior density, whereas the intervals for $m$
and \gls{N} were widely dispersed. Table~\ref{tab:abchpd} shows point estimates and
95\% \gls{HPD} intervals averaged over all simulations.

\begin{table}
    \centering
    \input{\tablepath/abc-hpd}
    \caption{Average widths of 95\% confidence intervals for \gls{BA} model
    parameters estimated with kernel-\gls{ABC}.}
    \label{tab:glm}
\end{table}

\subsection{Characterization of power-law exponent in Barab\'asi-Albert networks}

\Cref{tab:glm} shows the estimated parameters for a log-link \gls{GLM} fitted
to the observed distribution of \gls{gamma} values. The coefficients are
interpretable as multiplicative effects.

\begin{table}
    \centering
    \input{\tablepath/pa-gamma-glm}
    \caption{Estimated \gls{GLM} parameters for relationship between power-law
    exponent \gls{gamma} and \gls{BA} model parameters.}
    \label{tab:glm}
\end{table}
