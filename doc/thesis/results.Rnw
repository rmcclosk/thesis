<<setup, include=FALSE>>=
    library(netabc)
@

\subsection{Kernel classifiers}

<<treestats, include=FALSE>>=
    params <- c("alpha", "I", "m", "N")
    
    get.treestats <- function (param) {
        stats <- paste0("../../simulations/kernel-", param, "/statistics/*")
        d <- collect.data(stats)
        trees <- paste0("../../simulations/kernel-", param, "/tree/*")
        m <- collect.metadata(trees)
        rownames(m) <- sub("../../simulations/", "", rownames(m))
        d <- merge(d, m, by=0, suffixes=c("", ".1"))
        if (param == "alpha") {
            d <- subset(d, m == 2)
            colnames(d)[colnames(d) == "nsimnode"] <- "I"
        }
        setDT(d)
    }
    
    alpha.stats <- get.treestats("alpha")
    I.stats <- get.treestats("I")
    m.stats <- get.treestats("m")
    N.stats <- get.treestats("N")

    alpha.sackin.cor <- alpha.stats[,cor.test(alpha, sackin, method="spearman")]
    stopifnot(alpha.sackin.cor$p.value < 1e-5)

    N.ratio.cor <- N.stats[,cor.test(int.tip.ratio, N)]
    I.ratio.cor <- I.stats[,cor.test(int.tip.ratio, I)]
    stopifnot(N.ratio.cor$p.value < 1e-5)
    stopifnot(I.ratio.cor$p.value < 1e-5)
@

Trees simulated under different values of \gls{alpha} are visibly quite
distinct (\cref{fig:alphatrees}). In particular, higher values of \gls{alpha}
produce networks with a small number of highly connected nodes which, once
infected, are likely to transmit to many other nodes. This results in a more
unbalanced, ladder-like structure in the phylogeny, compared to networks with
lower \gls{alpha} values. Sackin's index was significantly correlated with
\gls{alpha} 
    (Spearman's rho \Sexpr{round(alpha.sackin.cor$estimate, 2)},
     $p < 10^{-5}$).
None of the other three parameters produced trees which were as easily
distinguished from each other
(\cref{fig:Itrees,fig:mtrees,fig:Ntrees,fig:Itrees}). However, the ratio of
internal to terminal branch lengths was positively correlated with $N$ and
negatively correlated with $I$ (Spearman's rho
    \Sexpr{round(N.ratio.cor$estimate, 2)} and
    \Sexpr{round(I.ratio.cor$estimate, 2)},
    both $p < 10^{-5}$).

\begin{figure}[ht]
  \centering
  \includegraphics{kernel-alpha-tree.pdf}
  \caption[Visibly distinctive trees simulated under three values of \gls{alpha}]{
    Epidemics simulated on \gls{BA} networks of 5000 nodes, with \gls{alpha}
    equal to 0.5, 1.0, or 1.5, until 1000 individuals were infected.
    Transmission trees were created by sampling 500 infected nodes. Higher
    \gls{alpha} values produced networks with a small number of
    highly-connected nodes, resulting in highly unbalanced, ladder-like trees.
  }
  \label{fig:alphatrees}
\end{figure}

\Cref{fig:kpca} shows \gls{kPCA} projections of the simulated trees onto the
first two principal components of the kernel matrix. The figure shows only the
simulations with 500-tip trees and, for all parameters except $I$, 1000
infected nodes. The three \gls{alpha} and \gls{I} values considered are well
separated from each other in feature space. On the other hand, the three
\gls{N} values overlap significantly, and the three \gls{m} values are
virtually indistinguishable. Similar observations can be made for other values
of \gls{I} and the number of tips
(\cref{fig:alphakpca,fig:Nkpca,fig:Ikpca,fig:mkpca}). The values of \gls{I} and
\gls{N} separate more clearly with larger numbers of tips, and in the case of
\gls{N} larger epidemic sizes.

\begin{figure}[ht]
  \centering
  \includegraphics{kernel-kpca.pdf}
  \caption[\gls{kPCA} projections of simulated trees under varying \gls{BA}
           parameter values]{
    Each parameter of the \gls{BA} model was individually varied to produce 300
    simulated trees. Kernel matrices were formed from all pairwise kernel
    scores among each set of 300 trees. The trees were projected onto the first
    two principal components of the kernel matrix calculated using \gls{kPCA}.
    All trees had 500 tips. The parameters not being varied were set to
    \gls{alpha} = 1, \gls{I} = 1000, \gls{m} = 2, and \gls{N} = 5000. The tree
    kernel meta-parameters were $\lambda = 0.3$ and $\sigma = 4$.
  }
  \label{fig:kpca}
\end{figure}

<<classifiers, include=FALSE>>=
    get.kernel.data <- function (param, step) {
        md <- collect.metadata(paste0('../../simulations/kernel-', param, '/', step, '/*'))
        if ('rbf_variance' %in% colnames(md)) {
          md <- subset(md, rbf_variance == 4 & decay_factor == 0.3)
        }
        if (param == 'alpha') {
            md <- subset(md, m == 2)
        }
        d <- setDT(collect.data(rownames(md)))
        if (param %in% c('alpha', 'm')) {
            d[,list(rsquared=mean(rsquared)), by=c('nsimnode', 'ntip')]
        } else if (param == 'I') {
            d[,list(rsquared=mean(rsquared)), by=ntip]
        } else {
            d[,list(rsquared=mean(rsquared)), by=c('I', 'ntip')]
        }
    }
    kernel.alpha <- get.kernel.data('alpha' ,'classifier')
    kernel.m <- get.kernel.data('m', 'classifier')
    kernel.I <- get.kernel.data('I', 'classifier')
    kernel.N <- get.kernel.data('N', 'classifier')

    sackin.alpha <- get.kernel.data('alpha', 'stats-classifier')
    sackin.m <- get.kernel.data('m', 'stats-classifier')
    sackin.I <- get.kernel.data('I', 'stats-classifier')
    sackin.N <- get.kernel.data('N', 'stats-classifier')

    nltt.alpha <- get.kernel.data('alpha', 'nltt-classifier')
    nltt.m <- get.kernel.data('m', 'nltt-classifier')
    nltt.I <- get.kernel.data('I', 'nltt-classifier')
    nltt.N <- get.kernel.data('N', 'nltt-classifier')
@

Accuracy of the \gls{kSVM} classifiers varied based on the parameter being
tested (\cref{fig:rsquared}, left). Classifiers based on two other tree
statistics, the \gls{nltt} and Sackin's index, generally exhibited worse
performance than the tree kernel, although the magnitude of the disparity
varied between the parameters (\cref{fig:rsquared}, centre and right). The
results were largely robust to variations in the tree kernel meta-parameters
$\lambda$ and $\sigma$, although accuracy varied between different epidemic and
sampling scenarios
(\cref{fig:alphacrossv,fig:mcrossv,fig:Icrossv,fig:Ncrossv}).

When classifying $\alpha$, the kernel-SVM classifier had an average $R^2$ of 
    \Sexpr{kernel.alpha[,round(mean(rsquared), 2)]},
compared to 
    \Sexpr{nltt.alpha[,round(mean(rsquared), 2)]}
for the \gls{nltt}-based SVM, and
    \Sexpr{sackin.alpha[,round(mean(rsquared), 2)]}
for the linear regression against Sackin's index. There was little variation
about the mean for different tree and epidemic sizes. No classifier could
accurately identify the $m$ parameter in any epidemic scenario, with average
$R^2$ values of 
  \Sexpr{kernel.m[,round(mean(rsquared), 2)]} for \gls{kSVM},
  \Sexpr{nltt.m[,round(mean(rsquared), 2)]} for the \gls{nltt}, and
  \Sexpr{sackin.m[,round(mean(rsquared), 2)]}
for Sackin's index. Again, there was little variation in accuracy between
epidemic scenarios, although the accuracy of the \gls{kSVM} was slightly higher
on 1000-tip trees.

The accuracy of classifiers $I$ varied significantly with the number of tips in
the tree. For 100-tip trees, the average $R^2$ values were
  \Sexpr{kernel.I[ntip == 100, round(mean(rsquared), 2)]},
  \Sexpr{nltt.I[ntip == 100, round(mean(rsquared), 2)]}, and
  \Sexpr{sackin.I[ntip == 100, round(mean(rsquared), 2)]}
for the tree kernel, \gls{nltt}, and Sackin's index respectively. For 500-tip
trees, the values increased to
  \Sexpr{kernel.I[ntip == 500, round(mean(rsquared), 2)]},
  \Sexpr{nltt.I[ntip == 500, round(mean(rsquared), 2)]}, and
  \Sexpr{sackin.I[ntip == 500, round(mean(rsquared), 2)]}.
Finally, the performance of classifiers for $N$ depended heavily on the
epidemic scenario. The $R^2$ of the \gls{kSVM} classifier ranged from
  \Sexpr{kernel.N[,round(min(rsquared), 2)]}
for the smallest epidemic and smallest sample size, to
  \Sexpr{kernel.N[,round(max(rsquared), 2)]}
for the largest. Likewise, $R^2$ for the \gls{nltt}-based SVM ranged from 
  \Sexpr{nltt.N[,round(min(rsquared), 2)]}
to
  \Sexpr{nltt.N[,round(max(rsquared), 2)]}.
Sackin's index did not accurately classify $N$ in any scenario, with an average
$R^2$ of
  \Sexpr{sackin.N[,round(mean(rsquared), 2)]}
and little variation between scenarios.

\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth]{kernel-rsquared.pdf}
  \caption{
      Cross-validation accuracy of kernel-SVM classifier (left), SVM classifier
      using \gls{nltt} (centre), and linear regression using Sackin's index
      (right) for \gls{BA} model parameters. Kernel meta-parameters were set to
      $\lambda = 0.3$ and $\sigma = 4$. Each point was calculated based on 300
      simulated transmission trees over networks with three different values of
      the parameter being tested. Vertical lines are empirical 95\% confidence
      intervals based on 1000 two-fold cross-validations.
  }
  \label{fig:rsquared}
\end{figure}

\subsection{Grid search}

The accuracy of grid search estimates largely paralleled that of the \gls{kSVM}
classifiers.

We used grid search to obtain marginal estimates for each network parameter
while holding all other parameters fixed. We observed that kernel scores were
highest at the values of \gls{alpha} on the grid closest to the true values, as
shown in Figure~\ref{fig:gridkernel}. However, there was a much stronger spike
in kernel scores near the true value for \gls{alpha} = 1.0 and 1.25. This is
recapitulated when we look at the accuracy of point estimates obtained by
taking the grid value with the highest median kernel score. As shown in
Figure~\ref{fig:gridest}, while the estimates are generally close to the true
value, they are much closer for \gls{alpha} = 1.25 than for the other values.

\begin{figure}[ht]
  \centering
  \includegraphics{gridsearch-alpha-kernel.pdf}
  \caption[Grid search kernel scores]{
    Grid search kernel scores for testing trees simulated under various
    \gls{alpha} values. All epidemics had \gls{I} = 1000 infected nodes, on
    \gls{BA} networks of size \gls{N} = 5000 with \gls{m} fixed at 2. Colours
    indicate the number of sampled tips.
  }
  \label{fig:gridkernel}
\end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics{gridsearch-alpha-point-estimate.pdf}
  \caption[Marginal estimates of \gls{alpha} obtained with grid search]{
    Marginal estimates of \gls{alpha} obtained with grid search. Training trees
    were simulated on a narrowly spaced grid of \gls{alpha} values, and
    compared to testing trees using the tree kernel. The \gls{alpha} value in
    the grid with the highest median kernel score was taken as the point
    estimate for the testing tree. These point estimates are shown as black
    dots. The dashed line is the identity.
  }
  \label{fig:gridest}
\end{figure}

\subsection{Accuracy of estimates with full ABC}

<<point_est, include=FALSE>>=
    f <- Sys.glob("../../simulations/abc-pa-free-m/point-estimate/*")
    d <- fread(f)
    d[,m := floor(m)]
    d[,alpha_error := abs(true_alpha - alpha)]
    d[,N_error := abs(true_N - N)]
    d[,I_error := abs(true_I - I)]
    d[,m_error := abs(true_m - m)]

    alpha.av <- anova(lm(alpha_error ~ factor(true_alpha) + factor(true_m) + factor(true_I), d))
    m.av <- anova(lm(m_error ~ factor(true_alpha) + factor(true_m) + factor(true_I), d))
    N.av <- anova(lm(N_error ~ factor(true_alpha) + factor(true_m) + factor(true_I), d))
    I.av <- anova(lm(I_error ~ factor(true_alpha) + factor(true_m) + factor(true_I), d))

    m.tbl <- d[,prop.table(table(m_error))]
    zero.alpha.test <- wilcox.test(d[true_alpha == 0, alpha_error], 
                                   d[true_alpha != 0, alpha_error])
    alpha.I.test <- wilcox.test(d[true_alpha < 1, I_error],
                                d[true_alpha >= 1, I_error])
    I.I.test <- wilcox.test(d[true_I == 1000, I_error],
                            d[true_I == 2000, I_error])
    alpha.m.test <- wilcox.test(d[true_alpha == 0 | true_alpha == 1, m_error],
                                d[true_alpha == 0.5 | true_alpha == 1.5, m_error])

    options(scipen=-1, digits=2)
@

We used kernel-\gls{ABC} to estimate the parameters of the \gls{BA} model 
on simulated trees where the true parameter values were known. Point estimates
for each parameter are shown in Figure~\ref{fig:abcpt}. Of the four parameters,
\gls{alpha} was the most accurately estimated, with a median [IQR] absolute error
of 
    \Sexpr{d[,median(alpha_error)]} 
    [\Sexpr{d[,quantile(alpha_error, 0.25)]}-\Sexpr{d[,quantile(alpha_error, 0.75)]}].
The accuracy of the estimates was not significantly different between values of
$m$ or $I$ (both one-way ANOVA,
    $p$ = \Sexpr{alpha.av["factor(true_m)", "Pr(>F)"]}
and 
    \Sexpr{alpha.av["factor(true_I)", "Pr(>F)"]}),
although the errors when the true value of \gls{alpha} was zero were
significantly greater than the other values 
    (Wilcoxon rank-sum test, $p$ = \Sexpr{zero.alpha.test$p.value}).
The error in the estimated value of $I$ was
    \Sexpr{d[,round(median(I_error))]} 
    [\Sexpr{d[,round(quantile(I_error, 0.25))]}-\Sexpr{d[,round(quantile(I_error, 0.75))]}].
Errors were significantly higher for $\alpha \geq 1$
    (Wilcoxon rank-sum test, $p$ = \Sexpr{alpha.I.test$p.value})
and for $I$ = 2000
    ($p$ = \Sexpr{I.I.test$p.value}),
but not for any values of $m$
    (one-way ANOVA, $p$ = \Sexpr{I.av["factor(true_m)", "Pr(>F)"]}).
The $m$ parameter was estimated correctly in
    \Sexpr{as.integer(m.tbl[1] * 100)} \%
of simulations, with an error of one in
    \Sexpr{as.integer(m.tbl[2] * 100)} \%
and of two or more in 
    \Sexpr{as.integer(sum(m.tbl[3:length(m.tbl)]) * 100)} \%
(the only possible $m$ values were 2, 3, 4, or 5). The true values of
$m$ and $I$ did not significantly affect the error
    (one-way ANOVA, $p$ = \Sexpr{m.av["factor(true_m)", "Pr(>F)"]} and
                          \Sexpr{m.av["factor(true_I)", "Pr(>F)"]}),
but the accuracy was significantly lower for integral than non-integral
values of \gls{alpha}
    (Wilcoxon rank-sum test, $p$ = \Sexpr{alpha.m.test$p.value}).
Finally, the total number of nodes \gls{N} was consistently over-estimated by
about a factor of two
    (error \Sexpr{d[,median(N_error)]} 
    [\Sexpr{d[,quantile(N_error, 0.25)]}-\Sexpr{d[,quantile(N_error, 0.75)]}]).
No other parameters influenced the accuracy of the $N$ estimates 
    (one-way ANOVA, $p \geq$ \Sexpr{min(N.av[,"Pr(>F)"])}).

\Cref{fig:abcex} shows the \gls{ABC} approximation to the posterior
distribution on the \gls{BA} parameters for one simulation (equivalent plots
for all the simulations can be found in the supplemental materials). \Gls{HPD}
intervals around \gls{alpha} and \gls{I} were narrow relative to the region of
nonzero prior density, whereas the intervals for $m$ and \gls{N} were widely
dispersed. Table~\ref{tab:abchpd} shows point estimates and 95\% \gls{HPD}
intervals averaged over all simulations.

\begin{table}
    \centering
    \input{\tablepath/abc-hpd}
    \caption{Average widths of 95\% confidence intervals for \gls{BA} model
    parameters estimated with kernel-\gls{ABC}.}
    \label{tab:glm}
\end{table}

\subsection{Characterization of power-law exponent in Barab\'asi-Albert networks}

\Cref{tab:glm} shows the estimated parameters for a log-link \gls{GLM} fitted
to the observed distribution of \gls{gamma} values. The coefficients are
interpretable as multiplicative effects.

\begin{table}
    \centering
    \input{\tablepath/pa-gamma-glm}
    \caption{Estimated \gls{GLM} parameters for relationship between power-law
    exponent \gls{gamma} and \gls{BA} model parameters.}
    \label{tab:glm}
\end{table}
