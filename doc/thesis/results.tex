\subsection{Separable parameters}

Our first simulation-based experiment was designed to determine which network
model parameters were potentially estimable by kernel-ABC. To do this, we
simulated trees under three distinct values of each parameter of interest, and
evaluated the accuracy of a kernel-\gls{SVM} classifier for the parameter. This
is the same approach taken by \textcite{poon2015phylodynamic}, and has the dual
purpose of allowing us to identify the optimal kernel meta-parameters
\gls{sigma} and \gls{lambda}. The parameters of the \gls{ER}, \gls{WS}, and
\gls{BA} network models were examined, but we will discuss only the results for
the $\alpha$ and prevalence parameters of the \gls{BA} model in the main text.
The results for the remaining models and their parameters can be found in the
supplemental material.

In Figure~\ref{fig:patrees}, we show that trees simulated under different
values of \gls{alpha} are visibly quite distinctive. In particular, higher
values of \gls{alpha} result in networks with a small number of highly
connected nodes (see Figure~\ref{fig:pabounds}) which, once infected, are
likely to transmit to many other nodes. This results in a more unbalanced,
ladder-like structure in the phylogeny. Kernel-\gls{PCA} projections show that
all three \gls{alpha} values are well separated from each other under several
different sampling scenarios (Figure~\ref{fig:pakpca}). With smaller trees,
it becomes harder to visually disinguish \gls{alpha} = 0.5 from \gls{alpha} =
1.0 using the first two principal components.

With suitably chosen meta-parameters, the accuracy of the kernel-\gls{SVM}
classifier for \gls{alpha} was very high under a variety of prevalence and
sampling scenarios (Figure~\ref{fig:pacrossv}). Accuracy was highest, with
$R^2$ values above 0.95, for the largest trees and complete sampling (bottom
center panel). However, even for trees of size 100 sampled from an epidemic on
2000 nodes, the $R^2$ was above 0.8 (top right panel). In all cases, the
accuracy of a Sackin's index-based classifier was also quite high, at about
0.75. The fact that Sackin's index is informative of \gls{alpha} was
unsurprising, given the clear differences in tree balance observed under
different \gls{alpha} values. The \gls{nltt}
statistic~\autocite{janzen2015approximate} did not improve the classifier, but
rather slightly reduced the $R^2$ in most cases. 

\begin{figure}[ht]
  \centering
  \label{fig:patrees}
  \includegraphics{kernel_pa_trees}
  \caption[Visibly distinctive trees simulated under three values of \gls{alpha}]{
    Epidemics of 1000 infected were simulated on \gls{BA} networks of 5000
    nodes, with \gls{alpha} equal to 0.5, 1.0, or 1.5. Transmission trees were
    created by sampling 500 infected nodes. Higher \gls{alpha} values produce
    networks with a small number of highly-connected nodes, which results in a
    highly unbalanced, ladder-like tree structure.
  }
\end{figure}

\begin{figure}[ht]
  \centering
  \label{fig:pacrossv}
  \includegraphics{kernel_pa_crossv}
  \caption[Cross-validation performance of kernel support vector machine
  classifier for preferential attachment power]{
    Cross-validation performance of kernel support vector machine classifier
    for preferential attachment power.
  }
\end{figure}

\begin{figure}[ht]
  \centering
  \label{fig:pakpca}
  \includegraphics{kernel_pa_kpca}
  \caption[Projection of kernel matrix for different attachment power values
  onto its first two principal components]{
    Projection of the kernel matrix for different preferential attachment power
    values onto its first two principal components, for eight simulation
    scenarios. Each point corresponds to a simulated transmission tree, and is
    coloured by preferential attachment power. Facets are number of infected
    nodes (horizontal), and number of sampled tips (vertical). The parameters
    to the tree kernel were $\lambda = 0.3$ and $\sigma = 4$, and the nLTT was
    not used. Qualitatively, trees with a larger number of tips are easier to
    separate in kernel space, regardless of what sampling proportion they
    represent. In all cases, the highest attachment power can be separated from
    the other two, but the two lowest values become hand to distinguish with in
    the 100-tip trees.
  }
\end{figure}

We also considered the possibility of inferring the number of infected nodes,
or \defn{prevalence}, under this model. All parameters except \gls{I} were
fixed at the following values: \gls{N} = 5000, \gls{alpha} = 1.0, and \gls{m} =
2. As shown in Figure~\ref{fig:prevtrees}, the prevalence had no obvious effect
on the tree shape. However, a kernel-\gls{SVM} classifier was able to
distinguish the number of infected nodes with high accuracy ($R^2 > 0.9$;
Figure~\ref{fig:prevcrossv}). Moreover, the use of the \gls{nltt} statistic
improved classification accuracy by a small amount, in contrast to the results
for \gls{alpha}. In contrast, a Sackin's index-based classifier displayed
extremely poor performance ($R^2$ < 0.1, not shown). 

It is important to note that, if we cut off the epidemic simulation when 500
nodes are infected, the resulting tree will be shorter (in calendar time) than
if we continue until 2000 nodes are infected. However, this information is not
used when building the classifier, since the branch lengths in each tree are
scaled by their mean. Therefore, the high performance of the classifier is due
to structural differences captured by the tree kernel, rather than the trees
simply having different heights.

\begin{figure}[ht]
  \centering
  \label{fig:prevtrees}
  \includegraphics{kernel_nsimnode_trees}
  \caption[Similarly shaped simulated under three values of \gls{I}]{
    Epidemics were simulated on networks of size 5000 until \gls{I} = 500,
    1000, or 2000 nodes were infected. When scaled to the same height, there is
    no immediately visible distinction in shape between trees simulated under
    different \gls{I} values.
  }
\end{figure}

\begin{figure}[ht]
  \centering
  \label{fig:prevcrossv}
  \includegraphics{kernel_nsimnode_crossv}
  \caption[Cross-validation performance of kernel-\gls{SVM} classifier for
           prevalence]{
    For \gls{BA} networks of size \gls{N} = 5000, a kernel-\gls{SVM} classifier
    is very accurate at predicting \gls{I}. Epidemics were simulated until
    \gls{I} = 500, 1000, or 2000 nodes were infected, and either 100 or 500
    nodes were sampled for inclusion in a transmission tree. The parameters of
    the \gls{BA} network were \gls{alpha} = 1.0 and \gls{m} = 2. A Sackin's
    index-based classifier performed very poorly on these data ($R^2 = $ TODO
    for 100-tip trees and blah for 500-tip trees, not shown).
  }
\end{figure}

\subsection{Accuracy of marginal estimates}

We used grid search to obtain \defn{marginal} estimates for each network
parameter while holding all other parameters fixed. We observed that kernel
scores were highest at the values of \gls{alpha} on the grid closest to the
true values, as shown in Figure~\ref{fig:gridkernel}. However, there was a much
stronger spike in kernel scores near the true value for \gls{alpha} = 1.0 and
1.25. This is recapitulated when we look at the accuracy of point estimates
obtained by taking the grid value with the highest median kernel score. As
shown in Figure~\ref{fig:gridest}, while the estimates are generally close to
the true value, they are much closer for \gls{alpha} = 1.25 than for the other
values.

\begin{figure}[ht]
  \centering
  \includegraphics{gridsearch_pa_kernel}
  \caption[Grid search kernel scores]{
    Grid search kernel scores for testing trees simulated under various
    \gls{alpha} values. All epidemics had \gls{I} = 1000 infected nodes, on
    \gls{BA} networks of size \gls{N} = 5000 with \gls{m} fixed at 2. Colours
    indicate the number of sampled tips.
  }
  \label{fig:gridkernel}
\end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics{gridsearch_pa_estimates}
  \caption[Marginal estimates of \gls{alpha} obtained with grid search]{
    Marginal estimates of \gls{alpha} obtained with grid search. Training trees
    were simulated on a narrowly spaced grid of \gls{alpha} values, and
    compared to testing trees using the tree kernel. The \gls{alpha} value in
    the grid with the highest median kernel score was taken as the point
    estimate for the testing tree. These point estimates are shown as black
    dots. The dashed line is the identity.
  }
  \label{fig:gridest}
\end{figure}

\subsection{Accuracy of estimates with full ABC}
