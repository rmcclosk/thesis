Name: gridsearch-edge-density
Description: Grid search for random network edge density
Processes: 20
Steps:
    train-network:
        Extension: gml
        Parameters:
            nnode: 5000
            nsimnode: 1000
            edge_density: "[i/50000. for i in range(10, 201)]"
            replicate: "range(10)"
        Interpreter: R --vanilla --silent
        Startup: suppressPackageStartupMessages(library(netabc))
        Rule: | 
            set.seed({seed})
            g <- sample_gnp({nnode}, {edge_density})
            while (length(component_distribution(g)) - 1 < {nsimnode}) {{
                g <- sample_gnp({nnode}, {edge_density})
            }}
            graph_attr(g, "comment") <- "{yaml}"
            write.graph(SI.net(g), "{train-network}", format="gml")

    train-tree:
        Extension: nwk
        Parameters:
            edge_density: "[i/50000. for i in range(10, 201)]"
            replicate: "range(10)"
            nsimnode: 1000
            ntip: 1000
        Depends: train-network
        Interpreter: bash
        Rule: |
            echo "#{yaml}" > {train-tree}                                                 
            nettree --sim-nodes {nsimnode} --tree-tips {ntip} --seed {seed} {train-network} >> {train-tree}

    test-network:
        Extension: gml
        Parameters:
            nnode: 5000
            nsimnode: 1000
            true_edge_density: [0.0004, 0.001, 0.002, 0.0032]
            test_replicate: "range(10)"
        Interpreter: R --vanilla --silent
        Startup: suppressPackageStartupMessages(library(netabc))
        Rule: | 
            set.seed({seed})
            g <- sample_gnp({nnode}, {true_edge_density})
            while (length(component_distribution(g)) - 1 < {nsimnode}) {{
                g <- sample_gnp({nnode}, {true_edge_density})
            }}
            graph_attr(g, "comment") <- "{yaml}"
            write.graph(SI.net(g), "{test-network}", format="gml")

    test-tree:
        Extension: nwk
        Parameters:
            true_edge_density: [0.0004, 0.001, 0.002, 0.0032]
            test_replicate: "range(10)"
            nsimnode: 1000
            ntip: 1000
        Depends: test-network
        Interpreter: bash
        Rule: |
            echo "#{yaml}" > {test-tree}                                                 
            nettree --sim-nodes {nsimnode} --tree-tips {ntip} --seed {seed} {test-network} >> {test-tree}

    kernel:
        Extension: tsv
        Parameters:
            true_edge_density: [0.0004, 0.001, 0.002, 0.0032]
            test_replicate: "range(10)"
            decay_factor: 0.3
            rbf_variance: 50
        Depends: train-tree test-tree
        Interpreter: bash
        Rule: |
            echo "#{yaml}" > {kernel}
            for T in {train-tree}; do
                echo -n "$T"$'\t' >> {kernel}
                treekernel --ladderize --normalize --scale-branches mean \
                           --decay-factor {decay_factor} \
                           --gauss-factor {rbf_variance} \
                           {test-tree} $T >> {kernel}
            done

    kernel-plot:
        Extension: pdf
        Parameters:
            true_edge_density: [0.0004, 0.001, 0.002, 0.0032]
            test_replicate: [0, 1, 2]
        Depends: kernel train-tree
        Interpreter: R --quiet --vanilla
        Startup: suppressPackageStartupMessages(library(netabc))
        Rule: |
            k <- read.table("{kernel}", row.names=1, col.names=c("", "score"))
            k <- merge(k, collect.metadata(strsplit("{train-tree}", " ")[[1]]), by=0)
            k <- subset(k, score > 0.96)
            pt.est <- with(k, as.numeric(names(which.max(tapply(score, edge_density, mean)))))
            lines <- data.frame(value=c(pt.est, {true_edge_density}),
                                edge_density=c("estimated", "true"))
            ggplot(k, aes(x=edge_density, y=score)) + geom_point() +
                geom_vline(data=lines, aes(xintercept=value, linetype=edge_density, color=edge_density), show_guide=TRUE) +
                theme_bw()
            ggsave("{kernel-plot}")

    error-plot:
        Extension: pdf
        Parameters:
            rbf_variance: 50
        Depends: kernel test-tree train-tree
        Interpreter: R --quiet --vanilla
        Startup: |
            suppressPackageStartupMessages(library(netabc))
            suppressPackageStartupMessages(library(data.table))
            suppressPackageStartupMessages(library(reshape2))
        Rule: |
            # collect all kernel scores
            files <- strsplit("{kernel}", " ")[[1]]
            d <- collect.data(files, header=FALSE, col.names=c("tree", "score"))

            # combine with metadata from train and test trees
            test.cols <- c("test_replicate", "true_edge_density")
            d <- merge(d, collect.metadata(strsplit("{train-tree}", " ")[[1]]), by.x="tree", by.y=0)
            d <- merge(d, collect.metadata(strsplit("{test-tree}", " ")[[1]]), by=test.cols)
            setDT(d)

            # choose point estimate with highest mean kernel score
            d <- d[,agg := median(score), by=c(test.cols, "edge_density")]

            # compute absolute and relative errors
            plot.data <- d[,abs(true_edge_density - edge_density[which.max(agg)]), by=test.cols]
            plot.data <- setNames(plot.data, c(test.cols, "absolute"))
            plot.data <- plot.data[,relative := absolute / true_edge_density]
            plot.data <- melt(plot.data, id.vars=test.cols, variable.name="error.type", value.name="error")
            plot.data <- plot.data[,true_edge_density := as.factor(true_edge_density)]

            # plot the errors
            ggplot(plot.data, aes(x=true_edge_density, y=error, group=true_edge_density)) + 
                geom_boxplot() + 
                facet_wrap(~error.type, scales="free") + theme_bw()
            ggsave("{error-plot}")
